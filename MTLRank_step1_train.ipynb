{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87185458",
   "metadata": {},
   "source": [
    "### Read TF name list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba46a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tf_list = pd.read_csv(\"data/tf_list/tf_list.csv\", index_col = 0)\n",
    "ensembl_to_symbol = pd.read_csv(\"data/ensembl_to_symbol.csv\",index_col = 0)\n",
    "ensembl_to_symbol = ensembl_to_symbol.loc[~ensembl_to_symbol[\"ensembl_id\"].duplicated(),:]\n",
    "ensembl_to_symbol.index = ensembl_to_symbol[\"ensembl_id\"]\n",
    "ensembl_to_symbol.index.name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd2ff42",
   "metadata": {},
   "source": [
    "### Load expression data, and TF activitiy scores for a tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59ef15b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the tissue name here\n",
    "tissue = 'Liver'\n",
    "\n",
    "# First we get indices of TFs\n",
    "with h5py.File('data/processed/rpkm.hdf5', 'r') as f:\n",
    "    col_names = np.array(f[tissue]['ensembl']).astype(str)\n",
    "tf_idx = np.where(np.isin(col_names, tf_list[\"Ensembl ID\"].values))[0]\n",
    "\n",
    "# Get expressions only for TF columns. RPKM values are log10 transformed.\n",
    "with h5py.File('data/processed/rpkm.hdf5', 'r') as f:\n",
    "    rpkm = pd.DataFrame(np.log10(np.array(f[tissue]['exp'][:,tf_idx])+1),\n",
    "                                index = np.array(f[tissue]['barcode']).astype(str),\n",
    "                                columns = np.array(f[tissue]['ensembl'][tf_idx]).astype(str))\n",
    "\n",
    "with h5py.File('data/processed/velo.hdf5', 'r') as f:\n",
    "    velo = pd.DataFrame(np.array(f[tissue]['velo']),\n",
    "                                index = np.array(f[tissue]['barcode']).astype(str),\n",
    "                                columns = np.array(f[tissue]['ensembl']).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b82d0",
   "metadata": {},
   "source": [
    "### Read TF activity score matrices. Missing values are treated as zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bdea8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder = \"results/tf_activities_mat\"\n",
    "\n",
    "tf_gene_mat_mean = pd.read_csv(f\"{folder}/{tissue}_tfGeneMean.csv\", index_col = 0).transpose()\n",
    "tf_gene_mat_sum = pd.read_csv(f\"{folder}/{tissue}_tfGeneSum.csv\", index_col = 0).transpose()\n",
    "tf_gene_mat_mean.fillna(0,inplace = True)\n",
    "tf_gene_mat_sum.fillna(0,inplace = True)\n",
    "\n",
    "# scale the value by log2\n",
    "tf_gene_mat_mean = np.log2(tf_gene_mat_mean+1)\n",
    "tf_gene_mat_sum = np.log2(tf_gene_mat_sum+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9654ef48",
   "metadata": {},
   "source": [
    "### Reformat the data matrices to keep the consistent TFs and genes.\n",
    "Make rpkm matrix and tf activity matrix have the same tfs  \n",
    "Make velo matrix and tf activity matrix have the same genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c811941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common TF \n",
    "tfmat_cols = pd.DataFrame(tf_gene_mat_mean.columns.values,columns = ['tfmat_cols'])\n",
    "comm_tfs = ensembl_to_symbol.merge(how = 'left',\n",
    "                                    left_on = 'gene_symbol',\n",
    "                                    right_on = \"tfmat_cols\",\n",
    "                                    right = tfmat_cols)\n",
    "comm_tfs = comm_tfs.loc[~comm_tfs['tfmat_cols'].isna(),]\n",
    "comm_tfs = comm_tfs.loc[comm_tfs[\"ensembl_id\"].isin(rpkm.columns),]\n",
    "\n",
    "# Find common (velocity) genes\n",
    "tfmat_rows = pd.DataFrame(tf_gene_mat_mean.index.values,columns = ['tfmat_rows'])\n",
    "comm_genes = ensembl_to_symbol.merge(how = 'left',\n",
    "                                        left_on = 'ensembl_id',\n",
    "                                        right_on = \"tfmat_rows\",\n",
    "                                        right = tfmat_rows)\n",
    "comm_genes = comm_genes.loc[~comm_genes['tfmat_rows'].isna(),]\n",
    "comm_genes = comm_genes.loc[comm_genes[\"ensembl_id\"].isin(velo.columns),]\n",
    "\n",
    "'''\n",
    "Reorder rpkm mat, velo mat, and cluster label vectors. The TF-Gene matrix follow the same tf_order and gene_order. In this order, the columns in upper left\n",
    "corner are the tfs commonly found in rpkm matrix and tf activity matrix and the rows represent the genes commonly found in velo matrix\n",
    "and tf activity matrix.\n",
    "          TF\n",
    "       _______ __\n",
    "      | common|  |\n",
    "Genes |_______|  |\n",
    "      |__________|\n",
    "'''\n",
    "tf_order = pd.concat([comm_tfs['ensembl_id'], pd.Series(np.setdiff1d(rpkm.columns, comm_tfs['ensembl_id']))])\n",
    "gene_order = pd.concat([comm_genes['ensembl_id'], pd.Series(np.setdiff1d(velo.columns, comm_genes['ensembl_id']))])\n",
    "\n",
    "rpkm = rpkm.loc[:,tf_order]\n",
    "velo = velo.loc[:,gene_order]\n",
    "\n",
    "act_mat_sum = np.zeros((velo.shape[1], rpkm.shape[1]))\n",
    "act_mat_mean = np.zeros((velo.shape[1], rpkm.shape[1]))\n",
    "\n",
    "act_mat_sum[:comm_genes.shape[0],:][:,:comm_tfs.shape[0]] = tf_gene_mat_sum.loc[comm_genes['tfmat_rows'],comm_tfs['tfmat_cols']]\n",
    "act_mat_mean[:comm_genes.shape[0],:][:,:comm_tfs.shape[0]] = tf_gene_mat_mean.loc[comm_genes['tfmat_rows'],comm_tfs['tfmat_cols']]\n",
    "\n",
    "act_mat_sum = pd.DataFrame(act_mat_sum, index = gene_order, columns = tf_order)\n",
    "act_mat_mean = pd.DataFrame(act_mat_mean, index = gene_order, columns = tf_order)\n",
    "\n",
    "del tf_gene_mat_mean\n",
    "del tf_gene_mat_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f780269",
   "metadata": {},
   "source": [
    "### Filter genes\n",
    "we get genes with more than 4000 cells for which the velocity values are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9a17ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liver has 77 selected genes.\n"
     ]
    }
   ],
   "source": [
    "# Get cell counts for which the velocity values are available\n",
    "n_cells = 4000\n",
    "cell_counts = (~velo.isna()).sum(axis = 0)\n",
    "selected_genes = cell_counts.index[cell_counts > 4000].values\n",
    "print(f\"{tissue} has {selected_genes.shape[0]} selected genes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7ef0df",
   "metadata": {},
   "source": [
    "### Cluster and order genes with balanced k-means clustering (by velocity values)\n",
    "1. Cluster the selected velocity genes by velocity values (balanced kmeans clustering)\n",
    "2. In each cluster, order the genes by correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6934bd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster sizes for Liver: [26 26 25]\n"
     ]
    }
   ],
   "source": [
    "from k_means_constrained import KMeansConstrained\n",
    "\n",
    "# Get velocity matrix (rows are cells, cols are genes)\n",
    "mat = velo.loc[:,selected_genes].values\n",
    "\n",
    "# For each gene, impute the missing velocity values by mean velocity from all available cells.\n",
    "na_mask = np.isnan(mat).astype(int)\n",
    "mean_mat = np.nanmean(mat, axis = 0).reshape(1,-1) * na_mask\n",
    "mat = np.nan_to_num(mat,nan = 0)\n",
    "mat = mat + mean_mat\n",
    "mat = pd.DataFrame(\n",
    "                    mat,\n",
    "                    columns = velo.loc[:,selected_genes].columns\n",
    "                )\n",
    "\n",
    "# Specify cluster size and number of clusters\n",
    "c_size_min = 25\n",
    "c_size_max = 26\n",
    "\n",
    "n_clusters = 3\n",
    "\n",
    "# Get cluster label for each gene.\n",
    "cluster_labels = KMeansConstrained(n_clusters = n_clusters,\n",
    "                                    size_min = c_size_min,\n",
    "                                    size_max = c_size_max).fit_predict(mat.values.T)\n",
    "cluster_labels = pd.DataFrame(cluster_labels, index = mat.columns, columns = [\"cluster\"])\n",
    "sizes = np.unique(cluster_labels['cluster'], return_counts=True)[1]\n",
    "print(f\"Cluster sizes for {tissue}: {np.unique(cluster_labels['cluster'], return_counts=True)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4232c2",
   "metadata": {},
   "source": [
    "### Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f70972b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize velo\n",
    "velo = (velo - velo.mean())/velo.std()\n",
    "\n",
    "# standardize rpkm train\n",
    "rpkm = (rpkm - rpkm.mean())/rpkm.std()\n",
    "\n",
    "# Fill na as zeros in rpkm matrices\n",
    "rpkm.fillna(value = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f52b5",
   "metadata": {},
   "source": [
    "### Train and get models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37cfea1",
   "metadata": {},
   "source": [
    "**Set Hyperparameters here**\n",
    "Hyperparameters to be set:\n",
    "- n_epochs: number of epochs\n",
    "- n_rep: number of replicates for each model\n",
    "- n_jobs: number of jobs for parallel computation. Should be less than total number of CPU cores.\n",
    "- batch_size: batch size for training\n",
    "- num_feature_type: for current framework, this is equal to 3.\n",
    "- learning_rate: learning rate for neural network training\n",
    "- Lambda: tracenorm reugularization strength\n",
    "- gamma: L1 regularization srength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f103e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 8\n",
    "n_rep = 5\n",
    "n_jobs = 10\n",
    "batch_size = 256\n",
    "num_feature_type = 3\n",
    "learning_rate = 0.01\n",
    "Lambda = 0.01\n",
    "gamma = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2063c9b",
   "metadata": {},
   "source": [
    "**MTL model architecture is set here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66cf2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_mtl_model(num_tf, num_feature_type, num_genes):\n",
    "    models = []\n",
    "    for k in range(num_genes):\n",
    "        inputs = [Input(shape = (num_feature_type,)) for i in range(num_tf)]\n",
    "        concat_layer = [Dense(1, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.l1(gamma))(inp) for inp in inputs]\n",
    "        concat_layer = concatenate(concat_layer)\n",
    "        out = Dense(64, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.l1(gamma))(concat_layer)\n",
    "        out = Dense(32, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.l1(gamma))(out)\n",
    "        out = Dense(16, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.l1(gamma))(out)\n",
    "        out = Dense(1, activation = \"linear\")(out)\n",
    "\n",
    "        models.append(Model(inputs = inputs, outputs = out))   \n",
    "        \n",
    "    return(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1086795",
   "metadata": {},
   "source": [
    "**Trace norm and gradient of trace norm**  \n",
    "Define nuclear norm, (sub)gradient of nuclear norm, and tensor trace norm, and tensor unfold function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91a02a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define nuclear norm operation\n",
    "@tf.custom_gradient\n",
    "def nuclear_norm(x):\n",
    "    sigma = tf.linalg.svd(x, full_matrices=False, compute_uv=False)\n",
    "    norm = tf.reduce_sum(sigma)\n",
    "    \n",
    "    # Grandient function\n",
    "    def nuclear_norm_grad(dy):\n",
    "        _, U, V = tf.linalg.svd(x, full_matrices=False, compute_uv=True)\n",
    "        grad = tf.matmul(U, tf.transpose(V))\n",
    "        return dy * grad\n",
    "    \n",
    "    return norm, nuclear_norm_grad\n",
    "\n",
    "def TensorUnfold(A, k):\n",
    "    tmp_arr = np.arange(A.shape.ndims)\n",
    "    A = tf.transpose(A, tf.convert_to_tensor([tmp_arr[k]] + np.delete(tmp_arr, k).tolist()))\n",
    "    A = tf.reshape(A, tf.convert_to_tensor([A.shape[0], np.prod(A.shape[1:])]))\n",
    "    return A\n",
    "\n",
    "def trace_norm(X):\n",
    "    return nuclear_norm(TensorUnfold(X, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f0404",
   "metadata": {},
   "source": [
    "**Train models for all selected genes**  \n",
    "Trained models will be saved under results/full_model/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88c60c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 22:59:44.132593: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 22:59:44.142092: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 22:59:44.196457: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 22:59:44.206807: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 22:59:44.208547: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 22:59:44.221340: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 22:59:44.249830: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 22:59:44.373043: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 22:59:44.416488: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 22:59:44.454315: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x14a19bbe14c0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x14a19bbe14c0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x14c8912614c0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x14c8912614c0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x148205f5e550> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x148205f5e550>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features ... Mon Dec 12 22:59:41 2022\n",
      "Setting up models...Mon Dec 12 22:59:43 2022\n",
      "Preparing features ... Mon Dec 12 22:59:41 2022\n",
      "Setting up models...Mon Dec 12 22:59:43 2022\n",
      "Preparing features ... Mon Dec 12 22:59:40 2022\n",
      "Setting up models...Mon Dec 12 22:59:43 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x14e1842e14c0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x14e1842e14c0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x14c5d909e550> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x14c5d909e550>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features ... Mon Dec 12 22:59:41 2022\n",
      "Setting up models...Mon Dec 12 22:59:43 2022\n",
      "Preparing features ... Mon Dec 12 22:59:40 2022\n",
      "Setting up models...Mon Dec 12 22:59:43 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x1515ca1614c0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x1515ca1614c0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x1538493a14c0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x1538493a14c0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features ... Mon Dec 12 22:59:40 2022\n",
      "Setting up models...Mon Dec 12 22:59:43 2022\n",
      "Preparing features ... Mon Dec 12 22:59:40 2022\n",
      "Setting up models...Mon Dec 12 22:59:43 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x14a01c55e550> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x14a01c55e550>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features ... Mon Dec 12 22:59:41 2022\n",
      "Setting up models...Mon Dec 12 22:59:43 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x154689dde550> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x154689dde550>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features ... Mon Dec 12 22:59:40 2022\n",
      "Setting up models...Mon Dec 12 22:59:43 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x1497a9da14c0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x1497a9da14c0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features ... Mon Dec 12 22:59:41 2022\n",
      "Setting up models...Mon Dec 12 22:59:43 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 23:19:06.833978: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:19:32.620788: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:19:33.894876: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:19:38.125743: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:19:41.116720: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:19:46.613149: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:19:57.682751: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:20:10.285399: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:20:16.922240: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:20:21.417062: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:20:21.419475: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:20:32.297594: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:20:40.284876: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:20:41.615332: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:20:42.921773: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:20:58.943972: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:20:58.972200: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:21:04.122061: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:21:16.734006: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:21:17.482805: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:21:49.182749: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:21:53.203493: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:22:03.295624: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:22:21.176385: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:22:22.112543: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:22:46.256856: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:22:56.971859: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:23:12.609311: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:23:22.861881: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:23:25.663837: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:23:28.064879: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:23:48.723605: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:24:14.722754: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:24:22.989691: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Iter 1/18, loss value: 4.445512, MSE: 1.2819667, 1041.6s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.2493825, MSE: 1.0958983, 3.0s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.143642, MSE: 1.0061866, 2.6s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.102956, MSE: 0.98980683, 2.6s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 4.165454, MSE: 1.0845526, 2.8s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 3.9776592, MSE: 0.93564075, 2.7s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 3.912944, MSE: 0.91566235, 2.6s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.8534467, MSE: 0.9060281, 2.6s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.7921436, MSE: 0.89883256, 10.1s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.7966762, MSE: 0.96087, 2.7s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.6558151, MSE: 0.8802182, 2.7s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.6043873, MSE: 0.8910068, 2.7s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.6083508, MSE: 0.95850384, 2.6s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.4564273, MSE: 0.87076896, 2.6s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.4066784, MSE: 0.88547474, 2.6s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.283161, MSE: 0.82608986, 2.6s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.241179, MSE: 0.84741783, 2.7s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.0134108, MSE: 0.6818686, 2.4s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 3.0729518, MSE: 0.80147165, 2.8s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 3.0052266, MSE: 0.7919467, 2.9s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 2.9242043, MSE: 0.76703477, 2.7s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.8083348, MSE: 0.70511687, 2.6s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.7866168, MSE: 0.73507655, 2.8s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.7109585, MSE: 0.7087481, 2.6s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.7145095, MSE: 0.7594224, 2.6s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.667007, MSE: 0.75685924, 2.6s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.6161504, MSE: 0.74892396, 2.8s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.5654304, MSE: 0.7392693, 2.7s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.4332042, MSE: 0.64632255, 2.7s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.4443583, MSE: 0.69522667, 2.6s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.4514332, MSE: 0.73871666, 2.6s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.3784955, MSE: 0.7009836, 2.7s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.3262305, MSE: 0.6829268, 2.8s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.2801213, MSE: 0.67026144, 2.6s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.2726722, MSE: 0.6956972, 2.6s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.2594702, MSE: 0.71477926, 2.3s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.1858633, MSE: 0.6725067, 2.6s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.0871665, MSE: 0.6044322, 10.5s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 2.1160219, MSE: 0.6631728, 2.6s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 2.0633755, MSE: 0.6396901, 2.7s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 2.0489962, MSE: 0.65384346, 2.6s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 1.9639713, MSE: 0.5965985, 2.6s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 2.0191948, MSE: 0.6788781, 2.6s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 1.9517007, MSE: 0.6377141, 2.6s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 1.8977277, MSE: 0.6094697, 2.6s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 1.8959529, MSE: 0.6328404, 2.6s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 1.8728588, MSE: 0.6342067, 2.6s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.8131167, MSE: 0.5981709, 2.6s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.8085847, MSE: 0.61664224, 2.6s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.7694145, MSE: 0.59993505, 2.6s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.7582176, MSE: 0.6107303, 2.6s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.7533727, MSE: 0.62734103, 2.6s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.7207682, MSE: 0.6156333, 2.6s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.7695283, MSE: 0.6848072, 2.3s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.6439114, MSE: 0.5785768, 2.6s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.664345, MSE: 0.61755806, 2.6s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.563035, MSE: 0.5339503, 2.6s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.5541979, MSE: 0.5422627, 2.6s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.586618, MSE: 0.591302, 2.6s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.5831773, MSE: 0.6041523, 2.7s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.5695381, MSE: 0.60642153, 2.6s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.5339513, MSE: 0.58628625, 2.6s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.522033, MSE: 0.58940506, 2.6s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.5165145, MSE: 0.598467, 2.6s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.527076, MSE: 0.6232104, 2.6s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.4564294, MSE: 0.5664221, 2.6s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.4442378, MSE: 0.56782395, 2.6s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.4476955, MSE: 0.5846568, 10.4s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.4735122, MSE: 0.623639, 2.6s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.4459084, MSE: 0.60904, 2.6s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.3952432, MSE: 0.5711249, 2.6s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.3796027, MSE: 0.5678501, 2.2s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.390736, MSE: 0.5905279, 2.6s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.3761287, MSE: 0.5868496, 2.6s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.3366013, MSE: 0.55767053, 2.6s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.3228334, MSE: 0.55371785, 2.7s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.3040675, MSE: 0.54440504, 2.6s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.3165196, MSE: 0.56603026, 2.6s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.2825983, MSE: 0.541028, 2.6s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.2585962, MSE: 0.52578384, 2.6s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.2844193, MSE: 0.56022114, 2.7s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.2857525, MSE: 0.57013273, 2.6s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.2473576, MSE: 0.54023397, 2.6s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.2423427, MSE: 0.5435768, 2.6s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.311778, MSE: 0.62119836, 2.6s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.2479441, MSE: 0.5654989, 2.6s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.269776, MSE: 0.5952383, 2.6s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.263686, MSE: 0.5968915, 2.6s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.2348113, MSE: 0.5754772, 2.7s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.1754457, MSE: 0.5233217, 2.3s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.160533, MSE: 0.51530707, 2.6s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.1448017, MSE: 0.5059472, 2.6s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.1515257, MSE: 0.51862866, 2.6s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.1437767, MSE: 0.5165352, 2.6s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.1291218, MSE: 0.50735176, 2.6s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.1536747, MSE: 0.53738666, 2.6s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.1738511, MSE: 0.5630368, 10.3s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.1500793, MSE: 0.5446646, 2.7s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.1293087, MSE: 0.5293367, 2.7s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.1406951, MSE: 0.54613274, 2.8s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.1496673, MSE: 0.5605447, 2.6s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.1152194, MSE: 0.5313746, 2.7s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.1311779, MSE: 0.5525438, 2.7s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.124155, MSE: 0.5508145, 2.7s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.134801, MSE: 0.5665666, 2.7s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.1440635, MSE: 0.58080995, 2.7s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.1068063, MSE: 0.5484438, 2.7s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 1.1044401, MSE: 0.5508324, 2.2s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 1.0648202, MSE: 0.51544183, 2.7s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 1.0614588, MSE: 0.51576716, 2.6s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 1.0220202, MSE: 0.4797208, 2.7s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 1.0616031, MSE: 0.522514, 2.8s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 1.0204697, MSE: 0.48464885, 2.6s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 1.0775275, MSE: 0.544982, 2.7s used\n",
      "Epoch 1/8, Iter 1/18, loss value: 4.4216022, MSE: 1.2583678, 1046.7s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.324437, MSE: 1.1712472, 3.7s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.2649045, MSE: 1.1279914, 2.8s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.1807017, MSE: 1.0682793, 2.6s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 4.1334453, MSE: 1.0531541, 2.7s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 4.0612073, MSE: 1.0197688, 2.7s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 4.016768, MSE: 1.0200493, 2.9s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.940341, MSE: 0.99338776, 2.6s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.8705585, MSE: 0.97760624, 9.9s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.8208203, MSE: 0.98533404, 2.7s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.7034328, MSE: 0.92817086, 2.9s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.62218, MSE: 0.90919465, 2.7s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.5849223, MSE: 0.935591, 2.7s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.4590259, MSE: 0.8741639, 2.7s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.4522028, MSE: 0.93190324, 2.6s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.2537658, MSE: 0.7978, 2.8s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.196271, MSE: 0.8040302, 2.7s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.1911516, MSE: 0.861624, 2.2s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 3.0212255, MSE: 0.75213146, 2.6s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 2.9966006, MSE: 0.7859488, 2.6s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 2.9292479, MSE: 0.7748493, 2.6s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.9128323, MSE: 0.8124726, 2.7s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.8256903, MSE: 0.77712, 2.6s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.7410293, MSE: 0.74200153, 2.6s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.6973386, MSE: 0.7454897, 2.6s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.6925516, MSE: 0.78556794, 2.6s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.594408, MSE: 0.7301821, 2.6s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.5614517, MSE: 0.7380084, 2.6s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.5138714, MSE: 0.72941965, 2.6s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.5016131, MSE: 0.7545904, 2.6s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.4759982, MSE: 0.7649426, 2.6s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.3994708, MSE: 0.7231106, 2.6s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.3410938, MSE: 0.6983134, 2.6s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.308846, MSE: 0.6987591, 2.6s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.2456164, MSE: 0.667509, 2.8s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.1886158, MSE: 0.64185584, 2.3s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.156884, MSE: 0.64052516, 2.6s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.153048, MSE: 0.66623807, 9.9s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 2.153049, MSE: 0.6949882, 2.7s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 2.047149, MSE: 0.6171145, 2.6s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 2.0412703, MSE: 0.6385968, 2.6s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 2.0421863, MSE: 0.66621244, 2.6s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 2.0599985, MSE: 0.71002686, 2.6s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 1.9630506, MSE: 0.63833106, 2.6s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 1.9427061, MSE: 0.6426148, 2.6s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 1.8769822, MSE: 0.6008002, 2.6s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 1.9164462, MSE: 0.66343874, 2.6s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.8815918, MSE: 0.6512454, 2.6s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.8372169, MSE: 0.62901646, 2.6s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.8062755, MSE: 0.61957324, 2.6s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.8075708, MSE: 0.64178026, 2.6s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.7173877, MSE: 0.57185805, 2.6s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.7294986, MSE: 0.6038049, 2.6s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.7387887, MSE: 0.6325731, 2.2s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.6652324, MSE: 0.5776273, 2.6s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.679673, MSE: 0.6099926, 2.7s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.616123, MSE: 0.5635904, 2.6s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.6366985, MSE: 0.60068154, 2.6s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.6191654, MSE: 0.59909356, 2.6s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.5651157, MSE: 0.56029165, 2.6s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.551446, MSE: 0.56137127, 2.6s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.5405686, MSE: 0.56503624, 2.6s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.5752342, MSE: 0.6141333, 2.6s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.5276912, MSE: 0.58065027, 2.6s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.5260713, MSE: 0.5928164, 2.6s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.5048585, MSE: 0.58502233, 2.6s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.4973013, MSE: 0.5905569, 2.6s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.4942129, MSE: 0.6004826, 9.8s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.5255206, MSE: 0.6444864, 2.6s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.4898446, MSE: 0.62117046, 2.6s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.4592195, MSE: 0.602689, 2.7s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.5051365, MSE: 0.660333, 2.3s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.3617741, MSE: 0.5280431, 2.6s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.3859992, MSE: 0.56255144, 2.6s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.3202066, MSE: 0.506332, 2.7s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.3782591, MSE: 0.57347715, 2.6s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.4145876, MSE: 0.6184902, 2.6s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.3440694, MSE: 0.55638117, 2.5s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.3277946, MSE: 0.54841167, 2.6s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.3153702, MSE: 0.54409003, 2.7s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.3150812, MSE: 0.5518696, 2.6s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.319232, MSE: 0.5640496, 2.6s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.318149, MSE: 0.5709069, 2.6s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.29945, MSE: 0.56002533, 2.6s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.3285184, MSE: 0.5969918, 2.6s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.2858524, MSE: 0.56212103, 2.6s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.3004891, MSE: 0.58449435, 2.6s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.347791, MSE: 0.6394396, 2.6s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.2463405, MSE: 0.5454231, 2.6s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.1974989, MSE: 0.5037787, 2.3s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.259478, MSE: 0.57247555, 2.6s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.1946931, MSE: 0.5137595, 2.6s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.2064816, MSE: 0.5312142, 2.6s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.1822366, MSE: 0.51230216, 2.6s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.1820583, MSE: 0.5172692, 2.6s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.2090037, MSE: 0.5493435, 2.6s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.1920283, MSE: 0.53747797, 9.8s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.1853263, MSE: 0.535879, 2.8s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.2115135, MSE: 0.5673183, 2.6s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.1822273, MSE: 0.5433431, 2.5s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.1674488, MSE: 0.5339998, 2.7s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.1942611, MSE: 0.5661199, 2.7s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.1656909, MSE: 0.542693, 2.7s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.1936779, MSE: 0.575725, 2.7s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.1996901, MSE: 0.58678937, 2.7s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.1503303, MSE: 0.5424669, 2.6s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.1182561, MSE: 0.5153495, 2.7s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 1.195622, MSE: 0.5974528, 2.3s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 1.1071184, MSE: 0.5132764, 2.6s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 1.0718131, MSE: 0.48183835, 2.6s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 1.077213, MSE: 0.49071774, 2.7s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 1.1248423, MSE: 0.5417117, 2.7s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 1.0533617, MSE: 0.4735549, 2.7s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 1.0697076, MSE: 0.49317998, 2.6s used\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Iter 1/18, loss value: 4.498609, MSE: 1.331733, 1046.0s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.3170614, MSE: 1.1594388, 2.9s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.282959, MSE: 1.140513, 2.7s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.1747255, MSE: 1.0552051, 2.6s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 4.0962806, MSE: 1.0069983, 2.7s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 3.9947658, MSE: 0.94209355, 2.7s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 4.0060277, MSE: 0.995567, 2.6s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.9598331, MSE: 0.99627084, 2.6s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.8666987, MSE: 0.95399815, 11.2s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.7150664, MSE: 0.85638785, 2.8s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.6802373, MSE: 0.8780631, 2.7s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.6530356, MSE: 0.90929615, 2.7s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.6854916, MSE: 1.0014488, 2.7s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.4579606, MSE: 0.8342739, 2.7s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.4283304, MSE: 0.86531967, 2.6s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.3932521, MSE: 0.8906979, 2.8s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.2006443, MSE: 0.757803, 2.6s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.2618797, MSE: 0.87786716, 2.2s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 3.1373148, MSE: 0.81025785, 2.6s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 3.0280704, MSE: 0.7562963, 2.7s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 2.924258, MSE: 0.7060127, 2.8s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.925448, MSE: 0.75883114, 2.6s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.8347404, MSE: 0.71777683, 2.6s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.7521956, MSE: 0.68294877, 2.6s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.7231784, MSE: 0.69987357, 2.6s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.692046, MSE: 0.7130039, 2.6s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.6784306, MSE: 0.7419201, 2.6s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.5752525, MSE: 0.67958516, 2.6s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.5870314, MSE: 0.7306475, 2.6s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.5419936, MSE: 0.72346187, 2.6s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.4754002, MSE: 0.69344807, 2.6s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.520033, MSE: 0.77361304, 2.6s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.3989272, MSE: 0.68698335, 2.6s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.4081113, MSE: 0.7297843, 2.6s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.2886715, MSE: 0.64321715, 2.7s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.2735183, MSE: 0.66022015, 2.3s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.2414293, MSE: 0.65912926, 2.7s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.189871, MSE: 0.6376892, 10.5s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 2.1447878, MSE: 0.6219976, 2.6s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 2.1062632, MSE: 0.61223555, 2.6s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 2.1006272, MSE: 0.6348783, 2.7s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 2.05013, MSE: 0.6120675, 2.6s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 2.0462792, MSE: 0.6352475, 2.6s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 1.9784248, MSE: 0.59383005, 2.6s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 1.9709675, MSE: 0.6120775, 2.6s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 1.9409345, MSE: 0.60702956, 2.6s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 1.9436195, MSE: 0.6340613, 2.6s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.9257414, MSE: 0.63992697, 2.6s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.8525797, MSE: 0.5899533, 2.6s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.9025891, MSE: 0.6625528, 2.8s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.838289, MSE: 0.6203149, 2.6s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.8008913, MSE: 0.60451436, 2.6s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.743191, MSE: 0.56807697, 2.6s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.732471, MSE: 0.5781674, 2.2s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.7185354, MSE: 0.58407587, 2.6s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.6706715, MSE: 0.5552828, 2.6s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.6711128, MSE: 0.5741306, 2.5s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.6209698, MSE: 0.54167974, 2.6s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.6672355, MSE: 0.6050732, 2.6s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.6418467, MSE: 0.5963404, 2.7s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.5568208, MSE: 0.527581, 2.6s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.5361824, MSE: 0.5228112, 2.6s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.6141357, MSE: 0.6162809, 2.6s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.594799, MSE: 0.61211485, 2.6s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.5426722, MSE: 0.5747701, 2.6s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.5349696, MSE: 0.5814527, 2.6s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.5389018, MSE: 0.59952664, 2.6s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.5254856, MSE: 0.5999564, 10.1s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.4998243, MSE: 0.5878154, 2.6s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.4931722, MSE: 0.5945701, 2.6s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.4395165, MSE: 0.55412066, 2.6s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.3992229, MSE: 0.5266755, 2.2s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.4002421, MSE: 0.5397771, 2.6s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.3804088, MSE: 0.531369, 2.6s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.3994687, MSE: 0.5612147, 2.6s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.3685052, MSE: 0.5404364, 2.6s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.3763783, MSE: 0.5582461, 2.6s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.3481754, MSE: 0.53965795, 2.7s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.3551774, MSE: 0.555965, 2.6s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.3749752, MSE: 0.58498156, 2.6s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.348865, MSE: 0.56783015, 2.5s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.3708093, MSE: 0.5986754, 2.6s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.3058193, MSE: 0.54251623, 2.6s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.3560139, MSE: 0.60150343, 2.6s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.3406125, MSE: 0.59461766, 2.6s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.2764114, MSE: 0.5387645, 2.6s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.3015306, MSE: 0.57221764, 2.6s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.330955, MSE: 0.609834, 2.6s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.2590322, MSE: 0.5459436, 2.6s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.2397027, MSE: 0.53439975, 2.3s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.2335589, MSE: 0.53535104, 2.7s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.241199, MSE: 0.5493563, 2.6s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.2272658, MSE: 0.54130745, 2.6s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.2439983, MSE: 0.56385195, 2.6s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.1821771, MSE: 0.5078591, 2.6s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.2112687, MSE: 0.54265755, 2.6s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.1778835, MSE: 0.51497006, 10.3s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.1783962, MSE: 0.52101415, 2.6s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.2031711, MSE: 0.5513258, 2.6s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.1866753, MSE: 0.54039556, 2.6s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.1893588, MSE: 0.5487408, 2.6s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.1587412, MSE: 0.5238792, 2.6s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.1517949, MSE: 0.52267516, 2.7s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.2138884, MSE: 0.59049827, 2.6s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.164547, MSE: 0.54676676, 2.7s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.15645, MSE: 0.54429716, 2.7s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.0950749, MSE: 0.48851666, 2.7s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 1.0687499, MSE: 0.46766397, 2.3s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 1.0860052, MSE: 0.49007317, 2.7s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 1.0956223, MSE: 0.5042465, 2.7s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 1.0534662, MSE: 0.46605936, 2.7s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 1.1273556, MSE: 0.5438079, 2.6s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 1.0413663, MSE: 0.46171576, 2.7s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 1.0805953, MSE: 0.50477076, 2.7s used\n",
      "Epoch 1/8, Iter 1/18, loss value: 4.5907946, MSE: 1.4280245, 1048.2s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.377161, MSE: 1.2233415, 3.9s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.219538, MSE: 1.0803319, 2.6s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.15054, MSE: 1.0337619, 2.7s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 4.096977, MSE: 1.009739, 2.8s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 4.0113645, MSE: 0.95981306, 2.6s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 3.9846926, MSE: 0.97426856, 3.0s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.8595543, MSE: 0.89496005, 2.7s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.861619, MSE: 0.9468369, 10.3s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.7368662, MSE: 0.87505585, 2.9s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.6709766, MSE: 0.8645984, 2.8s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.68602, MSE: 0.93698436, 2.6s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.5444689, MSE: 0.8540355, 2.6s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.4901378, MSE: 0.8591216, 2.6s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.4610305, MSE: 0.88970304, 2.8s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.3755977, MSE: 0.8636932, 2.6s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.274217, MSE: 0.8211591, 2.6s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.2082627, MSE: 0.81307095, 2.2s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 3.1134732, MSE: 0.77419287, 2.6s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 3.0159807, MSE: 0.7309631, 2.6s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 2.9668236, MSE: 0.7343636, 2.6s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.9476838, MSE: 0.7659304, 2.5s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.8616345, MSE: 0.72865176, 2.6s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.8212826, MSE: 0.7350778, 2.5s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.7753875, MSE: 0.73398304, 2.5s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.6311598, MSE: 0.63267666, 2.6s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.6609936, MSE: 0.7037715, 2.6s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.6339202, MSE: 0.71642107, 2.6s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.5626335, MSE: 0.68335366, 2.5s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.528717, MSE: 0.6862762, 2.6s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.4951117, MSE: 0.6883549, 2.7s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.4541757, MSE: 0.6820736, 2.7s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.4354284, MSE: 0.6969791, 2.6s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.3754416, MSE: 0.6699101, 2.6s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.3375154, MSE: 0.66422737, 2.6s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.309876, MSE: 0.6682097, 2.2s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.2274559, MSE: 0.6165248, 2.5s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.206584, MSE: 0.62558424, 10.4s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 2.1777658, MSE: 0.6259266, 2.6s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 2.1511903, MSE: 0.6278655, 2.6s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 2.0879524, MSE: 0.59256357, 2.6s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 2.0729904, MSE: 0.60490096, 2.6s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 2.103754, MSE: 0.6623585, 2.6s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 2.0339422, MSE: 0.61862904, 2.5s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 1.9691436, MSE: 0.5793234, 2.6s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 1.9997077, MSE: 0.634684, 2.6s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 1.963205, MSE: 0.62227786, 2.6s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.9845774, MSE: 0.66712403, 2.6s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.854665, MSE: 0.5600683, 2.6s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.904669, MSE: 0.632412, 2.6s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.8590648, MSE: 0.60859704, 2.6s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.8758602, MSE: 0.6466019, 2.6s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.7544091, MSE: 0.54581183, 2.6s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.7380633, MSE: 0.5495456, 2.3s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.743146, MSE: 0.5738609, 2.7s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.6985238, MSE: 0.54782474, 2.6s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.6901219, MSE: 0.5574839, 2.6s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.7001286, MSE: 0.58504903, 2.6s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.6661608, MSE: 0.56812435, 2.6s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.6606855, MSE: 0.57927305, 2.6s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.6128008, MSE: 0.54753625, 2.6s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.61199, MSE: 0.56242186, 2.6s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.5851398, MSE: 0.5508247, 2.6s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.604212, MSE: 0.58490914, 2.6s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.5873063, MSE: 0.58278626, 2.6s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.5820267, MSE: 0.59203476, 2.7s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.5506506, MSE: 0.5747942, 2.6s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.5380911, MSE: 0.5760099, 10.4s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.5511723, MSE: 0.6025832, 2.6s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.510737, MSE: 0.5753949, 2.5s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.473641, MSE: 0.5512877, 2.6s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.5069726, MSE: 0.5973037, 2.2s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.4254632, MSE: 0.5278319, 2.5s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.4042752, MSE: 0.51801044, 2.6s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.4228818, MSE: 0.5474694, 2.6s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.3959159, MSE: 0.53075093, 2.6s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.3771178, MSE: 0.521913, 2.5s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.3691165, MSE: 0.5235374, 2.5s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.357195, MSE: 0.52096504, 2.6s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.3921399, MSE: 0.5650814, 2.6s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.3568802, MSE: 0.53882354, 2.5s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.3874453, MSE: 0.5785035, 2.6s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.3383718, MSE: 0.5384705, 2.6s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.3441033, MSE: 0.55307376, 2.6s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.3236854, MSE: 0.54138017, 2.6s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.3424418, MSE: 0.5687732, 2.6s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.356905, MSE: 0.5917247, 2.7s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.3451555, MSE: 0.5883306, 2.7s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.294733, MSE: 0.54608643, 2.6s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.2096124, MSE: 0.4689117, 2.3s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.2634556, MSE: 0.5301441, 2.6s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.2687596, MSE: 0.5422793, 2.6s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.2313428, MSE: 0.51130724, 2.6s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.2114677, MSE: 0.49749944, 2.6s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.2512047, MSE: 0.5430666, 2.6s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.243443, MSE: 0.5410725, 2.6s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.2451596, MSE: 0.5485011, 10.5s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.2206976, MSE: 0.5297521, 2.5s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.1811254, MSE: 0.49585292, 2.6s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.1896266, MSE: 0.5099045, 2.6s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.207993, MSE: 0.53387696, 2.6s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.2024293, MSE: 0.5340464, 2.6s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.2068822, MSE: 0.5442397, 2.6s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.2011738, MSE: 0.54424256, 2.6s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.1431136, MSE: 0.4918763, 2.6s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.2141318, MSE: 0.5686303, 2.6s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.1831868, MSE: 0.54337156, 2.6s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 1.1266547, MSE: 0.49226445, 2.3s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 1.1542462, MSE: 0.5248441, 2.7s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 1.1412904, MSE: 0.51645315, 2.6s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 1.1138729, MSE: 0.493327, 2.6s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 1.1157582, MSE: 0.499221, 2.6s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 1.1098126, MSE: 0.49727598, 2.8s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 1.0903666, MSE: 0.48178953, 2.8s used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 23:24:27.137929: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Iter 1/18, loss value: 4.4644365, MSE: 1.2963352, 1053.4s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.342395, MSE: 1.1837072, 2.9s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.185258, MSE: 1.0420388, 2.6s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.170734, MSE: 1.0513225, 2.7s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 4.1642475, MSE: 1.0761156, 2.7s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 4.0589395, MSE: 1.0084842, 2.7s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 4.0006104, MSE: 0.99343723, 2.6s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.9109302, MSE: 0.9519415, 2.6s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.9231267, MSE: 1.016493, 10.0s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.7702076, MSE: 0.9191442, 2.9s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.7961621, MSE: 1.003327, 2.6s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.5897253, MSE: 0.8571179, 2.6s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.5799274, MSE: 0.9089798, 2.8s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.4880881, MSE: 0.879633, 2.6s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.3806314, MSE: 0.8350326, 2.6s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.3692787, MSE: 0.8863402, 2.7s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.2907937, MSE: 0.86980987, 2.6s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.1534512, MSE: 0.793346, 2.2s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 3.0901368, MSE: 0.7885383, 2.6s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 3.0113964, MSE: 0.7665535, 2.8s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 2.896053, MSE: 0.7060538, 2.6s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.897733, MSE: 0.76057583, 2.6s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.8075316, MSE: 0.7210669, 2.7s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.8114333, MSE: 0.77352655, 2.6s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.7146406, MSE: 0.72317344, 2.6s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.731763, MSE: 0.7847858, 2.7s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.7158504, MSE: 0.8114146, 2.5s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.6206403, MSE: 0.7569079, 2.8s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.5185971, MSE: 0.693847, 2.6s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.5732496, MSE: 0.7860222, 2.6s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.4906352, MSE: 0.739575, 2.6s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.4597754, MSE: 0.74380744, 2.6s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.3952193, MSE: 0.7133503, 2.6s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.377408, MSE: 0.7286984, 2.6s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.2910855, MSE: 0.674724, 2.6s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.2581978, MSE: 0.6733679, 2.2s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.2480922, MSE: 0.6936788, 2.6s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.201148, MSE: 0.676288, 10.6s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 2.097649, MSE: 0.60160744, 2.8s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 2.0520678, MSE: 0.58410746, 2.6s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 2.0655134, MSE: 0.62501484, 2.6s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 2.0819092, MSE: 0.6683709, 2.7s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 2.04321, MSE: 0.65598273, 2.8s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 1.9932603, MSE: 0.63158965, 2.6s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 1.9471185, MSE: 0.61027634, 2.6s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 1.9538958, MSE: 0.6412223, 2.7s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 1.9077291, MSE: 0.6186806, 2.7s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.9130584, MSE: 0.6471716, 2.6s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.8822373, MSE: 0.63893867, 2.6s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.8808482, MSE: 0.6595332, 2.5s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.8438773, MSE: 0.64406973, 2.5s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.8443373, MSE: 0.6653043, 2.5s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.7820568, MSE: 0.6233739, 2.6s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.713834, MSE: 0.5750832, 2.2s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.703655, MSE: 0.5839229, 2.6s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.70496, MSE: 0.60354877, 2.5s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.6287042, MSE: 0.5447291, 2.6s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.6530042, MSE: 0.58580863, 2.6s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.5969331, MSE: 0.54600143, 2.6s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.5826607, MSE: 0.54753137, 2.5s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.6038016, MSE: 0.5841932, 2.6s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.5760913, MSE: 0.5717455, 2.6s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.5338393, MSE: 0.54434717, 2.9s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.5566654, MSE: 0.5817826, 2.6s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.6006951, MSE: 0.6400967, 2.8s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.5114423, MSE: 0.56479406, 2.7s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.5660903, MSE: 0.63304675, 2.6s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.5446513, MSE: 0.6250616, 10.2s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.498774, MSE: 0.59237003, 2.6s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.5376332, MSE: 0.64402413, 2.6s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.4599242, MSE: 0.5787665, 2.6s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.4381516, MSE: 0.56909347, 2.3s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.4208984, MSE: 0.56339604, 2.6s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.4147063, MSE: 0.56798273, 2.6s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.4108515, MSE: 0.57418454, 2.6s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.3506672, MSE: 0.52353656, 2.6s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.3500286, MSE: 0.5320111, 2.6s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.3607807, MSE: 0.55162174, 2.6s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.3379619, MSE: 0.5375566, 2.7s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.3539066, MSE: 0.56220835, 2.9s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.3485719, MSE: 0.5655218, 2.6s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.3480656, MSE: 0.573693, 2.7s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.3446922, MSE: 0.57897854, 2.6s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.323142, MSE: 0.56594706, 2.6s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.3026595, MSE: 0.5538598, 2.7s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.2955995, MSE: 0.5550595, 2.8s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.3634013, MSE: 0.6311421, 2.7s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.2987554, MSE: 0.57458085, 2.8s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.2609698, MSE: 0.54477155, 2.6s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.2782545, MSE: 0.56984794, 2.2s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.25567, MSE: 0.5545849, 2.5s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.2002664, MSE: 0.5058427, 2.6s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.1921813, MSE: 0.50392526, 2.6s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.1872542, MSE: 0.5047877, 2.5s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.197158, MSE: 0.52017283, 2.5s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.1895227, MSE: 0.51795125, 2.6s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.1905739, MSE: 0.5245578, 10.3s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.1954135, MSE: 0.53508586, 2.6s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.1634715, MSE: 0.5088719, 2.7s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.1926883, MSE: 0.54375863, 2.6s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.1734396, MSE: 0.5301648, 2.6s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.2043397, MSE: 0.56685454, 2.6s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.2255225, MSE: 0.5938016, 2.7s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.2078941, MSE: 0.58190894, 2.9s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.1812212, MSE: 0.5608473, 2.7s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.1656072, MSE: 0.5506987, 2.8s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.1345477, MSE: 0.52498853, 2.6s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 1.179864, MSE: 0.575415, 2.2s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 1.0704876, MSE: 0.47065884, 2.6s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 1.0815179, MSE: 0.4856993, 2.6s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 1.1265631, MSE: 0.5343004, 2.6s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 1.0824854, MSE: 0.49355507, 2.6s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 1.0891957, MSE: 0.5036121, 2.6s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 1.0975515, MSE: 0.5153251, 2.8s used\n",
      "Epoch 1/8, Iter 1/18, loss value: 4.4733925, MSE: 1.3084055, 1053.5s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.324956, MSE: 1.169498, 3.0s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.233848, MSE: 1.0940989, 2.6s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.147298, MSE: 1.0315093, 2.8s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 4.0631886, MSE: 0.97917116, 2.9s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 4.088868, MSE: 1.0436122, 2.7s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 3.9971528, MSE: 0.99647003, 2.8s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.8842149, MSE: 0.93316203, 2.6s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.832489, MSE: 0.9353193, 10.2s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.8801222, MSE: 1.0402285, 3.0s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.7393322, MSE: 0.9593242, 2.6s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.6608067, MSE: 0.9427666, 2.5s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.4703143, MSE: 0.8155121, 2.6s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.521115, MSE: 0.9303265, 2.6s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.3929448, MSE: 0.8663448, 2.7s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.3359122, MSE: 0.87312734, 2.7s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.2295141, MSE: 0.829666, 2.6s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.0882, MSE: 0.7501935, 2.2s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 3.0506372, MSE: 0.77234375, 2.6s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 3.0140896, MSE: 0.7936764, 2.6s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 2.9997501, MSE: 0.8350891, 2.6s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.872949, MSE: 0.76188177, 2.6s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.8630006, MSE: 0.8032145, 2.6s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.75155, MSE: 0.7406771, 2.6s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.7199936, MSE: 0.7557501, 2.6s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.6490686, MSE: 0.729166, 2.6s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.5814288, MSE: 0.70390373, 2.6s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.596298, MSE: 0.75929546, 2.6s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.5145457, MSE: 0.71634954, 2.6s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.4995756, MSE: 0.73856175, 2.6s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.496444, MSE: 0.77116203, 2.6s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.38786, MSE: 0.69711864, 2.5s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.4273386, MSE: 0.7702557, 2.6s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.3285313, MSE: 0.7043096, 2.6s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.222463, MSE: 0.6304011, 2.6s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.29968, MSE: 0.73914295, 2.2s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.190353, MSE: 0.6603154, 2.6s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.1601148, MSE: 0.65975666, 10.4s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 2.109356, MSE: 0.6378339, 2.6s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 2.1279995, MSE: 0.68451625, 2.7s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 2.0662537, MSE: 0.6501968, 2.7s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 1.9808271, MSE: 0.591594, 2.6s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 2.032432, MSE: 0.6694319, 2.6s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 1.9893743, MSE: 0.65186024, 2.6s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 1.9380121, MSE: 0.6253224, 2.6s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 1.8670928, MSE: 0.5786138, 2.6s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 1.9479465, MSE: 0.68302697, 2.6s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.9121422, MSE: 0.6701176, 2.6s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.8340007, MSE: 0.61412656, 2.6s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.8461428, MSE: 0.6478291, 2.6s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.8050303, MSE: 0.6277227, 2.6s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.8544996, MSE: 0.6978579, 2.6s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.7418046, MSE: 0.6052697, 2.5s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.6901519, MSE: 0.5731061, 2.2s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.6599041, MSE: 0.5616119, 2.6s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.6724218, MSE: 0.59204614, 2.7s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.6709048, MSE: 0.6077579, 2.7s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.6362444, MSE: 0.58967674, 2.7s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.6199805, MSE: 0.5893997, 2.6s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.5723534, MSE: 0.5573831, 2.6s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.5488672, MSE: 0.54917157, 2.6s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.5610807, MSE: 0.5762225, 2.6s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.6096488, MSE: 0.6393389, 2.6s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.536556, MSE: 0.5805196, 2.6s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.5348446, MSE: 0.5927012, 2.6s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.5376369, MSE: 0.6090605, 2.6s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.5282351, MSE: 0.6130033, 2.6s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.5386971, MSE: 0.63658965, 10.3s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.4735293, MSE: 0.5843063, 2.6s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.4581926, MSE: 0.5815511, 2.7s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.4265068, MSE: 0.5621558, 2.7s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.4080737, MSE: 0.55568737, 2.2s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.3883408, MSE: 0.5471952, 2.6s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.3983505, MSE: 0.5677196, 2.6s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.4064579, MSE: 0.58580124, 2.7s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.3323351, MSE: 0.5210192, 2.6s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.3354934, MSE: 0.533054, 2.6s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.337369, MSE: 0.5436465, 2.6s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.3390415, MSE: 0.5538933, 2.6s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.3308872, MSE: 0.5542173, 2.6s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.3389249, MSE: 0.57059044, 2.7s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.3225965, MSE: 0.56240225, 2.6s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.3331518, MSE: 0.5809337, 2.6s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.3272012, MSE: 0.5829736, 2.6s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.3396156, MSE: 0.603407, 2.6s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.3371346, MSE: 0.6089213, 2.6s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.2943377, MSE: 0.5740559, 2.6s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.2788748, MSE: 0.56637967, 2.6s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.2457376, MSE: 0.5408434, 2.6s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.1660308, MSE: 0.46851498, 2.2s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.2552811, MSE: 0.5647115, 2.5s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.2264768, MSE: 0.54219764, 2.5s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.1884475, MSE: 0.50992763, 2.6s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.2104776, MSE: 0.537411, 2.7s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.2142241, MSE: 0.5465063, 2.8s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.1854749, MSE: 0.5231795, 2.7s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.1596777, MSE: 0.5027797, 10.9s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.2052367, MSE: 0.55363476, 2.6s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.188303, MSE: 0.54191434, 2.6s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.1786886, MSE: 0.5374367, 2.6s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.1694725, MSE: 0.5335954, 2.6s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.1618001, MSE: 0.5313578, 2.6s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.1946516, MSE: 0.56957453, 2.6s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.1873308, MSE: 0.5675744, 2.6s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.1714976, MSE: 0.556904, 3.0s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.1815118, MSE: 0.5719667, 2.7s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.149122, MSE: 0.5445307, 2.8s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 1.1338248, MSE: 0.53399384, 2.2s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 1.0856209, MSE: 0.4900696, 2.6s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 1.1064436, MSE: 0.51467973, 2.7s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 1.0949905, MSE: 0.5067591, 2.6s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 1.0839916, MSE: 0.49912816, 2.7s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 1.0577179, MSE: 0.47609872, 2.7s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 1.0699558, MSE: 0.49156386, 2.6s used\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Iter 1/18, loss value: 4.6246357, MSE: 1.4580828, 1054.8s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.2339854, MSE: 1.0762486, 3.0s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.229539, MSE: 1.0870402, 2.6s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.282226, MSE: 1.1627773, 2.6s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 4.1587014, MSE: 1.0695018, 2.6s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 4.1173706, MSE: 1.0645784, 2.8s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 3.9840994, MSE: 0.9730989, 2.6s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.9811893, MSE: 1.016739, 2.6s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.8781326, MSE: 0.96421176, 10.1s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.8373983, MSE: 0.9773629, 2.7s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.7568467, MSE: 0.9533045, 2.6s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.6716185, MSE: 0.926437, 2.9s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.5780644, MSE: 0.8925067, 2.6s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.5383441, MSE: 0.91309875, 2.7s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.4386172, MSE: 0.87380433, 2.6s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.3911178, MSE: 0.8864696, 2.9s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.2523556, MSE: 0.8072768, 2.7s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.3028235, MSE: 0.9162703, 2.4s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 3.1180568, MSE: 0.78795475, 2.6s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 3.0120966, MSE: 0.73676515, 2.6s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 3.0306244, MSE: 0.80824685, 2.9s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.9257562, MSE: 0.7543795, 2.6s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.9024634, MSE: 0.7800685, 2.6s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.8236809, MSE: 0.748255, 2.6s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.6982594, MSE: 0.6678166, 2.6s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.7409878, MSE: 0.75362074, 2.6s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.6889086, MSE: 0.7428116, 2.6s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.6299262, MSE: 0.7234386, 2.6s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.576179, MSE: 0.7077977, 2.6s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.6427069, MSE: 0.8110537, 2.6s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.5534415, MSE: 0.7572613, 2.6s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.517248, MSE: 0.75553286, 2.5s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.5147266, MSE: 0.7866759, 2.6s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.4629412, MSE: 0.7677837, 2.6s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.3616574, MSE: 0.69865406, 2.6s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.27234, MSE: 0.6408044, 2.2s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.2853808, MSE: 0.6843239, 2.6s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.2034147, MSE: 0.63193554, 10.6s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 2.1737833, MSE: 0.631003, 2.6s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 2.1708653, MSE: 0.6561394, 2.6s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 2.1392398, MSE: 0.652017, 2.6s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 2.0683012, MSE: 0.60807836, 2.6s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 2.0855734, MSE: 0.6518276, 2.6s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 2.0630188, MSE: 0.6552582, 2.6s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 2.073739, MSE: 0.6913226, 2.6s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 2.0065258, MSE: 0.64873475, 2.6s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 2.0016463, MSE: 0.66784006, 2.6s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.94416, MSE: 0.6337748, 2.6s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.9681324, MSE: 0.68064857, 2.6s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.8857076, MSE: 0.6206016, 2.6s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.9023272, MSE: 0.65900683, 2.7s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.898603, MSE: 0.6764074, 2.6s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.8507991, MSE: 0.64913976, 2.6s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.7633768, MSE: 0.581674, 2.2s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.7514032, MSE: 0.5887337, 2.6s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.7364175, MSE: 0.59214395, 2.6s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.6820457, MSE: 0.5554798, 2.6s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.7136905, MSE: 0.60421616, 2.6s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.7146657, MSE: 0.6217099, 2.6s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.646802, MSE: 0.5698132, 2.6s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.7245721, MSE: 0.6631855, 2.6s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.6885469, MSE: 0.64241195, 2.6s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.6049023, MSE: 0.57365066, 2.6s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.6443579, MSE: 0.6276941, 2.6s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.5785692, MSE: 0.5762547, 2.6s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.5720719, MSE: 0.5838857, 2.6s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.6171674, MSE: 0.64283836, 2.6s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.6143093, MSE: 0.6536342, 10.4s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.5389524, MSE: 0.59163505, 2.6s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.5732553, MSE: 0.639017, 2.6s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.5031005, MSE: 0.5816979, 2.6s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.4677678, MSE: 0.55885446, 2.2s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.4558661, MSE: 0.55877376, 2.6s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.4546391, MSE: 0.5686955, 2.6s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.4230852, MSE: 0.5477908, 2.7s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.4258919, MSE: 0.5606738, 2.6s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.3946849, MSE: 0.5391556, 2.6s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.4257729, MSE: 0.57972074, 2.6s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.3449237, MSE: 0.5080299, 2.6s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.4203639, MSE: 0.59247667, 2.6s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.4011698, MSE: 0.58230835, 2.6s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.3972186, MSE: 0.5873869, 2.6s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.3534749, MSE: 0.5525811, 2.6s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.3563209, MSE: 0.56434065, 2.6s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.4126561, MSE: 0.629459, 2.6s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.3820527, MSE: 0.60746676, 2.6s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.3627043, MSE: 0.5966216, 2.6s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.4138122, MSE: 0.65604985, 2.7s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.3421695, MSE: 0.59275824, 2.7s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.250896, MSE: 0.50968516, 2.3s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.2692597, MSE: 0.5356782, 2.6s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.2490185, MSE: 0.5224057, 2.7s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.2701005, MSE: 0.5500392, 2.6s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.2573669, MSE: 0.5434642, 2.6s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.2557899, MSE: 0.5477324, 2.6s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.2523522, MSE: 0.5500165, 2.6s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.2476019, MSE: 0.5510693, 10.2s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.2363894, MSE: 0.5457839, 2.6s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.2225156, MSE: 0.5377427, 2.6s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.2244037, MSE: 0.5453423, 2.6s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.2406101, MSE: 0.56722504, 2.6s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.2781904, MSE: 0.61048865, 2.6s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.2337079, MSE: 0.57154185, 2.7s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.249697, MSE: 0.59304, 2.7s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.1952341, MSE: 0.54409385, 2.6s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.1993893, MSE: 0.5537528, 2.6s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.176091, MSE: 0.5359479, 2.7s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 1.1366434, MSE: 0.501959, 2.3s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 1.1309228, MSE: 0.5012914, 2.6s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 1.137242, MSE: 0.51219183, 2.6s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 1.1350312, MSE: 0.51416886, 2.6s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 1.1395409, MSE: 0.5225924, 2.6s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 1.1294388, MSE: 0.51648206, 2.7s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 1.0859206, MSE: 0.47691897, 2.6s used\n",
      "Epoch 1/8, Iter 1/18, loss value: 4.5610714, MSE: 1.3937308, 1053.3s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.3125563, MSE: 1.1541697, 3.0s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.191841, MSE: 1.0479823, 2.7s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.188324, MSE: 1.0669194, 2.7s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 4.0805287, MSE: 0.988898, 2.6s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 4.093155, MSE: 1.0375649, 2.9s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 3.9193418, MSE: 0.90528387, 2.7s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.905208, MSE: 0.93735886, 2.6s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.8833604, MSE: 0.9657409, 10.2s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.865993, MSE: 1.0017534, 2.9s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.6576054, MSE: 0.8491137, 2.6s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.6306, MSE: 0.8799222, 2.6s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.5999484, MSE: 0.908482, 2.5s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.4313676, MSE: 0.7998871, 2.8s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.4473996, MSE: 0.87625396, 2.5s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.311111, MSE: 0.79991543, 2.6s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.2602098, MSE: 0.808314, 2.7s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.244139, MSE: 0.85041934, 2.2s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 3.1036339, MSE: 0.76595724, 2.6s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 3.000165, MSE: 0.71688396, 2.7s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 2.9974542, MSE: 0.7668502, 2.7s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.9171996, MSE: 0.73736656, 2.9s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.8637748, MSE: 0.73268276, 2.7s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.7448702, MSE: 0.6605424, 2.8s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.7594848, MSE: 0.7200061, 2.6s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.7322092, MSE: 0.7356472, 2.6s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.6946883, MSE: 0.7392473, 2.6s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.6074533, MSE: 0.6915025, 2.6s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.5733929, MSE: 0.6954581, 2.6s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.549631, MSE: 0.7084018, 2.6s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.4853067, MSE: 0.6796674, 2.6s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.4752636, MSE: 0.7041684, 2.6s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.41752, MSE: 0.6801089, 2.6s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.394964, MSE: 0.6904939, 2.6s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.3364384, MSE: 0.6642602, 2.6s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.354619, MSE: 0.7139982, 2.4s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.1849866, MSE: 0.57483715, 2.8s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.1864636, MSE: 0.60597754, 10.6s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 2.1441665, MSE: 0.59270203, 2.6s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 2.1177974, MSE: 0.5947782, 2.6s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 2.0857234, MSE: 0.59058744, 2.6s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 2.0376618, MSE: 0.56987774, 2.6s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 2.0370166, MSE: 0.5960354, 2.6s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 2.0608878, MSE: 0.64611584, 2.7s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 1.9779651, MSE: 0.5887717, 2.6s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 2.0044591, MSE: 0.64034146, 2.6s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 1.9981658, MSE: 0.6584726, 2.6s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.9120953, MSE: 0.59606224, 2.6s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.9469917, MSE: 0.6539653, 2.6s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.9197007, MSE: 0.64902484, 2.6s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.8795371, MSE: 0.6306536, 2.7s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.8796544, MSE: 0.6520568, 2.7s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.7981108, MSE: 0.5912756, 2.6s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.763481, MSE: 0.5768405, 2.2s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.7373173, MSE: 0.5698766, 2.6s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.7417743, MSE: 0.59278274, 2.7s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.7160112, MSE: 0.58482397, 2.6s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.6713212, MSE: 0.5574459, 2.5s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.6225951, MSE: 0.5256218, 2.5s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.6541342, MSE: 0.57366884, 2.5s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.6615062, MSE: 0.59716296, 2.5s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.639466, MSE: 0.5908152, 2.6s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.6482701, MSE: 0.61507094, 2.6s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.5673095, MSE: 0.5491816, 2.5s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.548703, MSE: 0.5452836, 2.6s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.5296601, MSE: 0.54063255, 2.6s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.5562156, MSE: 0.5813046, 2.6s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.5224862, MSE: 0.56140363, 10.7s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.5133209, MSE: 0.56588024, 3.0s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.507168, MSE: 0.57309794, 2.7s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.4372165, MSE: 0.51634955, 2.6s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.4974399, MSE: 0.5893663, 2.2s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.4374182, MSE: 0.5415219, 2.6s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.3623523, MSE: 0.47792223, 2.6s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.3882669, MSE: 0.5146946, 2.5s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.4084656, MSE: 0.545321, 2.6s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.4015744, MSE: 0.54849213, 2.6s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.4035952, MSE: 0.560178, 2.6s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.4125235, MSE: 0.57859606, 2.6s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.3335385, MSE: 0.5089322, 2.6s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.381106, MSE: 0.5655736, 2.5s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.3647411, MSE: 0.5580465, 2.6s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.3420519, MSE: 0.544097, 2.7s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.3627605, MSE: 0.5734108, 2.7s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.3228974, MSE: 0.54209054, 2.6s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.3445479, MSE: 0.57226545, 2.9s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.3420055, MSE: 0.5781335, 2.7s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.3062501, MSE: 0.5506672, 2.7s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.3165036, MSE: 0.56903166, 2.6s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.1770097, MSE: 0.43762812, 2.2s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.2272255, MSE: 0.49546856, 2.6s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.2282603, MSE: 0.5036293, 2.6s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.258852, MSE: 0.5408386, 2.6s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.1715628, MSE: 0.45988795, 2.6s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.1989996, MSE: 0.49356392, 2.6s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.2236445, MSE: 0.5243206, 2.6s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.2254071, MSE: 0.53215814, 10.4s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.1912758, MSE: 0.50407636, 2.6s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.221731, MSE: 0.5406139, 2.6s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.2070363, MSE: 0.53193814, 2.8s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.2061224, MSE: 0.53692603, 2.6s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.2138357, MSE: 0.55046886, 2.8s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.1946119, MSE: 0.53708494, 2.6s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.198659, MSE: 0.546946, 2.6s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.1656594, MSE: 0.51970655, 2.7s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.2082529, MSE: 0.5679646, 2.6s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.170115, MSE: 0.53531396, 2.5s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 1.1254108, MSE: 0.49608162, 2.2s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 1.1250589, MSE: 0.5008964, 2.7s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 1.0826211, MSE: 0.46281287, 2.8s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 1.1105818, MSE: 0.4946613, 2.6s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 1.1250963, MSE: 0.5128174, 2.6s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 1.1071568, MSE: 0.49852258, 2.6s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 1.1230373, MSE: 0.518154, 2.6s used\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Iter 1/18, loss value: 4.6123724, MSE: 1.4413408, 1047.6s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.370403, MSE: 1.2080958, 3.9s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.2508507, MSE: 1.1028208, 2.7s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.1463, MSE: 1.0200665, 2.7s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 4.109345, MSE: 1.0119911, 2.7s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 4.0868244, MSE: 1.0246682, 2.7s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 4.015171, MSE: 0.99349856, 2.8s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.9891806, MSE: 1.0128301, 2.7s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.8320565, MSE: 0.9049974, 10.5s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.7885413, MSE: 0.9140512, 3.1s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.6923208, MSE: 0.8730167, 2.7s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.6974277, MSE: 0.93533367, 2.7s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.6200275, MSE: 0.9165202, 2.9s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.567079, MSE: 0.9230455, 2.7s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.4515686, MSE: 0.86733234, 2.8s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.3379154, MSE: 0.8133856, 2.7s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.295528, MSE: 0.83023524, 2.6s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.0977528, MSE: 0.6908179, 2.3s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 3.144508, MSE: 0.7942614, 2.7s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 3.089357, MSE: 0.7942928, 2.9s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 2.9967208, MSE: 0.75516665, 2.7s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.9584517, MSE: 0.7685548, 2.6s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.8510995, MSE: 0.7108625, 2.6s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.7846785, MSE: 0.6920739, 2.7s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.7605033, MSE: 0.7136269, 2.7s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.7438226, MSE: 0.7408138, 2.7s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.7071521, MSE: 0.74619454, 2.6s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.5941894, MSE: 0.67359436, 2.7s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.5441298, MSE: 0.662418, 2.6s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.58398, MSE: 0.7396933, 2.8s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.5319438, MSE: 0.7238687, 2.8s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.4822545, MSE: 0.70925814, 2.7s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.4896817, MSE: 0.75073427, 2.7s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.429635, MSE: 0.7238846, 2.7s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.337357, MSE: 0.66408646, 2.7s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.2490053, MSE: 0.6074922, 2.4s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.2710912, MSE: 0.6604554, 2.6s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.1873088, MSE: 0.60673344, 10.5s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 2.2000606, MSE: 0.6488877, 2.6s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 2.1342568, MSE: 0.61173606, 2.8s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 2.1292176, MSE: 0.63471454, 2.8s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 2.1064253, MSE: 0.6394344, 2.6s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 2.0799675, MSE: 0.6399317, 2.7s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 1.9961872, MSE: 0.58246315, 2.6s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 1.9932439, MSE: 0.6052824, 2.7s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 2.059717, MSE: 0.69704825, 2.8s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 1.9670948, MSE: 0.62900424, 2.6s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.9623098, MSE: 0.64816767, 2.6s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.9107956, MSE: 0.62002254, 2.6s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.8851104, MSE: 0.61707807, 2.6s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.8731265, MSE: 0.62722945, 2.6s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.8573655, MSE: 0.6330433, 2.7s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.8683934, MSE: 0.6651113, 2.6s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.664716, MSE: 0.4818443, 2.3s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.7431898, MSE: 0.5799251, 2.8s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.7071083, MSE: 0.5627609, 2.7s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.6580677, MSE: 0.5320842, 2.7s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.6778445, MSE: 0.5696992, 2.6s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.6501338, MSE: 0.5593771, 2.7s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.6510655, MSE: 0.5772362, 2.8s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.6452454, MSE: 0.58790874, 2.7s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.5716933, MSE: 0.5304259, 2.6s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.6271412, MSE: 0.60157263, 2.7s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.586037, MSE: 0.57581866, 2.8s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.5673914, MSE: 0.572188, 2.6s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.5722767, MSE: 0.5917355, 2.6s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.5951574, MSE: 0.6289435, 2.6s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.5624399, MSE: 0.6103257, 10.6s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.5476291, MSE: 0.6092655, 2.6s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.5395281, MSE: 0.6145986, 2.6s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.5187343, MSE: 0.6069658, 2.7s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.4709806, MSE: 0.57194936, 2.3s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.4263618, MSE: 0.5394044, 2.7s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.4145854, MSE: 0.5390891, 2.9s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.400806, MSE: 0.5361792, 2.6s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.4149959, MSE: 0.5608633, 2.6s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.3915867, MSE: 0.54769707, 2.7s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.3573081, MSE: 0.52342856, 2.8s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.3752396, MSE: 0.5512222, 2.7s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.3184936, MSE: 0.5041163, 2.6s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.3653467, MSE: 0.5604338, 2.7s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.3484192, MSE: 0.5528279, 2.6s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.367941, MSE: 0.58153677, 2.6s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.3373468, MSE: 0.56006294, 2.6s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.378178, MSE: 0.60987586, 2.7s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.322223, MSE: 0.56263894, 2.6s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.3423011, MSE: 0.5911757, 2.6s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.3449026, MSE: 0.60214067, 2.6s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.304435, MSE: 0.56992716, 2.6s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.3377745, MSE: 0.61113536, 2.2s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.2221625, MSE: 0.50270903, 2.6s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.2588015, MSE: 0.54581016, 2.6s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.2775263, MSE: 0.5706059, 2.6s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.243824, MSE: 0.54263777, 2.9s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.2195263, MSE: 0.52392495, 2.7s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.2060226, MSE: 0.51596254, 2.7s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.2663326, MSE: 0.58181137, 10.8s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.248553, MSE: 0.56962705, 2.8s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.2229385, MSE: 0.5497011, 2.7s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.1845185, MSE: 0.51691186, 2.6s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.2039237, MSE: 0.5418968, 2.6s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.2164725, MSE: 0.56000555, 2.6s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.2301015, MSE: 0.57925963, 2.7s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.225133, MSE: 0.5797981, 2.6s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.200218, MSE: 0.5603056, 2.6s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.2077427, MSE: 0.57322764, 2.7s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.1247559, MSE: 0.495683, 2.6s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 1.1188523, MSE: 0.49517134, 2.3s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 1.0982507, MSE: 0.47963566, 2.6s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 1.1122328, MSE: 0.4981818, 2.7s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 1.0882701, MSE: 0.4784827, 2.8s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 1.1787536, MSE: 0.57307714, 2.9s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 1.1174453, MSE: 0.5157939, 2.6s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 1.0908514, MSE: 0.4932211, 2.8s used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 23:24:37.747916: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:24:38.490988: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:24:40.610295: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:24:41.079888: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:24:46.821561: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:24:46.840109: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:24:48.915523: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:24:54.317340: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Iter 1/18, loss value: 4.3006854, MSE: 1.1371596, 1076.3s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.25912, MSE: 1.1065183, 3.6s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.2033434, MSE: 1.0684257, 2.7s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.1872926, MSE: 1.0788678, 2.8s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 4.0557055, MSE: 0.9816824, 2.7s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 4.0589094, MSE: 1.0264392, 2.6s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 3.9502406, MSE: 0.96558297, 2.9s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.848658, MSE: 0.917169, 2.6s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.8486457, MSE: 0.9748124, 10.4s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.721711, MSE: 0.9090821, 2.6s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.7457132, MSE: 0.9970963, 2.8s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.5658906, MSE: 0.8832085, 2.6s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.4744213, MSE: 0.85906, 2.6s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.463739, MSE: 0.9164219, 2.6s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.3558154, MSE: 0.8766466, 2.6s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.2823029, MSE: 0.8707805, 2.7s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.196506, MSE: 0.8516425, 2.6s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.0564628, MSE: 0.77695817, 2.3s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 2.9983878, MSE: 0.78154844, 2.6s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 2.9324641, MSE: 0.77615505, 2.7s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 2.901652, MSE: 0.8035567, 2.6s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.8306649, MSE: 0.78824466, 2.6s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.8025393, MSE: 0.81321895, 2.7s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.6423178, MSE: 0.7034833, 2.6s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.6442046, MSE: 0.75329435, 2.6s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.6164403, MSE: 0.7708391, 2.6s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.5693364, MSE: 0.7666538, 2.5s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.4708042, MSE: 0.7087829, 2.5s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.4335651, MSE: 0.7103231, 2.8s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.4038627, MSE: 0.7178654, 2.7s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.3660398, MSE: 0.7158891, 2.6s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.3391142, MSE: 0.72348106, 2.6s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.3184776, MSE: 0.7363465, 2.6s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.2954626, MSE: 0.74607235, 2.6s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.2037492, MSE: 0.6863922, 2.5s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.1536074, MSE: 0.667587, 2.2s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.0355844, MSE: 0.5798633, 2.6s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.089902, MSE: 0.6638105, 10.5s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 2.0185988, MSE: 0.62145776, 2.6s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 2.0471342, MSE: 0.67813736, 2.6s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 2.0003335, MSE: 0.65865105, 2.6s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 1.9654086, MSE: 0.65029055, 2.6s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 1.9570538, MSE: 0.6678152, 2.7s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 1.88736, MSE: 0.62325156, 2.7s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 1.8881779, MSE: 0.64858174, 2.6s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 1.8741107, MSE: 0.65842307, 2.6s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 1.8565669, MSE: 0.664084, 2.6s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.8242607, MSE: 0.6543798, 2.6s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.789413, MSE: 0.64139086, 2.6s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.7944055, MSE: 0.6676786, 2.6s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.7642658, MSE: 0.65826565, 2.6s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.7673255, MSE: 0.68151534, 2.6s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.6528581, MSE: 0.5868832, 2.6s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.5706944, MSE: 0.52406186, 2.2s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.5944536, MSE: 0.5663, 2.6s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.6267936, MSE: 0.6163202, 2.6s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.5698774, MSE: 0.5765518, 2.6s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.5536082, MSE: 0.5767876, 2.6s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.5696245, MSE: 0.60858256, 2.5s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.5443571, MSE: 0.5985144, 2.5s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.511461, MSE: 0.5803871, 2.6s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.5047729, MSE: 0.58815503, 2.5s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.4734654, MSE: 0.57100177, 2.6s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.4670236, MSE: 0.57837754, 2.6s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.4648626, MSE: 0.5897242, 2.5s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.4838836, MSE: 0.62197244, 2.6s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.4648464, MSE: 0.6159059, 2.6s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.4180005, MSE: 0.58165234, 10.7s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.5095065, MSE: 0.685471, 2.8s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.4711057, MSE: 0.65898746, 2.6s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.3731154, MSE: 0.5725888, 2.6s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.3535423, MSE: 0.56425834, 2.2s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.3335986, MSE: 0.5547699, 2.6s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.322824, MSE: 0.5537725, 2.7s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.3273449, MSE: 0.5676141, 2.6s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.2742162, MSE: 0.52325845, 2.6s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.2780015, MSE: 0.5354088, 2.6s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.2858557, MSE: 0.55140024, 2.6s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.2969043, MSE: 0.5703784, 2.6s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.2986349, MSE: 0.58001333, 2.6s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.2649794, MSE: 0.55417943, 2.5s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.2872386, MSE: 0.58416593, 2.6s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.3352163, MSE: 0.63969314, 2.6s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.2584168, MSE: 0.5704041, 2.6s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.2412798, MSE: 0.5607667, 2.5s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.225566, MSE: 0.55243486, 2.5s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.2684324, MSE: 0.6024866, 2.5s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.2702022, MSE: 0.61136645, 2.5s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.2076557, MSE: 0.5556251, 2.6s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.1691341, MSE: 0.5236521, 2.2s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.1636486, MSE: 0.52415264, 2.6s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.1294503, MSE: 0.49540564, 2.9s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.1487422, MSE: 0.519702, 2.6s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.1310275, MSE: 0.50657856, 2.7s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.164408, MSE: 0.54447556, 2.7s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.1438828, MSE: 0.5284883, 2.6s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.1289254, MSE: 0.51812565, 10.4s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.1865232, MSE: 0.58047366, 2.6s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.1661557, MSE: 0.5648568, 2.6s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.1336503, MSE: 0.5370964, 2.6s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.1381639, MSE: 0.5462709, 2.6s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.1333628, MSE: 0.54614997, 2.6s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.1274545, MSE: 0.5449796, 2.6s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.1181377, MSE: 0.5402711, 2.6s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.1355977, MSE: 0.5623163, 2.6s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.1150758, MSE: 0.5465571, 2.6s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.0766711, MSE: 0.5128609, 2.6s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 1.0799527, MSE: 0.5206681, 2.5s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 1.0348208, MSE: 0.47951248, 2.7s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 1.0062555, MSE: 0.45427033, 2.8s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 1.0369436, MSE: 0.48815483, 2.6s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 1.0441297, MSE: 0.49838874, 2.6s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 1.0083438, MSE: 0.4657029, 2.6s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 1.0530162, MSE: 0.5135945, 2.5s used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 23:25:16.821736: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:25:18.662501: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:25:24.762485: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:25:33.146005: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:25:34.696827: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:25:38.325425: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:25:41.325338: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:25:43.329912: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:25:59.258122: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x1538b2c2df70> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x1538b2c2df70>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8, Iter 7/18, loss value: 1.1106126, MSE: 0.5374969, 2.6s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 1.0696225, MSE: 0.5001074, 2.7s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 1.1042776, MSE: 0.5385371, 2.7s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 1.056921, MSE: 0.4949379, 2.7s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 1.0651462, MSE: 0.50688255, 2.6s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 1.0916783, MSE: 0.537137, 2.6s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 1.0640256, MSE: 0.5131632, 2.7s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 1.0723088, MSE: 0.5251192, 2.8s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 1.1069504, MSE: 0.5634606, 2.7s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 1.1029556, MSE: 0.5632012, 2.7s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 1.0664632, MSE: 0.53044695, 2.7s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 1.0686867, MSE: 0.53627294, 2.2s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 1.002776, MSE: 0.47342396, 9.8s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 1.0172237, MSE: 0.49030605, 2.6s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 1.0104569, MSE: 0.48583773, 2.6s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 1.0178897, MSE: 0.49545762, 2.6s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 0.9972515, MSE: 0.47703233, 2.6s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 1.0213718, MSE: 0.5035833, 2.6s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 0.96537995, MSE: 0.45009688, 2.6s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 1.0109973, MSE: 0.49818766, 2.6s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 1.0350914, MSE: 0.5248877, 2.7s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 0.9893195, MSE: 0.48184204, 2.7s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 1.0180793, MSE: 0.5133982, 2.6s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 1.0271177, MSE: 0.52514493, 2.6s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 1.0062807, MSE: 0.5070054, 2.6s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 1.024069, MSE: 0.5275796, 2.7s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 1.0453483, MSE: 0.5515755, 2.6s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 0.97594786, MSE: 0.48482403, 2.6s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 0.9634265, MSE: 0.47482476, 2.7s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 0.96576, MSE: 0.4796912, 2.3s used\n",
      "Saving models ... Mon Dec 12 23:25:48 2022\n",
      "Preparing features ... Mon Dec 12 23:26:20 2022\n",
      "Setting up models...Mon Dec 12 23:26:22 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x14c8a002df70> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x14c8a002df70>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8, Iter 7/18, loss value: 1.0478578, MSE: 0.5186862, 2.6s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 1.0423846, MSE: 0.5165964, 2.6s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 1.017904, MSE: 0.49551052, 2.6s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 1.0415945, MSE: 0.52275366, 2.6s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 1.0525043, MSE: 0.5371593, 2.6s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 1.0480081, MSE: 0.5360628, 2.7s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 1.0502211, MSE: 0.54170465, 2.6s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 1.0300539, MSE: 0.5250534, 2.6s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 1.0803468, MSE: 0.5789454, 2.7s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 1.0067198, MSE: 0.5088686, 2.6s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 1.0186666, MSE: 0.5243197, 2.6s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 0.9470042, MSE: 0.45626196, 2.2s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 0.9720061, MSE: 0.484427, 10.2s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 0.98105454, MSE: 0.4961961, 2.6s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 0.94780684, MSE: 0.46555132, 2.7s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 0.9789914, MSE: 0.49925184, 2.6s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 0.941537, MSE: 0.46419096, 2.6s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 0.974118, MSE: 0.49926966, 2.6s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 0.96476537, MSE: 0.4925099, 2.7s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 0.9735701, MSE: 0.503898, 2.7s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 0.96184886, MSE: 0.49479806, 2.6s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 0.95277464, MSE: 0.48842818, 2.6s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 0.9725424, MSE: 0.51102537, 2.6s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 0.9728166, MSE: 0.5140451, 2.9s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 0.94845366, MSE: 0.49232525, 2.6s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 0.9552586, MSE: 0.50196034, 2.7s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 0.95425755, MSE: 0.50374246, 2.6s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 0.9637536, MSE: 0.5158829, 2.6s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 0.96646535, MSE: 0.52124125, 2.7s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 0.856687, MSE: 0.41404894, 2.3s used\n",
      "Saving models ... Mon Dec 12 23:25:46 2022\n",
      "Preparing features ... Mon Dec 12 23:26:18 2022\n",
      "Setting up models...Mon Dec 12 23:26:20 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x14e1fddedf70> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x14e1fddedf70>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8, Iter 7/18, loss value: 1.0554409, MSE: 0.48342186, 2.7s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 1.0680401, MSE: 0.50002223, 2.7s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 1.0957711, MSE: 0.53179157, 2.7s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 1.0749576, MSE: 0.5148438, 2.7s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 1.0678911, MSE: 0.5116469, 2.6s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 1.062738, MSE: 0.5103931, 2.6s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 1.1086168, MSE: 0.5601523, 2.6s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 1.0865281, MSE: 0.54197747, 2.6s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 1.0808072, MSE: 0.5401462, 2.6s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 1.0487216, MSE: 0.5120148, 2.6s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 1.0299405, MSE: 0.49728295, 2.6s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 0.9397259, MSE: 0.41097638, 2.3s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 1.0086913, MSE: 0.48353118, 10.1s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 0.9797433, MSE: 0.4576391, 2.6s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 0.9639653, MSE: 0.44468787, 2.6s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 0.9662784, MSE: 0.4497977, 2.6s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 0.99365604, MSE: 0.4799248, 2.7s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 0.98999846, MSE: 0.4790295, 2.7s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 0.9873454, MSE: 0.4791997, 2.7s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 0.99216926, MSE: 0.4869145, 2.8s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 0.9822394, MSE: 0.4799394, 2.6s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 0.98628426, MSE: 0.48701066, 2.6s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 1.0161579, MSE: 0.5199281, 2.6s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 0.99782485, MSE: 0.50455666, 2.6s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 0.97165495, MSE: 0.48129737, 2.6s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 0.99412864, MSE: 0.50664, 2.6s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 1.0108043, MSE: 0.5261255, 2.6s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 0.98639655, MSE: 0.5045482, 2.6s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 0.9477668, MSE: 0.46872133, 2.7s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 0.95704544, MSE: 0.48075625, 2.3s used\n",
      "Saving models ... Mon Dec 12 23:25:49 2022\n",
      "Preparing features ... Mon Dec 12 23:26:21 2022\n",
      "Setting up models...Mon Dec 12 23:26:23 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x14a025f0d040> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x14a025f0d040>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8, Iter 7/18, loss value: 1.1053123, MSE: 0.5006995, 2.6s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 1.1143706, MSE: 0.5137028, 2.6s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 1.0915387, MSE: 0.4948905, 2.6s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 1.0733677, MSE: 0.48078015, 2.6s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 1.0926514, MSE: 0.5042397, 2.6s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 1.1219416, MSE: 0.5377645, 2.8s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 1.1078737, MSE: 0.5278715, 2.6s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 1.0670085, MSE: 0.49108478, 2.7s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 1.1053133, MSE: 0.5333822, 2.6s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 1.1058803, MSE: 0.5380063, 2.6s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 1.0923676, MSE: 0.52849984, 2.6s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 1.0452454, MSE: 0.48516446, 2.3s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 1.0165886, MSE: 0.45958978, 10.4s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 1.019143, MSE: 0.46480224, 2.6s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 1.0129509, MSE: 0.46106288, 2.7s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 1.0295789, MSE: 0.47998953, 2.7s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 1.0137691, MSE: 0.46656638, 2.6s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 1.0018282, MSE: 0.45723024, 2.6s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 1.0211718, MSE: 0.4792693, 2.8s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 1.0244316, MSE: 0.48542073, 2.7s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 1.0406575, MSE: 0.5045895, 2.6s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 1.0171885, MSE: 0.48409602, 2.7s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 1.0284405, MSE: 0.49835393, 2.6s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 1.0639241, MSE: 0.53676903, 2.6s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 1.0572656, MSE: 0.5329742, 2.6s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 1.0499287, MSE: 0.5285234, 2.6s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 1.0236529, MSE: 0.50511706, 2.6s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 1.0640249, MSE: 0.5483107, 2.6s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 0.98820126, MSE: 0.4752973, 2.6s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 0.90187514, MSE: 0.39169496, 2.2s used\n",
      "Saving models ... Mon Dec 12 23:25:50 2022\n",
      "Preparing features ... Mon Dec 12 23:26:23 2022\n",
      "Setting up models...Mon Dec 12 23:26:25 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train.<locals>.train_step at 0x14c62274d040> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function train.<locals>.train_step at 0x14c62274d040>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8, Iter 7/18, loss value: 1.1128697, MSE: 0.50775963, 2.7s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 1.1027195, MSE: 0.50153655, 2.6s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 1.1327734, MSE: 0.53556067, 2.6s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 1.1174245, MSE: 0.52424234, 2.6s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 1.1253392, MSE: 0.53623015, 2.6s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 1.1330901, MSE: 0.5481699, 2.6s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 1.139719, MSE: 0.5588241, 2.6s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 1.1489086, MSE: 0.57197297, 2.7s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 1.1319456, MSE: 0.55895877, 2.7s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 1.1526527, MSE: 0.58360165, 2.6s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 1.0861232, MSE: 0.5210422, 2.6s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 1.0242641, MSE: 0.46294415, 2.2s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 1.0106239, MSE: 0.45250782, 10.1s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 1.036045, MSE: 0.48079202, 2.7s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 1.0708144, MSE: 0.51812184, 2.6s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 1.0398855, MSE: 0.48957312, 2.7s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 1.0233752, MSE: 0.47538635, 2.6s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 1.0677289, MSE: 0.522252, 2.6s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 1.0605233, MSE: 0.5179669, 2.6s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 1.0328702, MSE: 0.4931461, 2.6s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 1.0294577, MSE: 0.49257132, 2.6s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 1.0627699, MSE: 0.52877253, 2.7s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 1.0732234, MSE: 0.54209054, 2.6s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 1.0412872, MSE: 0.5130003, 2.7s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 1.040155, MSE: 0.514759, 2.8s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 1.0737678, MSE: 0.55126977, 2.6s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 1.0479269, MSE: 0.52825993, 2.6s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 1.0582404, MSE: 0.54140836, 2.6s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 0.9732344, MSE: 0.4592223, 2.6s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 0.89024276, MSE: 0.37891424, 2.3s used\n",
      "Saving models ... Mon Dec 12 23:25:56 2022\n",
      "Preparing features ... Mon Dec 12 23:26:28 2022\n",
      "Setting up models...Mon Dec 12 23:26:30 2022\n",
      "Epoch 7/8, Iter 7/18, loss value: 1.1161841, MSE: 0.541243, 2.6s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 1.0959165, MSE: 0.52463806, 2.6s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 1.074245, MSE: 0.506721, 2.6s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 1.0867171, MSE: 0.5228785, 2.6s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 1.0956395, MSE: 0.5354515, 2.6s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 1.0990498, MSE: 0.5425505, 2.6s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 1.0979578, MSE: 0.5450975, 2.6s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 1.0880209, MSE: 0.53892744, 2.7s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 1.0601473, MSE: 0.5147997, 2.9s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 1.1083555, MSE: 0.56673926, 2.7s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 1.0529925, MSE: 0.514974, 2.8s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 1.000102, MSE: 0.46543443, 2.2s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 1.0202963, MSE: 0.4884811, 10.4s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 1.022324, MSE: 0.49289063, 2.7s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 1.0328099, MSE: 0.50557905, 2.6s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 0.98505425, MSE: 0.46007246, 2.6s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 0.9914913, MSE: 0.46879622, 2.6s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 1.044946, MSE: 0.5247847, 2.6s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 1.035294, MSE: 0.5177818, 2.7s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 1.017585, MSE: 0.5028219, 2.7s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 0.9705127, MSE: 0.45853233, 2.7s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 0.9978826, MSE: 0.4887149, 2.6s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 1.0087245, MSE: 0.5023829, 2.6s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 0.9947921, MSE: 0.49126202, 2.8s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 1.042258, MSE: 0.54147536, 3.0s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 0.99883527, MSE: 0.50078833, 2.6s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 1.0500848, MSE: 0.5547885, 2.9s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 1.0315939, MSE: 0.5391111, 2.8s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 1.0297534, MSE: 0.54004294, 2.6s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 0.92059433, MSE: 0.43360466, 2.2s used\n",
      "Saving models ... Mon Dec 12 23:25:57 2022\n",
      "Epoch 7/8, Iter 7/18, loss value: 1.0888336, MSE: 0.5100893, 2.6s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 1.1062045, MSE: 0.5310576, 2.6s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 1.1086395, MSE: 0.53711945, 2.6s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 1.103835, MSE: 0.5360191, 2.6s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 1.0760545, MSE: 0.5120106, 2.6s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 1.0644732, MSE: 0.5043422, 2.6s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 1.0734404, MSE: 0.51719177, 2.6s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 1.0878074, MSE: 0.5353464, 2.6s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 1.088577, MSE: 0.54001415, 2.6s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 1.0678449, MSE: 0.5230755, 2.9s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 1.0513813, MSE: 0.5102118, 2.7s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 0.97124445, MSE: 0.43368313, 2.3s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 1.0061145, MSE: 0.47194406, 10.3s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 0.989421, MSE: 0.45810038, 2.6s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 1.0091522, MSE: 0.4803225, 2.6s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 1.0109848, MSE: 0.48460966, 2.7s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 1.0073853, MSE: 0.48350522, 2.7s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 0.979743, MSE: 0.4583297, 2.7s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 1.0040894, MSE: 0.48544222, 2.6s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 1.0092238, MSE: 0.49337164, 2.7s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 1.043158, MSE: 0.5300543, 2.6s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 1.0258937, MSE: 0.5155505, 2.6s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 1.0254877, MSE: 0.5179762, 2.6s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 1.0044242, MSE: 0.4998676, 2.6s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 1.0127681, MSE: 0.5111485, 2.7s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 1.0072412, MSE: 0.50851935, 2.6s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 1.0404395, MSE: 0.54460984, 2.6s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 0.9910923, MSE: 0.4980784, 2.6s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 0.9704858, MSE: 0.48016065, 2.7s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 0.925254, MSE: 0.43763345, 2.5s used\n",
      "Saving models ... Mon Dec 12 23:25:56 2022\n",
      "Epoch 7/8, Iter 7/18, loss value: 1.0997853, MSE: 0.49874884, 2.6s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 1.0796983, MSE: 0.48259336, 2.6s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 1.0722448, MSE: 0.4790319, 2.6s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 1.1212313, MSE: 0.5320344, 2.7s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 1.1174119, MSE: 0.5322605, 2.6s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 1.101582, MSE: 0.5204993, 2.6s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 1.0595592, MSE: 0.48249722, 2.9s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 1.1110386, MSE: 0.5379783, 2.6s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 1.1014525, MSE: 0.5323584, 2.7s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 1.1068795, MSE: 0.5417579, 2.8s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 1.0586576, MSE: 0.49760005, 2.7s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 1.0075155, MSE: 0.4503824, 2.2s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 1.0266323, MSE: 0.47283003, 10.5s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 1.034665, MSE: 0.48366225, 2.7s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 1.02162, MSE: 0.47310692, 2.6s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 1.0102538, MSE: 0.4642139, 2.6s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 1.004197, MSE: 0.46074262, 2.6s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 1.0110865, MSE: 0.47024792, 2.7s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 1.0022207, MSE: 0.463971, 2.6s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 1.0146343, MSE: 0.4791071, 2.6s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 1.0396521, MSE: 0.50697863, 2.7s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 1.039215, MSE: 0.50941443, 2.6s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 1.014571, MSE: 0.4877375, 2.6s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 1.0588706, MSE: 0.5350581, 2.6s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 0.99092937, MSE: 0.47013003, 2.7s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 1.0298002, MSE: 0.51209617, 2.6s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 1.0246624, MSE: 0.51005787, 2.7s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 1.031143, MSE: 0.51955533, 2.6s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 0.979949, MSE: 0.47137767, 2.5s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 0.9850866, MSE: 0.4795981, 2.2s used\n",
      "Saving models ... Mon Dec 12 23:25:57 2022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8, Iter 7/18, loss value: 1.1292531, MSE: 0.53564614, 2.6s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 1.1426404, MSE: 0.5530522, 2.7s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 1.0745353, MSE: 0.48893818, 2.8s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 1.1142514, MSE: 0.5326718, 2.7s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 1.1189004, MSE: 0.54133266, 2.7s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 1.1002908, MSE: 0.52664495, 2.7s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 1.1275165, MSE: 0.5578443, 2.6s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 1.109263, MSE: 0.5435444, 2.6s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 1.1019356, MSE: 0.54007745, 2.6s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 1.1263578, MSE: 0.56840986, 2.6s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 1.0959642, MSE: 0.5420965, 2.7s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 1.0221031, MSE: 0.47238696, 2.3s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 1.0570984, MSE: 0.5109424, 10.8s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 1.078603, MSE: 0.5356213, 3.0s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 1.0735635, MSE: 0.53353924, 2.6s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 1.0075926, MSE: 0.4703499, 2.6s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 1.0321686, MSE: 0.4976246, 2.8s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 0.9963782, MSE: 0.464471, 2.6s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 1.0500033, MSE: 0.52081007, 2.9s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 0.98595345, MSE: 0.45958042, 2.6s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 1.0139614, MSE: 0.49055704, 2.6s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 1.0353541, MSE: 0.51496017, 2.7s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 1.039393, MSE: 0.5221463, 2.6s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 1.0499825, MSE: 0.53587854, 2.6s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 1.0344121, MSE: 0.52345604, 2.7s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 1.0470552, MSE: 0.53920484, 2.6s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 1.0353074, MSE: 0.5305228, 2.6s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 0.96998966, MSE: 0.4682978, 2.9s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 0.9961438, MSE: 0.4975026, 2.7s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 1.0141118, MSE: 0.51834047, 2.6s used\n",
      "Saving models ... Mon Dec 12 23:26:02 2022\n",
      "Epoch 7/8, Iter 7/18, loss value: 1.055438, MSE: 0.5192126, 2.6s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 1.0483737, MSE: 0.51527375, 2.6s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 1.0282172, MSE: 0.49813065, 2.6s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 1.0207068, MSE: 0.49366763, 2.6s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 1.0085486, MSE: 0.48458132, 2.6s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 1.0502911, MSE: 0.52942276, 2.6s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 1.0425925, MSE: 0.52491707, 2.6s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 1.0545405, MSE: 0.539967, 2.6s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 1.0576388, MSE: 0.54620147, 2.8s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 1.0611694, MSE: 0.55287254, 2.6s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 0.9862037, MSE: 0.4809395, 2.7s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 0.9423554, MSE: 0.4399555, 2.3s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 0.9544368, MSE: 0.45445016, 11.2s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 0.9776355, MSE: 0.47942924, 2.6s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 0.97539246, MSE: 0.47879282, 2.6s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 0.94856656, MSE: 0.45366666, 2.6s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 0.94104207, MSE: 0.44792968, 2.6s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 0.9718567, MSE: 0.48078325, 2.6s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 0.9357163, MSE: 0.4466265, 2.6s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 0.96036506, MSE: 0.47324827, 2.6s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 0.9260486, MSE: 0.44098294, 2.6s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 0.97473335, MSE: 0.49164146, 2.6s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 0.99405015, MSE: 0.5131501, 2.7s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 0.96289384, MSE: 0.48432642, 2.7s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 0.98978806, MSE: 0.5135124, 2.7s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 0.9633057, MSE: 0.48931345, 2.7s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 0.9817698, MSE: 0.51014113, 2.7s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 0.9588635, MSE: 0.48957804, 2.8s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 0.9353248, MSE: 0.4685288, 3.0s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 0.8796448, MSE: 0.41529065, 2.4s used\n",
      "Saving models ... Mon Dec 12 23:26:21 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 23:44:27.007062: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:44:43.404149: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:44:44.449652: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:45:03.830363: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:45:25.685344: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:45:33.174008: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:45:41.460800: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:46:31.289279: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:46:32.867478: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:46:41.305485: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:46:50.919890: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:46:50.937649: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:46:51.719693: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:47:03.400045: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:47:03.412826: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:47:05.904049: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:47:11.027100: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:47:29.316824: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:47:43.062751: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:48:15.212492: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:48:30.487273: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:48:32.641849: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:48:35.910176: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:48:43.180462: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:48:45.616816: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:48:51.934191: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:48:55.178493: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:49:09.533179: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Iter 1/18, loss value: 4.5821137, MSE: 1.4765989, 967.7s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.3664513, MSE: 1.2693347, 2.8s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.1602426, MSE: 1.0762323, 2.5s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.0748615, MSE: 1.010777, 2.5s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 4.008457, MSE: 0.9707407, 2.4s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 3.9654517, MSE: 0.9596904, 2.5s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 3.907247, MSE: 0.9383479, 2.4s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.8280072, MSE: 0.9002937, 2.5s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.727511, MSE: 0.8444391, 2.4s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.673871, MSE: 0.8385719, 2.5s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.6027267, MSE: 0.8176561, 2.5s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.541914, MSE: 0.80896676, 2.4s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.4447992, MSE: 0.765359, 9.4s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.3790774, MSE: 0.75395644, 2.5s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.3031216, MSE: 0.7328104, 2.4s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.29697, MSE: 0.78153336, 2.5s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.2094724, MSE: 0.7486079, 2.5s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.166432, MSE: 0.7595025, 2.2s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 3.0219898, MSE: 0.6675136, 2.6s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 2.9684854, MSE: 0.6652186, 2.7s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 2.920854, MSE: 0.66736186, 2.5s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.8896694, MSE: 0.6845074, 2.5s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.8338447, MSE: 0.6755394, 2.5s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.7428153, MSE: 0.6299267, 2.5s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.6728015, MSE: 0.60381854, 2.4s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.653008, MSE: 0.62643325, 2.4s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.607621, MSE: 0.6220332, 2.4s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.562231, MSE: 0.6162132, 2.4s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.4772449, MSE: 0.5695131, 2.5s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.5170443, MSE: 0.64645934, 2.5s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.4282727, MSE: 0.5937515, 2.5s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.3762648, MSE: 0.57683545, 2.5s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.3292952, MSE: 0.5641232, 2.5s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.3206687, MSE: 0.58907014, 2.5s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.2567415, MSE: 0.55803907, 2.5s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.2040117, MSE: 0.53755796, 2.1s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.1818495, MSE: 0.5467179, 2.6s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.1227233, MSE: 0.5182556, 2.5s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 2.132839, MSE: 0.5584585, 2.6s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 2.0426104, MSE: 0.49777713, 2.5s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 2.0338302, MSE: 0.51799685, 2.5s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 2.0150301, MSE: 0.5276431, 2.5s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 1.9750524, MSE: 0.51561624, 9.6s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 1.9385889, MSE: 0.50660247, 2.4s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 1.9239328, MSE: 0.51876813, 2.5s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 1.9020914, MSE: 0.52315557, 2.5s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 1.8712728, MSE: 0.51800084, 2.5s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.8849485, MSE: 0.5567818, 2.5s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.8356786, MSE: 0.53203505, 2.6s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.8139653, MSE: 0.5342551, 2.5s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.8003905, MSE: 0.5439492, 2.5s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.7697697, MSE: 0.5359003, 2.5s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.7217951, MSE: 0.50995517, 2.5s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.6710026, MSE: 0.48056015, 2.2s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.6688755, MSE: 0.49903974, 2.5s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.615437, MSE: 0.4654448, 2.5s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.6244899, MSE: 0.49370852, 2.4s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.599946, MSE: 0.4877362, 2.5s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.5570974, MSE: 0.46290916, 2.5s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.5557553, MSE: 0.4791303, 2.4s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.5281777, MSE: 0.46883118, 2.5s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.5338233, MSE: 0.49142706, 2.5s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.491219, MSE: 0.46540612, 2.4s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.5277746, MSE: 0.51814646, 2.4s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.4869475, MSE: 0.49314034, 2.5s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.455856, MSE: 0.47748867, 2.6s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.4291829, MSE: 0.4659786, 2.5s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.4754636, MSE: 0.5271997, 2.5s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.4423189, MSE: 0.5087137, 2.4s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.4348345, MSE: 0.51564443, 2.4s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.3684688, MSE: 0.4632885, 2.4s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.3575914, MSE: 0.46591485, 2.1s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.3348154, MSE: 0.4559828, 9.5s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.3130262, MSE: 0.4464572, 2.5s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.3086746, MSE: 0.4537349, 2.4s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.3127973, MSE: 0.4688289, 2.5s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.2867167, MSE: 0.4532712, 2.4s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.2983267, MSE: 0.4751508, 2.5s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.2951931, MSE: 0.4819562, 2.5s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.3054539, MSE: 0.5020638, 2.5s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.2634661, MSE: 0.46981427, 2.4s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.2420344, MSE: 0.45791876, 2.5s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.25734, MSE: 0.48255593, 2.5s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.2743179, MSE: 0.5087119, 2.6s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.2329326, MSE: 0.4764119, 2.6s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.2650819, MSE: 0.51754445, 2.5s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.2164968, MSE: 0.47777352, 2.6s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.2274, MSE: 0.49721748, 2.6s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.2135291, MSE: 0.49164867, 2.5s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.1682622, MSE: 0.4545856, 2.1s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.1570024, MSE: 0.45115435, 2.5s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.1336172, MSE: 0.43502462, 2.5s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.1397866, MSE: 0.4480877, 2.4s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.1400254, MSE: 0.4550044, 2.4s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.1141558, MSE: 0.43550643, 2.5s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.1112747, MSE: 0.43891156, 2.5s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.1289889, MSE: 0.46294767, 2.5s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.0950669, MSE: 0.43540493, 2.5s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.1257571, MSE: 0.47245926, 2.4s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.100866, MSE: 0.45380446, 2.5s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.1152661, MSE: 0.47445115, 2.5s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.1220253, MSE: 0.48732895, 2.5s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.0717409, MSE: 0.44315735, 9.5s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.117089, MSE: 0.4945386, 2.5s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.0913514, MSE: 0.47459593, 2.5s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.0921607, MSE: 0.48116916, 2.5s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.0547049, MSE: 0.44942293, 2.5s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 1.0250832, MSE: 0.42528263, 2.2s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 1.070538, MSE: 0.4758397, 2.5s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 1.0159745, MSE: 0.42582768, 2.7s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 1.0497308, MSE: 0.4637476, 2.5s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 1.047849, MSE: 0.46588853, 2.5s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 1.0160234, MSE: 0.43812898, 2.6s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 0.9839145, MSE: 0.4098862, 2.5s used\n",
      "Epoch 1/8, Iter 1/18, loss value: 4.515026, MSE: 1.4111395, 965.9s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.367067, MSE: 1.271608, 2.8s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.170923, MSE: 1.089026, 2.5s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.108393, MSE: 1.0471964, 2.5s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 4.0068455, MSE: 0.97309226, 2.5s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 3.94246, MSE: 0.9421098, 2.5s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 3.8606284, MSE: 0.89900637, 2.5s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.8899856, MSE: 0.97165674, 2.5s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.7692714, MSE: 0.8981035, 2.5s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.6628852, MSE: 0.84199667, 2.6s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.5934374, MSE: 0.8254056, 2.5s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.6296232, MSE: 0.9163108, 2.5s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.447506, MSE: 0.79006636, 9.5s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.3592296, MSE: 0.7585234, 2.5s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.2704387, MSE: 0.72691286, 2.5s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.1919708, MSE: 0.7056376, 2.5s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.2006598, MSE: 0.7712706, 2.5s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.0310462, MSE: 0.6579254, 2.2s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 3.0162244, MSE: 0.6978103, 2.5s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 2.8938904, MSE: 0.6289316, 2.6s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 2.9259238, MSE: 0.71290237, 2.5s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.8333569, MSE: 0.6706756, 2.5s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.763461, MSE: 0.649417, 2.6s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.7062163, MSE: 0.6390951, 2.6s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.6175916, MSE: 0.59565634, 2.5s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.6079073, MSE: 0.629556, 2.5s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.5482516, MSE: 0.6118839, 2.5s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.5247068, MSE: 0.62881136, 2.6s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.4749982, MSE: 0.6182131, 2.4s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.3928635, MSE: 0.5738953, 2.5s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.3846498, MSE: 0.60235906, 2.5s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.3640885, MSE: 0.6174884, 2.5s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.319852, MSE: 0.60802823, 2.5s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.2476225, MSE: 0.5697416, 2.6s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.25198, MSE: 0.60742545, 2.5s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.1831062, MSE: 0.57128197, 2.2s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.0784934, MSE: 0.49840873, 2.6s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.0994668, MSE: 0.5503019, 2.6s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 2.0596762, MSE: 0.5406879, 2.5s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 2.0337913, MSE: 0.54430175, 2.6s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 2.0400677, MSE: 0.5794669, 2.5s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 1.9849845, MSE: 0.5527518, 2.5s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 1.9216554, MSE: 0.5171965, 9.7s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 1.8671885, MSE: 0.49000368, 2.5s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 1.906297, MSE: 0.55565596, 2.5s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 1.884249, MSE: 0.55947447, 2.5s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 1.8206813, MSE: 0.52109617, 2.5s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.8182461, MSE: 0.54330236, 2.5s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.8112688, MSE: 0.56046396, 2.5s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.7575865, MSE: 0.53031814, 2.5s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.7782425, MSE: 0.5737872, 2.5s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.7143712, MSE: 0.5320032, 2.5s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.6671181, MSE: 0.5061488, 2.5s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.5497749, MSE: 0.40963858, 2.2s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.5873684, MSE: 0.46720314, 2.5s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.5807308, MSE: 0.47989693, 2.5s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.5498445, MSE: 0.46774468, 2.5s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.5790884, MSE: 0.5151298, 2.6s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.5519534, MSE: 0.5056063, 2.5s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.5111393, MSE: 0.48192164, 2.5s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.4959829, MSE: 0.4833519, 2.6s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.4983971, MSE: 0.5018534, 2.5s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.4780765, MSE: 0.49728575, 2.5s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.506536, MSE: 0.54119605, 2.4s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.4690691, MSE: 0.5187803, 2.5s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.4301534, MSE: 0.49460244, 2.5s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.4268363, MSE: 0.50570315, 2.6s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.407455, MSE: 0.5004617, 2.5s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.4277321, MSE: 0.5345758, 2.5s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.3867178, MSE: 0.5071117, 2.6s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.3732255, MSE: 0.50688845, 2.5s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.3218244, MSE: 0.4683427, 2.1s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.332654, MSE: 0.49130905, 9.6s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.2873594, MSE: 0.45743093, 2.6s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.2884694, MSE: 0.4692456, 2.5s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.3061917, MSE: 0.49726108, 2.6s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.284684, MSE: 0.48572266, 2.5s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.2764376, MSE: 0.4871728, 2.5s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.2610817, MSE: 0.48132062, 2.5s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.2626635, MSE: 0.4921336, 2.5s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.2314312, MSE: 0.46991596, 2.5s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.246826, MSE: 0.4942247, 2.5s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.2184465, MSE: 0.47471184, 2.5s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.2228014, MSE: 0.48789477, 2.6s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.203012, MSE: 0.47691578, 2.5s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.205399, MSE: 0.48796296, 2.5s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.1943564, MSE: 0.48546943, 2.5s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.2066364, MSE: 0.50614285, 2.5s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.1732982, MSE: 0.48093072, 2.5s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.1904198, MSE: 0.5059528, 2.1s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.1233903, MSE: 0.44638863, 2.5s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.1265275, MSE: 0.45632333, 2.5s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.1024315, MSE: 0.43857372, 2.5s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.1397395, MSE: 0.481834, 2.5s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.1081011, MSE: 0.4559313, 2.5s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.113041, MSE: 0.4664512, 2.5s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.1292424, MSE: 0.4882667, 2.5s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.0854973, MSE: 0.45031556, 2.5s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.0763125, MSE: 0.4468606, 2.5s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.0689521, MSE: 0.44510677, 2.6s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.0851564, MSE: 0.46692082, 2.5s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.0884101, MSE: 0.47569934, 2.5s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.0789123, MSE: 0.4716757, 9.8s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.086676, MSE: 0.48498496, 2.5s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.0747771, MSE: 0.4786553, 2.5s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.0970185, MSE: 0.50643635, 2.5s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.0758897, MSE: 0.49084264, 2.5s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 0.9717052, MSE: 0.3919463, 2.2s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 0.9883993, MSE: 0.413422, 2.5s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 1.0414592, MSE: 0.47085574, 2.6s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 1.0055872, MSE: 0.43922842, 2.5s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 0.98468083, MSE: 0.42228812, 2.5s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 1.002528, MSE: 0.44388783, 2.5s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 0.9813245, MSE: 0.4264933, 2.6s used\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Iter 1/18, loss value: 4.484026, MSE: 1.3812306, 965.6s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.2792144, MSE: 1.1848536, 2.7s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.1891384, MSE: 1.1083541, 2.4s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.1221213, MSE: 1.0621445, 2.4s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 4.0488095, MSE: 1.0162033, 2.4s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 3.881268, MSE: 0.88174224, 2.5s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 3.8445604, MSE: 0.88329023, 2.5s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.8022969, MSE: 0.88358897, 2.4s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.720732, MSE: 0.84830827, 2.5s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.6573083, MSE: 0.8341901, 2.4s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.5909507, MSE: 0.8194801, 2.4s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.51338, MSE: 0.7954448, 2.4s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.4760604, MSE: 0.8130807, 9.4s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.3781412, MSE: 0.7710173, 2.4s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.3011456, MSE: 0.7504081, 2.4s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.2499483, MSE: 0.7556967, 2.4s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.158631, MSE: 0.7206435, 2.4s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.114512, MSE: 0.73215246, 2.2s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 3.0969558, MSE: 0.7688242, 2.4s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 2.8909366, MSE: 0.6156893, 2.5s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 2.851983, MSE: 0.62812734, 2.4s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.8492763, MSE: 0.6752553, 2.5s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.7914453, MSE: 0.6655872, 2.4s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.6667862, MSE: 0.58744913, 2.5s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.6542592, MSE: 0.61983573, 2.4s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.60111, MSE: 0.60998964, 2.4s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.548243, MSE: 0.59879035, 2.4s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.5316203, MSE: 0.6223553, 2.5s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.485879, MSE: 0.6155369, 2.5s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.4744005, MSE: 0.6418216, 2.5s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.4387667, MSE: 0.6427496, 2.5s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.3295019, MSE: 0.56895536, 2.5s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.3222725, MSE: 0.59627295, 2.5s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.2754016, MSE: 0.5832023, 2.4s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.281293, MSE: 0.6222649, 2.6s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.2014604, MSE: 0.5748892, 2.1s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.146525, MSE: 0.5513494, 2.5s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.1043644, MSE: 0.5398629, 2.5s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 2.0692966, MSE: 0.53481275, 2.4s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 2.0242393, MSE: 0.5191979, 2.5s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 2.0047283, MSE: 0.52850163, 2.5s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 1.9647092, MSE: 0.51675355, 2.5s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 1.9532588, MSE: 0.5330362, 9.6s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 1.9639769, MSE: 0.57088786, 2.5s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 1.8641958, MSE: 0.49757928, 2.4s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 1.9207293, MSE: 0.5800103, 2.4s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 1.870522, MSE: 0.55502975, 2.4s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.8307903, MSE: 0.5399146, 2.4s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.8536873, MSE: 0.58664995, 2.4s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.8024855, MSE: 0.558706, 2.4s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.7543066, MSE: 0.533242, 2.4s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.7294827, MSE: 0.5304835, 2.6s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.6671485, MSE: 0.4896594, 2.4s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.6977079, MSE: 0.5411533, 2.1s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.6378183, MSE: 0.5013634, 2.5s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.619168, MSE: 0.50204104, 2.5s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.5949097, MSE: 0.49656922, 2.4s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.5685853, MSE: 0.48840645, 2.4s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.5894109, MSE: 0.5267687, 2.4s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.5310117, MSE: 0.48548424, 2.5s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.4854214, MSE: 0.45664826, 2.5s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.4788074, MSE: 0.46625125, 2.5s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.483782, MSE: 0.4870575, 2.4s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.4597006, MSE: 0.4785508, 2.4s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.4611925, MSE: 0.49534026, 2.5s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.4496212, MSE: 0.49877927, 2.6s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.4574093, MSE: 0.52123016, 2.4s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.4271886, MSE: 0.5053397, 2.5s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.4210123, MSE: 0.5132027, 2.6s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.4199333, MSE: 0.52579266, 2.4s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.353338, MSE: 0.47246438, 2.4s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.3489093, MSE: 0.48085552, 2.1s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.2856807, MSE: 0.4297528, 9.8s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.2849236, MSE: 0.44053924, 2.4s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.2663388, MSE: 0.4330605, 2.4s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.2615722, MSE: 0.43894923, 2.4s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.2562572, MSE: 0.44399846, 2.4s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.2806911, MSE: 0.47856846, 2.4s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.2542249, MSE: 0.4620814, 2.6s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.2698472, MSE: 0.48748493, 2.4s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.2659534, MSE: 0.49320462, 2.4s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.2625859, MSE: 0.49928674, 2.4s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.2592082, MSE: 0.5052826, 2.4s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.2300398, MSE: 0.48539388, 2.5s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.2399055, MSE: 0.5043103, 2.4s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.2165601, MSE: 0.4898195, 2.4s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.2418013, MSE: 0.5236897, 2.4s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.2046099, MSE: 0.49491647, 2.4s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.1259844, MSE: 0.4245699, 2.5s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.0944929, MSE: 0.40101776, 2.2s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.1208968, MSE: 0.43487728, 2.6s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.1223083, MSE: 0.4431616, 2.6s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.0918396, MSE: 0.4191127, 2.4s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.1227645, MSE: 0.45628497, 2.4s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.0755033, MSE: 0.41534325, 2.4s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.0806375, MSE: 0.42666247, 2.4s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.0993061, MSE: 0.4512781, 2.5s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.1152304, MSE: 0.47311822, 2.6s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.1112708, MSE: 0.4749266, 2.4s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.1030852, MSE: 0.47260526, 2.4s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.0852566, MSE: 0.4607932, 2.4s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.1055086, MSE: 0.48690334, 2.4s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.109194, MSE: 0.49634948, 9.6s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.1072206, MSE: 0.50013757, 2.4s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.0716368, MSE: 0.4702783, 2.4s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.083864, MSE: 0.48817453, 2.4s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.0249206, MSE: 0.43485332, 2.4s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 0.99543303, MSE: 0.4108835, 2.1s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 1.0052868, MSE: 0.42595363, 2.5s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 0.9851512, MSE: 0.41050705, 2.5s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 0.9874115, MSE: 0.41704738, 2.5s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 1.0157828, MSE: 0.4495339, 2.5s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 1.0021932, MSE: 0.44013605, 2.4s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 0.9814541, MSE: 0.4236017, 2.5s used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 23:49:29.200547: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:49:31.792050: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:49:33.108807: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:49:34.274532: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:49:36.792808: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:49:39.270755: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Iter 1/18, loss value: 4.3389254, MSE: 1.2357342, 983.5s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.1892195, MSE: 1.0952818, 2.8s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.085701, MSE: 1.0064931, 2.5s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.1066766, MSE: 1.049904, 2.5s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 4.010693, MSE: 0.98328894, 2.5s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 3.945136, MSE: 0.9531245, 2.5s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 3.8048491, MSE: 0.8535388, 2.5s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.7313666, MSE: 0.8253166, 2.6s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.7221682, MSE: 0.8652008, 2.6s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.6776166, MSE: 0.8728456, 2.5s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.5802999, MSE: 0.8301308, 2.5s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.4880092, MSE: 0.79420584, 2.6s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.3965125, MSE: 0.760449, 9.4s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.3047767, MSE: 0.7271246, 2.5s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.246246, MSE: 0.727199, 2.6s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.1589909, MSE: 0.6983553, 2.6s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.132766, MSE: 0.7301294, 2.6s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.0486343, MSE: 0.7031824, 2.2s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 2.952297, MSE: 0.66219467, 2.5s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 2.857785, MSE: 0.621589, 2.5s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 2.7968435, MSE: 0.61298394, 2.5s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.7387295, MSE: 0.6055093, 2.4s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.6716151, MSE: 0.58729494, 2.5s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.7064717, MSE: 0.6692799, 2.5s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.5480793, MSE: 0.55626124, 2.5s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.5601041, MSE: 0.61196655, 2.6s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.5554028, MSE: 0.64934206, 2.5s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.5157402, MSE: 0.6501863, 2.5s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.4490592, MSE: 0.62264204, 2.5s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.3841558, MSE: 0.5955528, 2.5s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.3014266, MSE: 0.5494183, 2.5s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.2880223, MSE: 0.57153064, 2.5s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.2780313, MSE: 0.5961307, 2.5s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.2421885, MSE: 0.5941352, 2.5s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.1675682, MSE: 0.5528057, 2.5s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.1423674, MSE: 0.56025976, 2.2s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.122949, MSE: 0.5725278, 2.5s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.0699317, MSE: 0.5504599, 2.6s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 1.9965572, MSE: 0.50735563, 2.5s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 1.9499508, MSE: 0.4903991, 2.5s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 1.9718807, MSE: 0.54140264, 2.6s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 1.9231352, MSE: 0.5211531, 2.6s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 1.8447522, MSE: 0.4706225, 10.1s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 1.8715484, MSE: 0.52476317, 2.7s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 1.8190976, MSE: 0.49901164, 2.4s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 1.7852273, MSE: 0.49119794, 2.4s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 1.7664745, MSE: 0.497798, 2.5s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.7744075, MSE: 0.5304445, 2.5s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.7205594, MSE: 0.5007051, 2.5s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.7336686, MSE: 0.537342, 2.5s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.6943996, MSE: 0.5210466, 2.5s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.6718643, MSE: 0.5208339, 2.5s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.6807873, MSE: 0.55141115, 2.5s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.6545916, MSE: 0.5462119, 2.1s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.5519845, MSE: 0.4636232, 2.6s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.559413, MSE: 0.49025947, 2.6s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.516, MSE: 0.46530965, 2.5s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.4908223, MSE: 0.45789415, 2.5s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.4982878, MSE: 0.48252824, 2.7s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.4810567, MSE: 0.48199916, 2.7s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.4648764, MSE: 0.4820745, 2.6s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.4681113, MSE: 0.5012269, 2.7s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.4281735, MSE: 0.47686124, 2.5s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.4543741, MSE: 0.5183247, 2.5s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.4355438, MSE: 0.5144082, 2.5s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.3733608, MSE: 0.46689793, 2.5s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.3849373, MSE: 0.49282092, 2.5s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.3550736, MSE: 0.4770002, 2.5s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.3740077, MSE: 0.5096599, 2.5s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.3386772, MSE: 0.487863, 2.5s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.3346381, MSE: 0.49699607, 2.5s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.2954105, MSE: 0.4704372, 2.1s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.2768239, MSE: 0.46372238, 10.0s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.268897, MSE: 0.4670388, 2.5s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.215697, MSE: 0.42450982, 2.5s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.2333872, MSE: 0.45230952, 2.5s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.2441394, MSE: 0.47290123, 2.5s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.1829907, MSE: 0.42135838, 2.6s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.2735624, MSE: 0.52135676, 2.7s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.1982067, MSE: 0.45540425, 2.5s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.210218, MSE: 0.47673467, 2.7s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.1875963, MSE: 0.46334305, 2.5s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.1818365, MSE: 0.46668404, 2.5s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.1648033, MSE: 0.45856076, 2.5s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.1767741, MSE: 0.47917953, 2.4s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.1934075, MSE: 0.50432223, 2.5s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.1602708, MSE: 0.47958836, 2.5s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.1822696, MSE: 0.50993955, 2.5s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.1156173, MSE: 0.4514011, 2.5s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.111803, MSE: 0.45551056, 2.1s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.0655915, MSE: 0.41666558, 2.5s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.0512427, MSE: 0.40915027, 2.5s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.0713627, MSE: 0.43578416, 2.5s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.05129, MSE: 0.42196414, 2.5s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.0521598, MSE: 0.42888454, 2.4s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.0311729, MSE: 0.41390625, 2.5s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.0595022, MSE: 0.44812325, 2.6s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.0546151, MSE: 0.44903117, 2.5s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.047048, MSE: 0.44739833, 2.6s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.0914232, MSE: 0.497697, 2.5s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.0445147, MSE: 0.456618, 2.7s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.0696727, MSE: 0.48751843, 2.5s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.0561337, MSE: 0.47961703, 10.4s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.0893376, MSE: 0.518406, 2.5s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.0315182, MSE: 0.46602932, 2.5s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.0499068, MSE: 0.4897224, 2.5s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.0020099, MSE: 0.44716525, 2.5s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 0.97036076, MSE: 0.4208492, 2.1s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 0.9641855, MSE: 0.41944373, 2.5s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 0.9751227, MSE: 0.43441018, 2.5s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 0.94148517, MSE: 0.40436825, 2.5s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 0.94112575, MSE: 0.40746963, 2.5s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 0.95828587, MSE: 0.42824417, 2.8s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 0.95701385, MSE: 0.4305451, 2.5s used\n",
      "Epoch 1/8, Iter 1/18, loss value: 4.5027523, MSE: 1.4008398, 987.3s used\n",
      "Epoch 1/8, Iter 2/18, loss value: 4.2931337, MSE: 1.1996331, 2.9s used\n",
      "Epoch 1/8, Iter 3/18, loss value: 4.1377974, MSE: 1.0582788, 2.6s used\n",
      "Epoch 1/8, Iter 4/18, loss value: 4.0193443, MSE: 0.96133727, 2.5s used\n",
      "Epoch 1/8, Iter 5/18, loss value: 3.9810467, MSE: 0.9515034, 2.5s used\n",
      "Epoch 1/8, Iter 6/18, loss value: 3.949854, MSE: 0.9550599, 2.5s used\n",
      "Epoch 1/8, Iter 7/18, loss value: 3.8601756, MSE: 0.9056634, 2.5s used\n",
      "Epoch 1/8, Iter 8/18, loss value: 3.836291, MSE: 0.9265786, 2.6s used\n",
      "Epoch 1/8, Iter 9/18, loss value: 3.7257676, MSE: 0.8648151, 2.5s used\n",
      "Epoch 1/8, Iter 10/18, loss value: 3.7317028, MSE: 0.9226558, 2.6s used\n",
      "Epoch 1/8, Iter 11/18, loss value: 3.584459, MSE: 0.82977897, 2.5s used\n",
      "Epoch 1/8, Iter 12/18, loss value: 3.5025737, MSE: 0.80414605, 2.5s used\n",
      "Epoch 1/8, Iter 13/18, loss value: 3.4289174, MSE: 0.7881113, 9.9s used\n",
      "Epoch 1/8, Iter 14/18, loss value: 3.389802, MSE: 0.80742705, 2.5s used\n",
      "Epoch 1/8, Iter 15/18, loss value: 3.290384, MSE: 0.76670283, 2.5s used\n",
      "Epoch 1/8, Iter 16/18, loss value: 3.2160258, MSE: 0.75101846, 2.5s used\n",
      "Epoch 1/8, Iter 17/18, loss value: 3.138427, MSE: 0.7316568, 2.5s used\n",
      "Epoch 1/8, Iter 18/18, loss value: 3.069337, MSE: 0.71998817, 2.1s used\n",
      "Epoch 2/8, Iter 1/18, loss value: 2.995107, MSE: 0.7013793, 2.5s used\n",
      "Epoch 2/8, Iter 2/18, loss value: 2.9099908, MSE: 0.67045677, 2.5s used\n",
      "Epoch 2/8, Iter 3/18, loss value: 2.8408263, MSE: 0.65392, 2.5s used\n",
      "Epoch 2/8, Iter 4/18, loss value: 2.754569, MSE: 0.61841536, 2.5s used\n",
      "Epoch 2/8, Iter 5/18, loss value: 2.7416592, MSE: 0.65457207, 2.5s used\n",
      "Epoch 2/8, Iter 6/18, loss value: 2.688271, MSE: 0.6483852, 2.5s used\n",
      "Epoch 2/8, Iter 7/18, loss value: 2.5758343, MSE: 0.58130693, 2.5s used\n",
      "Epoch 2/8, Iter 8/18, loss value: 2.5877118, MSE: 0.63680744, 2.6s used\n",
      "Epoch 2/8, Iter 9/18, loss value: 2.533302, MSE: 0.62433296, 2.6s used\n",
      "Epoch 2/8, Iter 10/18, loss value: 2.5028696, MSE: 0.6342887, 2.5s used\n",
      "Epoch 2/8, Iter 11/18, loss value: 2.46084, MSE: 0.6311815, 2.7s used\n",
      "Epoch 2/8, Iter 12/18, loss value: 2.403197, MSE: 0.61118144, 2.6s used\n",
      "Epoch 2/8, Iter 13/18, loss value: 2.348847, MSE: 0.5932964, 2.6s used\n",
      "Epoch 2/8, Iter 14/18, loss value: 2.3182561, MSE: 0.59802157, 2.5s used\n",
      "Epoch 2/8, Iter 15/18, loss value: 2.2962296, MSE: 0.61046237, 2.5s used\n",
      "Epoch 2/8, Iter 16/18, loss value: 2.2558339, MSE: 0.6038689, 2.6s used\n",
      "Epoch 2/8, Iter 17/18, loss value: 2.194561, MSE: 0.57585275, 2.5s used\n",
      "Epoch 2/8, Iter 18/18, loss value: 2.08532, MSE: 0.49919322, 2.3s used\n",
      "Epoch 3/8, Iter 1/18, loss value: 2.106354, MSE: 0.55190617, 2.6s used\n",
      "Epoch 3/8, Iter 2/18, loss value: 2.0767741, MSE: 0.5532515, 2.7s used\n",
      "Epoch 3/8, Iter 3/18, loss value: 2.0544848, MSE: 0.56107783, 2.6s used\n",
      "Epoch 3/8, Iter 4/18, loss value: 2.0232008, MSE: 0.55915815, 2.5s used\n",
      "Epoch 3/8, Iter 5/18, loss value: 2.0138288, MSE: 0.5784929, 2.5s used\n",
      "Epoch 3/8, Iter 6/18, loss value: 1.9265823, MSE: 0.5193231, 2.6s used\n",
      "Epoch 3/8, Iter 7/18, loss value: 1.887583, MSE: 0.50783724, 9.7s used\n",
      "Epoch 3/8, Iter 8/18, loss value: 1.8821301, MSE: 0.5292867, 2.5s used\n",
      "Epoch 3/8, Iter 9/18, loss value: 1.878968, MSE: 0.55242157, 2.5s used\n",
      "Epoch 3/8, Iter 10/18, loss value: 1.8128805, MSE: 0.5120769, 2.5s used\n",
      "Epoch 3/8, Iter 11/18, loss value: 1.8089937, MSE: 0.5334536, 2.6s used\n",
      "Epoch 3/8, Iter 12/18, loss value: 1.7915576, MSE: 0.5407093, 2.5s used\n",
      "Epoch 3/8, Iter 13/18, loss value: 1.7837931, MSE: 0.55710876, 2.6s used\n",
      "Epoch 3/8, Iter 14/18, loss value: 1.7002658, MSE: 0.49715993, 2.7s used\n",
      "Epoch 3/8, Iter 15/18, loss value: 1.69614, MSE: 0.5160038, 2.6s used\n",
      "Epoch 3/8, Iter 16/18, loss value: 1.7041938, MSE: 0.5464173, 2.5s used\n",
      "Epoch 3/8, Iter 17/18, loss value: 1.6471052, MSE: 0.5110783, 2.5s used\n",
      "Epoch 3/8, Iter 18/18, loss value: 1.6845758, MSE: 0.5696804, 2.2s used\n",
      "Epoch 4/8, Iter 1/18, loss value: 1.5756251, MSE: 0.48101136, 2.5s used\n",
      "Epoch 4/8, Iter 2/18, loss value: 1.5877297, MSE: 0.51264703, 2.5s used\n",
      "Epoch 4/8, Iter 3/18, loss value: 1.5346808, MSE: 0.47855133, 2.5s used\n",
      "Epoch 4/8, Iter 4/18, loss value: 1.5220587, MSE: 0.484311, 2.5s used\n",
      "Epoch 4/8, Iter 5/18, loss value: 1.5213304, MSE: 0.50137514, 2.6s used\n",
      "Epoch 4/8, Iter 6/18, loss value: 1.5190783, MSE: 0.516464, 2.6s used\n",
      "Epoch 4/8, Iter 7/18, loss value: 1.4945856, MSE: 0.50889945, 2.5s used\n",
      "Epoch 4/8, Iter 8/18, loss value: 1.4738111, MSE: 0.5044755, 2.6s used\n",
      "Epoch 4/8, Iter 9/18, loss value: 1.4697572, MSE: 0.5163725, 2.6s used\n",
      "Epoch 4/8, Iter 10/18, loss value: 1.4330704, MSE: 0.49534374, 2.5s used\n",
      "Epoch 4/8, Iter 11/18, loss value: 1.4158368, MSE: 0.493321, 2.5s used\n",
      "Epoch 4/8, Iter 12/18, loss value: 1.4054022, MSE: 0.49775922, 2.6s used\n",
      "Epoch 4/8, Iter 13/18, loss value: 1.4152529, MSE: 0.5221407, 2.6s used\n",
      "Epoch 4/8, Iter 14/18, loss value: 1.4016658, MSE: 0.5227965, 2.5s used\n",
      "Epoch 4/8, Iter 15/18, loss value: 1.3864709, MSE: 0.5215538, 2.5s used\n",
      "Epoch 4/8, Iter 16/18, loss value: 1.3695399, MSE: 0.5182489, 2.5s used\n",
      "Epoch 4/8, Iter 17/18, loss value: 1.3493998, MSE: 0.5113882, 2.5s used\n",
      "Epoch 4/8, Iter 18/18, loss value: 1.3054423, MSE: 0.48035598, 2.2s used\n",
      "Epoch 5/8, Iter 1/18, loss value: 1.292939, MSE: 0.48018003, 10.6s used\n",
      "Epoch 5/8, Iter 2/18, loss value: 1.2523432, MSE: 0.45116955, 2.5s used\n",
      "Epoch 5/8, Iter 3/18, loss value: 1.2662019, MSE: 0.4759644, 2.6s used\n",
      "Epoch 5/8, Iter 4/18, loss value: 1.2507675, MSE: 0.47089785, 2.6s used\n",
      "Epoch 5/8, Iter 5/18, loss value: 1.2359961, MSE: 0.46609324, 2.5s used\n",
      "Epoch 5/8, Iter 6/18, loss value: 1.2436076, MSE: 0.48357278, 2.6s used\n",
      "Epoch 5/8, Iter 7/18, loss value: 1.2319442, MSE: 0.48157498, 2.6s used\n",
      "Epoch 5/8, Iter 8/18, loss value: 1.2279017, MSE: 0.48701015, 2.6s used\n",
      "Epoch 5/8, Iter 9/18, loss value: 1.2350378, MSE: 0.5035915, 2.5s used\n",
      "Epoch 5/8, Iter 10/18, loss value: 1.2124373, MSE: 0.4902477, 2.5s used\n",
      "Epoch 5/8, Iter 11/18, loss value: 1.2434607, MSE: 0.5303296, 2.6s used\n",
      "Epoch 5/8, Iter 12/18, loss value: 1.1908777, MSE: 0.48669487, 2.6s used\n",
      "Epoch 5/8, Iter 13/18, loss value: 1.1982946, MSE: 0.50287986, 2.5s used\n",
      "Epoch 5/8, Iter 14/18, loss value: 1.1667161, MSE: 0.479869, 2.5s used\n",
      "Epoch 5/8, Iter 15/18, loss value: 1.1625105, MSE: 0.48406193, 2.5s used\n",
      "Epoch 5/8, Iter 16/18, loss value: 1.1766399, MSE: 0.50658226, 2.5s used\n",
      "Epoch 5/8, Iter 17/18, loss value: 1.1429175, MSE: 0.4810961, 2.5s used\n",
      "Epoch 5/8, Iter 18/18, loss value: 1.1705649, MSE: 0.5167454, 2.1s used\n",
      "Epoch 6/8, Iter 1/18, loss value: 1.1000435, MSE: 0.45381147, 2.5s used\n",
      "Epoch 6/8, Iter 2/18, loss value: 1.09237, MSE: 0.45296916, 2.5s used\n",
      "Epoch 6/8, Iter 3/18, loss value: 1.1131166, MSE: 0.4799719, 2.6s used\n",
      "Epoch 6/8, Iter 4/18, loss value: 1.0859208, MSE: 0.45870197, 2.6s used\n",
      "Epoch 6/8, Iter 5/18, loss value: 1.0818349, MSE: 0.46020603, 2.6s used\n",
      "Epoch 6/8, Iter 6/18, loss value: 1.0646894, MSE: 0.44860527, 2.6s used\n",
      "Epoch 6/8, Iter 7/18, loss value: 1.0651896, MSE: 0.45473674, 2.5s used\n",
      "Epoch 6/8, Iter 8/18, loss value: 1.0754058, MSE: 0.470712, 2.5s used\n",
      "Epoch 6/8, Iter 9/18, loss value: 1.0763372, MSE: 0.4774408, 2.5s used\n",
      "Epoch 6/8, Iter 10/18, loss value: 1.0729122, MSE: 0.47976196, 2.7s used\n",
      "Epoch 6/8, Iter 11/18, loss value: 1.0666426, MSE: 0.47914055, 2.5s used\n",
      "Epoch 6/8, Iter 12/18, loss value: 1.0837547, MSE: 0.50177914, 2.6s used\n",
      "Epoch 6/8, Iter 13/18, loss value: 1.0648384, MSE: 0.48847407, 10.0s used\n",
      "Epoch 6/8, Iter 14/18, loss value: 1.0606506, MSE: 0.48978, 2.5s used\n",
      "Epoch 6/8, Iter 15/18, loss value: 1.0940977, MSE: 0.52854383, 2.5s used\n",
      "Epoch 6/8, Iter 16/18, loss value: 1.0689808, MSE: 0.5087054, 2.6s used\n",
      "Epoch 6/8, Iter 17/18, loss value: 1.0202469, MSE: 0.465222, 2.5s used\n",
      "Epoch 6/8, Iter 18/18, loss value: 1.0291815, MSE: 0.47922355, 2.2s used\n",
      "Epoch 7/8, Iter 1/18, loss value: 0.96385455, MSE: 0.4184528, 2.8s used\n",
      "Epoch 7/8, Iter 2/18, loss value: 1.0070143, MSE: 0.4656882, 2.6s used\n",
      "Epoch 7/8, Iter 3/18, loss value: 0.96539736, MSE: 0.42787978, 2.5s used\n",
      "Epoch 7/8, Iter 4/18, loss value: 0.9715734, MSE: 0.4376827, 2.6s used\n",
      "Epoch 7/8, Iter 5/18, loss value: 0.97821987, MSE: 0.4480159, 2.7s used\n",
      "Epoch 7/8, Iter 6/18, loss value: 0.9608671, MSE: 0.43446314, 2.6s used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 23:49:50.765838: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:50:21.932675: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:50:23.160645: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:50:32.643335: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:50:39.538614: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:50:40.819050: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-12 23:50:56.936710: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8, Iter 7/18, loss value: 0.98866725, MSE: 0.4185125, 2.5s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 1.003666, MSE: 0.43755835, 2.6s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 1.0198207, MSE: 0.4579159, 2.5s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 1.002301, MSE: 0.44476047, 2.5s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 0.9957516, MSE: 0.44260716, 2.5s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 1.0129907, MSE: 0.4642331, 2.6s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 1.0165466, MSE: 0.47213995, 2.5s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 0.99484545, MSE: 0.45464534, 2.5s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 0.9977323, MSE: 0.46179128, 2.5s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 1.0005952, MSE: 0.46886674, 2.5s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 0.9893745, MSE: 0.46193427, 2.5s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 0.94823843, MSE: 0.42492485, 2.2s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 0.95268416, MSE: 0.4331409, 2.5s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 0.9535475, MSE: 0.43709382, 2.5s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 0.9356364, MSE: 0.4219704, 2.5s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 0.9289138, MSE: 0.417894, 2.5s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 0.93954206, MSE: 0.43127784, 2.5s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 0.9397007, MSE: 0.43449515, 9.8s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 0.92240524, MSE: 0.42044804, 2.6s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 0.93715596, MSE: 0.4384556, 2.6s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 0.8991432, MSE: 0.40366048, 2.6s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 0.9285926, MSE: 0.43630382, 2.5s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 0.90854216, MSE: 0.41941985, 2.6s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 0.93099874, MSE: 0.44504264, 2.5s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 0.92606485, MSE: 0.44323483, 2.5s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 0.92966604, MSE: 0.4499805, 2.5s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 0.94331825, MSE: 0.4667524, 2.5s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 0.9108372, MSE: 0.43734634, 2.5s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 0.91630423, MSE: 0.4459505, 2.5s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 0.88234603, MSE: 0.41505706, 2.2s used\n",
      "Saving models ... Mon Dec 12 23:50:42 2022\n",
      "Epoch 7/8, Iter 7/18, loss value: 0.9928955, MSE: 0.43920133, 2.5s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 0.96423846, MSE: 0.4147088, 2.4s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 0.98016083, MSE: 0.434792, 2.5s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 0.99897313, MSE: 0.45785564, 2.5s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 1.0008867, MSE: 0.4639271, 2.5s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 1.0054946, MSE: 0.4725377, 2.5s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 0.97774607, MSE: 0.44885027, 2.4s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 1.0157411, MSE: 0.49089676, 2.5s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 0.9737423, MSE: 0.45290864, 2.4s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 0.9983231, MSE: 0.48147437, 2.4s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 0.9580605, MSE: 0.44515517, 2.4s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 0.9088628, MSE: 0.39980072, 2.1s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 0.9290999, MSE: 0.42349666, 2.5s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 0.9112767, MSE: 0.4086047, 2.5s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 0.91547513, MSE: 0.41555732, 2.4s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 0.9291375, MSE: 0.43191946, 2.5s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 0.91961133, MSE: 0.425052, 2.4s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 0.89641654, MSE: 0.40456483, 9.5s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 0.94154364, MSE: 0.45246196, 2.4s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 0.91134226, MSE: 0.42500344, 2.5s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 0.9121447, MSE: 0.42867824, 2.4s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 0.9625338, MSE: 0.48200822, 2.4s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 0.90597034, MSE: 0.42840636, 2.5s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 0.91976047, MSE: 0.44520238, 2.4s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 0.9311025, MSE: 0.45943263, 2.5s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 0.9115354, MSE: 0.44293916, 2.4s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 0.9307563, MSE: 0.4652564, 2.4s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 0.89245194, MSE: 0.43001282, 2.4s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 0.9041343, MSE: 0.4446012, 2.4s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 0.8758531, MSE: 0.41912892, 2.1s used\n",
      "Saving models ... Mon Dec 12 23:50:42 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 23:51:13.371175: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8, Iter 7/18, loss value: 0.97415686, MSE: 0.4231926, 2.6s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 1.0006623, MSE: 0.45372403, 2.6s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 0.95291185, MSE: 0.41011056, 2.5s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 1.0111537, MSE: 0.47247535, 2.5s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 0.96778405, MSE: 0.43311718, 2.5s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 0.9793926, MSE: 0.4487164, 2.5s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 0.9993386, MSE: 0.47277912, 2.6s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 0.9707064, MSE: 0.44828224, 2.6s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 1.0020188, MSE: 0.48370594, 2.6s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 0.99012136, MSE: 0.47580746, 2.5s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 0.93961674, MSE: 0.42913783, 2.7s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 0.87709546, MSE: 0.37044162, 2.3s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 0.9138304, MSE: 0.4106144, 2.6s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 0.9102875, MSE: 0.40998825, 2.5s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 0.9191011, MSE: 0.42145428, 2.5s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 0.90312046, MSE: 0.40806362, 2.5s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 0.8905532, MSE: 0.39811662, 2.5s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 0.8864906, MSE: 0.3968686, 9.7s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 0.91820365, MSE: 0.4314413, 2.5s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 0.9108583, MSE: 0.42701954, 2.5s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 0.9306193, MSE: 0.44970578, 2.5s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 0.91213834, MSE: 0.43431476, 2.5s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 0.915577, MSE: 0.4407161, 2.6s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 0.9122294, MSE: 0.44009045, 2.5s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 0.89204764, MSE: 0.42265072, 2.5s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 0.9315065, MSE: 0.4648349, 2.5s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 0.94942343, MSE: 0.4854581, 2.5s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 0.926239, MSE: 0.46498907, 2.5s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 0.8792368, MSE: 0.4206679, 2.5s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 0.8654721, MSE: 0.4094192, 2.1s used\n",
      "Saving models ... Mon Dec 12 23:50:43 2022\n",
      "Epoch 7/8, Iter 7/18, loss value: 0.9731145, MSE: 0.45033684, 2.5s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 0.9842311, MSE: 0.46526486, 2.5s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 0.9575273, MSE: 0.4423546, 2.5s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 0.96229625, MSE: 0.45085046, 2.6s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 0.9322027, MSE: 0.42442253, 2.7s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 0.92714405, MSE: 0.4231405, 2.6s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 0.9277258, MSE: 0.42762145, 2.6s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 0.9381828, MSE: 0.44205257, 2.5s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 0.9826238, MSE: 0.4904486, 2.5s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 0.94722176, MSE: 0.4589934, 2.6s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 0.9044057, MSE: 0.42000398, 2.6s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 0.91622895, MSE: 0.4355486, 2.2s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 0.894731, MSE: 0.41717216, 2.5s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 0.87285227, MSE: 0.39795935, 2.5s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 0.8813019, MSE: 0.40877354, 2.5s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 0.89829016, MSE: 0.42798373, 2.5s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 0.87650067, MSE: 0.4085362, 2.5s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 0.89720565, MSE: 0.43167913, 9.7s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 0.8825691, MSE: 0.41965675, 2.4s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 0.8939346, MSE: 0.43385947, 2.4s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 0.8902453, MSE: 0.43304712, 2.5s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 0.8893019, MSE: 0.43484125, 2.5s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 0.8787354, MSE: 0.42703897, 2.5s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 0.8859339, MSE: 0.43702736, 2.5s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 0.8874084, MSE: 0.44111556, 2.6s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 0.8772514, MSE: 0.4336664, 2.6s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 0.88911796, MSE: 0.44835585, 2.7s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 0.8615453, MSE: 0.42372432, 2.6s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 0.8607823, MSE: 0.42592353, 2.7s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 0.85224074, MSE: 0.42023048, 2.3s used\n",
      "Saving models ... Mon Dec 12 23:51:05 2022\n",
      "Epoch 7/8, Iter 7/18, loss value: 0.9362534, MSE: 0.4136441, 2.6s used\n",
      "Epoch 7/8, Iter 8/18, loss value: 0.99624646, MSE: 0.47748783, 2.6s used\n",
      "Epoch 7/8, Iter 9/18, loss value: 0.97539556, MSE: 0.46050832, 2.6s used\n",
      "Epoch 7/8, Iter 10/18, loss value: 1.0039908, MSE: 0.4930112, 2.5s used\n",
      "Epoch 7/8, Iter 11/18, loss value: 0.9813143, MSE: 0.47424212, 2.7s used\n",
      "Epoch 7/8, Iter 12/18, loss value: 0.9571928, MSE: 0.4540574, 2.6s used\n",
      "Epoch 7/8, Iter 13/18, loss value: 0.978333, MSE: 0.47897378, 2.6s used\n",
      "Epoch 7/8, Iter 14/18, loss value: 1.0214876, MSE: 0.5257125, 3.1s used\n",
      "Epoch 7/8, Iter 15/18, loss value: 0.9899341, MSE: 0.4979166, 3.2s used\n",
      "Epoch 7/8, Iter 16/18, loss value: 0.9582516, MSE: 0.4699616, 2.6s used\n",
      "Epoch 7/8, Iter 17/18, loss value: 0.91072273, MSE: 0.42633644, 2.6s used\n",
      "Epoch 7/8, Iter 18/18, loss value: 0.91444886, MSE: 0.43394718, 2.4s used\n",
      "Epoch 8/8, Iter 1/18, loss value: 0.89257145, MSE: 0.41540745, 2.7s used\n",
      "Epoch 8/8, Iter 2/18, loss value: 0.91573524, MSE: 0.44114327, 2.6s used\n",
      "Epoch 8/8, Iter 3/18, loss value: 0.904798, MSE: 0.4324695, 2.6s used\n",
      "Epoch 8/8, Iter 4/18, loss value: 0.8967967, MSE: 0.42682597, 2.6s used\n",
      "Epoch 8/8, Iter 5/18, loss value: 0.9132144, MSE: 0.4457712, 2.6s used\n",
      "Epoch 8/8, Iter 6/18, loss value: 0.90309554, MSE: 0.43818513, 10.9s used\n",
      "Epoch 8/8, Iter 7/18, loss value: 0.8966708, MSE: 0.43448243, 2.9s used\n",
      "Epoch 8/8, Iter 8/18, loss value: 0.9133835, MSE: 0.45409507, 3.1s used\n",
      "Epoch 8/8, Iter 9/18, loss value: 0.89297915, MSE: 0.43661967, 3.1s used\n",
      "Epoch 8/8, Iter 10/18, loss value: 0.9057325, MSE: 0.45246795, 2.9s used\n",
      "Epoch 8/8, Iter 11/18, loss value: 0.9037441, MSE: 0.45366442, 2.7s used\n",
      "Epoch 8/8, Iter 12/18, loss value: 0.88111854, MSE: 0.43407655, 2.7s used\n",
      "Epoch 8/8, Iter 13/18, loss value: 0.9312093, MSE: 0.48714104, 2.7s used\n",
      "Epoch 8/8, Iter 14/18, loss value: 0.9055178, MSE: 0.46440426, 2.8s used\n",
      "Epoch 8/8, Iter 15/18, loss value: 0.87428343, MSE: 0.43614438, 2.7s used\n",
      "Epoch 8/8, Iter 16/18, loss value: 0.91077137, MSE: 0.47543526, 2.8s used\n",
      "Epoch 8/8, Iter 17/18, loss value: 0.85189104, MSE: 0.41938812, 2.8s used\n",
      "Epoch 8/8, Iter 18/18, loss value: 0.8486576, MSE: 0.41897145, 2.5s used\n",
      "Saving models ... Mon Dec 12 23:51:16 2022\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from time import time\n",
    "from joblib import Parallel,delayed\n",
    "import datetime\n",
    "\n",
    "iterator = [] \n",
    "for cluster in range(n_clusters):\n",
    "    for rep in range(1,n_rep+1):\n",
    "        iterator.append([cluster,rep])\n",
    "\n",
    "def train(tissue, cluster, n_epochs, batch_size, rep):\n",
    "   \n",
    "    # Get velocity genes for current cluster\n",
    "    cluster_genes = cluster_labels.loc[cluster_labels.iloc[:,0] == cluster,].index.values\n",
    "    num_genes = cluster_genes.shape[0]\n",
    "    num_tf = rpkm.shape[1]    \n",
    "    \n",
    "    # Create folder for saving trained models\n",
    "    if not os.path.exists(\"results/full_model\"):\n",
    "        os.mkdir(\"results/full_model\")\n",
    "    \n",
    "    # Prepare training data\n",
    "    X_train = defaultdict(list)\n",
    "    y_train = defaultdict(list)\n",
    "\n",
    "    print(\"Preparing features ... {}\".format(datetime.datetime.now().ctime()))\n",
    "    for gene in cluster_genes:\n",
    "\n",
    "        # Split train and test data for each gene\n",
    "        rpkm_train = rpkm\n",
    "        velo_train = velo[gene]\n",
    "\n",
    "        # Remove NAs.\n",
    "        select = ~pd.isna(velo_train)\n",
    "        velo_train = velo_train.loc[select]\n",
    "        rpkm_train = rpkm_train.loc[select,:]\n",
    "\n",
    "        # Generate train/test inputs for current gene\n",
    "        for i,TF in enumerate(rpkm_train.columns):\n",
    "\n",
    "            X_train[gene].append(np.empty((rpkm_train.shape[0], num_feature_type)))\n",
    "\n",
    "            # For current tf, get expression rpkms\n",
    "            X_train[gene][-1][:,0] = rpkm_train[TF].values\n",
    "\n",
    "            # Get TF mean signals and TF sum signals\n",
    "            X_train[gene][-1][:,1] = act_mat_mean.loc[gene,TF]\n",
    "            X_train[gene][-1][:,2] = act_mat_sum.loc[gene,TF]\n",
    "\n",
    "        y_train[gene] = velo_train.values\n",
    "    '''\n",
    "    Train by trace norm loss.\n",
    "    '''\n",
    "    print(\"Setting up models...{}\".format(datetime.datetime.now().ctime()))\n",
    "    # Build MTL model\n",
    "    models = build_mtl_model(num_tf = num_tf,\n",
    "                             num_feature_type = num_feature_type,\n",
    "                             num_genes = num_genes\n",
    "                            )\n",
    "    \n",
    "    # MSE loss function and adam optimizer\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "    \n",
    "    # Input signatures for training step as a tf.function\n",
    "    x_signatures = tf.data.DatasetSpec(tf.TensorSpec(shape = (num_tf, None, num_feature_type), dtype = tf.float32))\n",
    "    y_signatures = tf.data.DatasetSpec(tf.TensorSpec(shape = (None,), dtype = tf.float32))\n",
    "    \n",
    "    # training step and MTL loss function defined here\n",
    "    @tf.function(input_signature = (x_signatures, y_signatures))\n",
    "    def train_step(x_batches, y_batches):\n",
    "\n",
    "        # Record how loss value is computed for performing automatic differentiation later.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Run one round of forward pass for all models\n",
    "            y_pred = tf.TensorArray(tf.float32, size = num_genes)\n",
    "            for k,X in zip(tuple(range(num_genes)), x_batches):\n",
    "                y_pred = y_pred.write(k, models[k](tf.unstack(X), training = True))\n",
    "            \n",
    "            # Compute MSE loss\n",
    "            MSE = tf.TensorArray(tf.float32, size = num_genes)\n",
    "            for k,y in zip(tuple(range(num_genes)), y_batches):\n",
    "                MSE = MSE.write(k, tf.reduce_mean(mse(y, y_pred.read(k))))\n",
    "            MSE = MSE.gather(tf.range(num_genes))\n",
    "            \n",
    "            # Get the weights of the first and second FC layers. These layers are shared and their tracenorm loss will be calculated.\n",
    "            sharable_weights = tf.TensorArray(tf.float32, size = 2)\n",
    "\n",
    "            # Concat the first sharable FC layer from all models\n",
    "            stacked_layers1 = tf.TensorArray(tf.float32, num_genes)\n",
    "            for k,model in enumerate(models):\n",
    "                stacked_layers1 = stacked_layers1.write(k, model.trainable_weights[num_tf*2])\n",
    "            stacked_layers1 = stacked_layers1.gather(tf.range(num_genes))\n",
    "            \n",
    "            # Concat the second sharable FC layer from all models\n",
    "            stacked_layers2 = tf.TensorArray(tf.float32, num_genes)\n",
    "            for k,model in enumerate(models):\n",
    "                stacked_layers2 = stacked_layers2.write(k, model.trainable_weights[num_tf*2 + 2])\n",
    "            stacked_layers2 = stacked_layers2.gather(tf.range(num_genes))\n",
    "            \n",
    "            # Compute tracenorm from the two concatenated layer weight matrices\n",
    "            tracenorm = tf.TensorArray(tf.float32, 2)    \n",
    "            tracenorm = tracenorm.write(0,trace_norm(stacked_layers1))\n",
    "            tracenorm = tracenorm.write(1,trace_norm(stacked_layers2))\n",
    "            tracenorm = tracenorm.gather(tf.range(2))\n",
    "            \n",
    "            # Compute final loss. loss = MSE + lambda*tracenorm. (lambda = 0.01 for convenience)\n",
    "            loss = tf.reduce_mean(MSE) + tf.math.multiply(Lambda, tf.reduce_mean(tracenorm))\n",
    "\n",
    "        '''\n",
    "        Here gradients are calculated \n",
    "        'unconnected_gradients=tf.UnconnectedGradients.ZERO' ensures that\n",
    "        gradients for other task-specific layer other than the current one\n",
    "        are zeros.\n",
    "        '''\n",
    "        grads_all = tape.gradient(loss,\n",
    "                              [model.trainable_weights for model in models],\n",
    "                              unconnected_gradients=tf.UnconnectedGradients.ZERO)\n",
    "        \n",
    "        # Run one step of gradient descent by updating the weights.\n",
    "        for grad,model in zip(grads_all, models):\n",
    "            optimizer.apply_gradients(zip(grad, model.trainable_weights))\n",
    "        \n",
    "        return(loss, tf.reduce_mean(MSE))\n",
    "    \n",
    "    # Training epochs\n",
    "    for i in range(n_epochs):\n",
    "\n",
    "        # Generate sampling indices for each batch\n",
    "        # Number of batches are dependent on the gene with the most training examples (N).\n",
    "        # For other genes, examples are resampled if they have smaller sample sizes.\n",
    "        tmp = [(gene,sample.shape[0]) for gene,sample in y_train.items()]\n",
    "        tmp = sorted(tmp, key = lambda x: x[1], reverse = True)\n",
    "        max_size = tmp[0][1]\n",
    "\n",
    "        # Get sample indices for each training step\n",
    "        idx_iter = dict()\n",
    "        for gene,size in tmp:\n",
    "            idx = np.arange(size)\n",
    "            np.random.shuffle(idx)\n",
    "            idx = np.resize(idx, max_size)\n",
    "            idx_iter[gene] = np.split(idx, np.arange(batch_size,idx.shape[0],batch_size))\n",
    "        n_iter = len(idx_iter[gene])\n",
    "\n",
    "        # Training loop\n",
    "        for j in range(n_iter):\n",
    "            begin = time()\n",
    "\n",
    "            # Get training data batches for each training step (one batch per gene).\n",
    "            x_train_batches = []\n",
    "            y_train_batches = []\n",
    "            for k,gene in enumerate(cluster_genes):\n",
    "                x_train_batches.append([tf.cast(feature[idx_iter[gene][j],], dtype = tf.float32) for feature in X_train[gene]])\n",
    "                y_train_batches.append(tf.cast(y_train[gene][idx_iter[gene][j]], dtype = tf.float32)) \n",
    "            \n",
    "            # Wrap the data using tf.data.Dataset\n",
    "            x_batches = tf.data.Dataset.from_tensor_slices(x_train_batches)\n",
    "            y_batches = tf.data.Dataset.from_tensor_slices(y_train_batches)\n",
    "            \n",
    "            # Run one step of training\n",
    "            loss, MSE = train_step(x_batches, y_batches)\n",
    "            end = time()\n",
    "            spent = np.round(end - begin, 1)\n",
    "\n",
    "            print(\"Epoch {}/{}, Iter {}/{}, loss value: {}, MSE: {}, {}s used\".format(str(i+1),\n",
    "                                                                                str(n_epochs),\n",
    "                                                                                str(j+1),\n",
    "                                                                                str(n_iter),                                                                                          \n",
    "                                                                                str(loss.numpy()),\n",
    "                                                                                str(MSE.numpy()),\n",
    "                                                                                str(spent)))\n",
    "    '''\n",
    "    Save models\n",
    "    '''\n",
    "    print(\"Saving models ... {}\".format(datetime.datetime.now().ctime()))\n",
    "    for k,gene in enumerate(cluster_genes):\n",
    "        models[k].save_weights(f\"results/full_model/{gene}-{tissue}-rep{rep}\")\n",
    "    return(None)\n",
    "\n",
    "# Train ensemble model for each cluster, run for five reps.\n",
    "res = Parallel(n_jobs = n_jobs)(delayed(train)(tissue, cluster, n_epochs, batch_size, rep)\n",
    "                              for cluster,rep in iterator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow27",
   "language": "python",
   "name": "tensorflow27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
