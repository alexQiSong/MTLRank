{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Load the list of TF names (Ensemble ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = pd.read_csv(\"data/raw/tf/tf_list.csv\",index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2. Read ensembl ID to gene symbol mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_to_symbol = pd.read_csv(\"data/raw/id_mapping/ensembl_to_symbol.csv\",index_col = 0)\n",
    "ensembl_to_symbol.index = ensembl_to_symbol[\"ensembl_id\"]\n",
    "\n",
    "# Drop duplicates\n",
    "ensembl_to_symbol = ensembl_to_symbol.loc[~ensembl_to_symbol.index.duplicated(),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3. Read velocity and expression matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rpkm = dict()\n",
    "with h5py.File('data/processed/rpkm/rpkm.hdf5', 'r') as f:\n",
    "    for tissue in f.keys():\n",
    "        \n",
    "        # scale the rpkm by log10\n",
    "        rpkm[tissue] = pd.DataFrame(np.log10(np.array(f[tissue]['exp'])+1),\n",
    "                                        index = np.array(f[tissue]['barcode']).astype(str),\n",
    "                                        columns = np.array(f[tissue]['ensembl']).astype(str))\n",
    "\n",
    "velo = dict()\n",
    "with h5py.File('data/processed/velo/velo.hdf5', 'r') as f:\n",
    "    for tissue in f.keys():\n",
    "        velo[tissue] = pd.DataFrame(np.array(f[tissue]['velo']),\n",
    "                                        index = np.array(f[tissue]['barcode']).astype(str),\n",
    "                                        columns = np.array(f[tissue]['ensembl']).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4. Train L1 model for each gene in each tissue. Use TF expressions to predict gene velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qisong/anaconda3/envs/tf2/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kidney_Left finished\n",
      "Large_Intestine finished\n",
      "Liver finished\n",
      "Lung_Right finished\n",
      "Lymph_Node finished\n",
      "Spleen finished\n",
      "Thymus finished\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pdb\n",
    "\n",
    "# Train model by 5 fold cv and return R2 score\n",
    "def test_model(X, X_col, Y, Y_col):\n",
    "    \n",
    "    r2 = []\n",
    "    selected_tfs = []\n",
    "    X = csr_matrix(X)\n",
    "    for i in range(Y.shape[1]):\n",
    "        model = linear_model.Lasso(alpha=0.1)\n",
    "        current_gene = Y_col[i]\n",
    "        \n",
    "        # Exclude the current gene to predict from the TF-cell expression matrix\n",
    "        X_run = X.copy()\n",
    "        X_run[:,X_col == current_gene] = 0\n",
    "        \n",
    "        # exclude nan values\n",
    "        select = ~np.isnan(Y[:,i])\n",
    "        X_select = X_run[select,]\n",
    "        y_select = Y[select,i]\n",
    "        \n",
    "        # Compute R2 by 5 fold-cross-validation\n",
    "        r2.append(np.mean(cross_val_score(model, X_select, y_select, cv=5)))\n",
    "    \n",
    "        # Get list of selected tfs by training on whole dataset\n",
    "        model = linear_model.Lasso(alpha=0.1)\n",
    "        model.fit(X_select, y_select)\n",
    "        selected_tfs.append(np.where(model.coef_ != 0)[0])\n",
    "    return([r2, selected_tfs])\n",
    "\n",
    "r2_all = []\n",
    "selected_tfs_all = []\n",
    "res_all = []\n",
    "n_jobs = 14 # This is number of CPU cores to use. Modify it to suit your own machine.\n",
    "\n",
    "for tissue in rpkm.keys():\n",
    "    \n",
    "    X = rpkm[tissue].values\n",
    "    Y = velo[tissue].values\n",
    "    \n",
    "    X_cols = rpkm[tissue].columns\n",
    "    Y_splits = np.array_split(Y, n_jobs, axis = 1)\n",
    "    Y_col_splits = np.array_split(velo[tissue].columns,14)\n",
    "    \n",
    "    res = Parallel(n_jobs=n_jobs)(delayed(test_model)(X, X_cols, Y_split, Y_col_split) \n",
    "                              for Y_split,Y_col_split in zip(Y_splits,Y_col_splits))\n",
    "    \n",
    "    r2 = list(itertools.chain(*[each[0] for each in res])) \n",
    "    selected_tfs = list(itertools.chain(*[each[1] for each in res]))\n",
    "    r2_all.append(r2)\n",
    "    selected_tfs_all.append(selected_tfs)\n",
    "    print(\"{} finished\".format(tissue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4. Save L1 model results\n",
    "ensembl ids were mapped to hgnc symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_res = []\n",
    "for r2,tfs_idx,tissue in zip(r2_all,selected_tfs_all,rpkm.keys()):\n",
    "    \n",
    "    l1_res.append(pd.DataFrame({'tissue':tissue,\n",
    "                                   'r2':r2,\n",
    "                                   'gene_ensembl':velo[tissue].columns,\n",
    "                                   'gene_hgnc':ensembl_to_symbol.loc[velo[tissue].columns,][\"gene_symbol\"].values\n",
    "                                  })\n",
    "                    )\n",
    "    \n",
    "    # Get the selected TF ensembl ids\n",
    "    tf_ensembl = []\n",
    "    tf_hgnc = []\n",
    "    \n",
    "    \n",
    "    for i,gene in enumerate(velo[tissue].columns):\n",
    "        if tfs_idx[i].shape[0] > 0:\n",
    "            ensembl_ids = rpkm[tissue].columns[tfs_idx[i]]\n",
    "            hgnc_ids = ensembl_to_symbol.loc[ensembl_ids,][\"gene_symbol\"].values.astype(str)\n",
    "            \n",
    "            tf_ensembl.append(\" \".join(ensembl_ids))\n",
    "            tf_hgnc.append(\" \".join(hgnc_ids))\n",
    "        else:\n",
    "            tf_ensembl.append(\"\")\n",
    "            tf_hgnc.append(\"\")\n",
    "    \n",
    "    l1_res[-1][\"tf_ensembl\"] = tf_ensembl\n",
    "    l1_res[-1][\"tf_hgnc\"] = tf_hgnc\n",
    "l1_res = pd.concat(l1_res)\n",
    "l1_res = l1_res.sort_values(by = [\"tissue\",\"r2\"], ascending = False)\n",
    "l1_res.to_csv(\"results/r2/lasso_r2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
