{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1. Read the QC report file for all TFs and filter out low quality TFs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to download the QC table (named as \"**human_factor_full_QC**\") by yourself from CistromeDB: http://cistrome.org/db/#/bdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc = pd.read_csv(\"data/raw/cistromedb/human_factor_full_QC.txt\",sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From http://cistrome.org/chilin/_downloads/instructions.pdf\n",
    "1. FastQC is the sample’s median sequence quality scores. ChiLin calculates these scores using the\n",
    "FastQC software[2]. **A good sequence quality score is ≥ 25.**\n",
    "2. Original total reads is the sample’s raw total reads number.\n",
    "3. Uniquely mapped reads is the number of reads with mapping quality above 1. First, ChiLin aligns\n",
    "reads onto user-specified genomes. Then, it filters the SAM files. The **uniquely mapped RATIO** is the\n",
    "uniquely mapped reads divided by the total reads. **A good uniquely mapped ratio is ≥ 60%.**\n",
    "4. Unique locations of 4M reads is the number of genomic locations with one or more uniquely mapped\n",
    "reads (unique locations) from sub-sampled 4M reads. Unique locations ratio unique locations number\n",
    "divided by total number of uniquely mapped reads. ChiLin estimates NRF by dividing the number of\n",
    "unique locations by 4M sampled uniquely mapped reads. If reads are less than 4M, then ChiLin uses\n",
    "the total reads instead. ChiLin reports number of unique locations and the unique locations ratio. A\n",
    "good unique locations of 4M reads should be ≥ 70%.\n",
    "5. Locations with only 1 read from 4M reads number (ratio) is the number of locations with read\n",
    "number equal to 1 (N1). The ratio is N1 divided by 4M reads unless the total reads is less than 4M, in\n",
    "which case the total reads is used. A good score for this metric is > 70%.\n",
    "6. PBC of 4M reads is N1 (see 5) divided by unique locations (see 4). **A good PBC score is ≥ 80%.**\n",
    "7. Fragment size of 4M reads is in silico estimation of your size selection through maximum cross\n",
    "correlation. The estimation should to be close to the size selected in your experiment.\n",
    "8. Exon/DHS/Promoter ratio of 4M reads is the estimated ratio of reads falling in these regions (from\n",
    "a 4M reads sub-sample). Exons regions are defined as the merged exons regions from the RefSeq\n",
    "gene table. Promoter regions are defined as the RefSeq TSS +/- 2kb regions. Union DHS regions are\n",
    "called from ENCODE II UW DNase-seq Hypersensitive regions. The IP group samples should have\n",
    "higher reads ratios than the control group samples.\n",
    "9. **FRiP of 4M non-chrM reads is used for evaluating the signal to noise ratio.** First, ChiLin removes\n",
    "chrM reads from the total reads. Then ChiLin sub-samples 4M of these reads. Finally, it calculates\n",
    "the ratio of the sub-sample which fall under the called peaks. **A good FRiP score is ≥ 1%.**\n",
    "10. Replicates total peaks are the total peaks number called by MACS2 with fixed extension size and q\n",
    "value cutoff. A good peaks number depends on your experiment.\n",
    "11. Replicates 10 fold confident peaks are the number of peaks called by MACS2 where the fold change\n",
    "is ≥ 10. **A good number is above 500**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select samples with high quality, total number of selected TFs = 623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc = qc.loc[(qc.FastQC >= 25) & \n",
    " (qc.UniquelyMappedRatio >= 0.6) &\n",
    " (qc.PBC > 0.8) &\n",
    " (qc.FRiP > 0.01) &\n",
    " (qc.PeaksFoldChangeAbove10 > 500), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change SMAD2/3 -> SMAD23 so that we can use the TF name as file name\n",
    "qc.loc[qc[\"Factor\"] == \"SMAD2/3\",\"Factor\"] = \"SMAD23\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step2. Check number of cells, and number of peaks for each tissue**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need download the scATAC-seq datasets with the sample IDs shown in the following cell. These datasets can be downloaded from the HuBMap data portal: https://portal.hubmapconsortium.org/. Alternatively, you may perfrom batch download using commandline tool as described in https://software.docs.hubmapconsortium.org/clt/index.html. This script assumes you have downloaded the data into the folder **data/raw/atac/** and the subfolders in it were all named by sample ID. For example, for a sample with the ID \"73471388c8fb65d21f964a1df408db1f\", its ATAC-seq bed file (peaks.combined.bed) can be found inside data/raw/rna/73471388c8fb65d21f964a1df408db1f/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73471388c8fb65d21f964a1df408db1f\n",
      "7e6657cc565a7d89a9041dece3816ffa\n",
      "Liver completed, 50748 cells, 113726 peaks\n",
      "bf0f0ca3a57f5d82141c27f98ec6eb40\n",
      "01d94c78c858b9944b4bbdd5b273c2bd\n",
      "225d7c6d4843b97ec4f6a9acc0f82dda\n",
      "59e8b98ce6094e0b73c627edb5b00a09\n",
      "921c37b95f73de863c95dd97c3393d1b\n",
      "6e89c8eb27e1ef96bbbf4c48447dc4dc\n",
      "53cc1f9c21907d8f7880eed6828ba8a1\n",
      "fc5eb8a90d7caa1b8ea5d920b3d289c9\n",
      "1324f228f23b7ec156c6c58a66bd58fd\n",
      "4c390581222e1b00966bb7406f6f8073\n",
      "29610875ec053f0efb6c493c8329c1b8\n",
      "d4493657cde29702c5ed73932da5317c\n",
      "Heart completed, 310661 cells, 270033 peaks\n",
      "75d8ae60d6d2be8ba71ff5213940917d\n",
      "8a3b11f9934baa372696c240fcc14876\n",
      "9d534e3b706b1e88f4960077e651aa28\n",
      "81c9ebd67ad019ef2589f883d31e25c9\n",
      "f8de2f78bb01fbd41dd71cedd2b60750\n",
      "751eb90f02674b9c77cfed31155cd855\n",
      "d595473c117c90b357b1584f652fbcbc\n",
      "ccdb215b6931b3989b3960adf3ac4657\n",
      "717ec64b27b77e6ede9cb531b4edd786\n",
      "5c469cc1e2efa28c64389e1ff1549207\n",
      "73a351ecd690eb11ab6032445bcc7ae2\n",
      "2c1f879670564dff2e541e239ca96344\n",
      "88b6918eac299aa7a2bd0a8e8cf75236\n",
      "0699ea08c9e0bfbed61bcf7e01245936\n",
      "fb6757b606ac35be7fa85062fde9c2e1\n",
      "9282f8e2603962e6fd81de71190fe270\n",
      "8b6304135a1eb99d79c3bdc7cbbaa758\n",
      "668cac1d02b81af2de3a324e071d9984\n",
      "5989aab5470cba857a9bf6ab08f2b56b\n",
      "02900751a754e9c9bd0f09cb7480b786\n",
      "0014847f4cc27aa4e0049f8896aff673\n",
      "e2ac3b627b779d04894a93eadb2d607b\n",
      "Kidney (Left) completed, 48264 cells, 8887 peaks\n",
      "c62e8e0f3ab247175965c517231fceed\n",
      "9b21d48002e2f02d8654feeb3f0867bd\n",
      "06254c0d354ac6af7ea5d73ebc8b7f0c\n",
      "82ffdc56b04f0b4c8bffeacb635e225f\n",
      "7f90e8096c701c2025c744f82f1d2600\n",
      "692ed073768633721f33a542d088da69\n",
      "Large Intestine completed, 8368 cells, 98077 peaks\n",
      "880300ed65bc837c3a81aeea474e395c\n",
      "Spleen completed, 11857 cells, 27645 peaks\n",
      "b2fa01d2afd1d4f8c71d59bc3cbe9f84\n",
      "Lung (Right) completed, 17482 cells, 27371 peaks\n"
     ]
    }
   ],
   "source": [
    "from anndata import read_h5ad\n",
    "import h5py\n",
    "\n",
    "rootdir = \"data/atac\"\n",
    "\n",
    "# Iterate over tissues, read in cell by bin matrix, and peaks files. Then count number of cells and peaks.\n",
    "for tissue in [\"Liver\",\"Heart\",\"Kidney (Left)\",\"Large Intestine\",\"Spleen\",\"Lung (Right)\"]:\n",
    "    \n",
    "    n_peaks = 0\n",
    "    n_cells = 0\n",
    "    \n",
    "    # Read peaks and cell by bin matrix\n",
    "    for Dir in os.listdir(rootdir + tissue):\n",
    "        if os.path.exists(\"/\".join([rootdir,tissue,Dir,\"peaks.combined.bed\"])) and os.path.exists(\"/\".join([rootdir,tissue,Dir,\"cell_by_gene.hdf5\"])):\n",
    "            print(Dir)\n",
    "            peaks = pd.read_csv(\"/\".join([rootdir,tissue,Dir,\"peaks.combined.bed\"]),\n",
    "                            sep = \"\\t\", header = None)\n",
    "            n_peaks += peaks.shape[0]\n",
    "            n_cells += h5py.File(\"/\".join([rootdir, tissue, Dir, \"cell_by_gene.hdf5\"]),\"r\")['row_names'].shape[0]\n",
    "\n",
    "    print(\"{} completed, {} cells, {} peaks\".format(tissue, n_cells, n_peaks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. Read the scATAC-seq peaks, and build scATAC-seq search tree for each tissue and each chromosome**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liver completed\n",
      "Lung_Right completed\n",
      "Spleen completed\n",
      "Kidney_Left completed\n",
      "Kidney_Right completed\n",
      "Large_Intestine completed\n",
      "Heart completed\n"
     ]
    }
   ],
   "source": [
    "from intervaltree import IntervalTree,Interval\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "rootdir = \"data/atac/\"\n",
    "search_tree = defaultdict(dict)\n",
    "\n",
    "# Iterate over tissues and chromosomes. For each tissue, buid interval trees.\n",
    "for tissue in os.listdir(rootdir):\n",
    "    \n",
    "    # Skip pancreas\n",
    "    if os.path.isdir(rootdir + tissue) and tissue != \"Pancreas\":\n",
    "        peaks = []\n",
    "        for Dir in os.listdir(rootdir + tissue):\n",
    "            peaks.append(pd.read_csv(\"/\".join([rootdir,tissue,Dir,\"peaks.combined.bed\"]),\n",
    "                            sep = \"\\t\")\n",
    "                        )\n",
    "            peaks[-1].columns = [\"chrom\",\"chromStart\",\"chromEnd\"]\n",
    "        \n",
    "        # Combine peaks from the same tissue\n",
    "        peaks = pd.concat(peaks)\n",
    "        peaks['chrom'] = 'chr' + peaks['chrom']\n",
    "\n",
    "        # For each chromosome, build an interval tree for search.\n",
    "        for chrom,df in peaks.groupby('chrom'):\n",
    "            \n",
    "            # Remove parenthesis and spaces in the tissue name\n",
    "            tissue = re.sub('\\s+',\"_\",tissue)\n",
    "            tissue = re.sub('\\(',\"\",tissue)\n",
    "            tissue = re.sub('\\)',\"\",tissue)\n",
    "    \n",
    "            search_tree[tissue][chrom] = IntervalTree(Interval(row.chromStart,row.chromEnd) for i,row in df.iterrows())\n",
    "            search_tree[tissue][chrom].merge_overlaps()\n",
    "        print(\"{} completed\".format(tissue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3. For each ChIP-seq peaks of TF, compute the overlapping regions with scATAC-seq, and map the peak to nearest genes.**\n",
    "Need to install ChIPseeker R package before performing this step. Note that for T transcription factor, R will recognize character \"T\" as **True** value instead of character \"T\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APOBEC3B done;\n",
      "ARID1A done;\n",
      "AHR done;\n",
      "AFF1 done;\n",
      "ASXL1 done;\n",
      "ASH2L done;\n",
      "ARID2 done;\n",
      "ASCL1 done;\n",
      "ARRB1 done;\n",
      "AFF4 done;\n",
      "ARID3A done;\n",
      "ATF2 done;\n",
      "ATF1 done;\n",
      "BARX2 done;\n",
      "BATF3 done;\n",
      "BACH2 done;\n",
      "BCL11B done;\n",
      "BACH1 done;\n",
      "BATF done;\n",
      "ATF4 done;\n",
      "BCLAF1 done;\n",
      "BIRA done;\n",
      "BPTF done;\n",
      "BRD1 done;\n",
      "BCOR done;\n",
      "BRCA1 done;\n",
      "BCL6 done;\n",
      "BMI1 done;\n",
      "BHLHE40 done;\n",
      "BRD3 done;\n",
      "BRD2 done;\n",
      "BCL3 done;\n",
      "BRD9 done;\n",
      "C17orf49 done;\n",
      "C11orf30 done;\n",
      "CBX8 done;\n",
      "CBX5 done;\n",
      "CBX1 done;\n",
      "CBFB done;\n",
      "CCNT2 done;\n",
      "CDK6 done;\n",
      "ATF3 done;\n",
      "CDK7 done;\n",
      "CBX3 done;\n",
      "CDX2 done;\n",
      "CHD1 done;\n",
      "CEBPD done;\n",
      "CHD8 done;\n",
      "CLOCK done;\n",
      "CEBPG done;\n",
      "CDK9 done;\n",
      "CHD2 done;\n",
      "CHRM2 done;\n",
      "CDK8 done;\n",
      "CPSF3L done;\n",
      "CEBPA done;\n",
      "CREB3 done;\n",
      "CREM done;\n",
      "CNOT3 done;\n",
      "CTBP1 done;\n",
      "CREBBP done;\n",
      "CTNNB1 done;\n",
      "CTCFL done;\n",
      "CUX1 done;\n",
      "DCP1A done;\n",
      "DDX21 done;\n",
      "DDX20 done;\n",
      "DAXX done;\n",
      "DEAF1 done;\n",
      "DIDO1 done;\n",
      "DEK done;\n",
      "DLX1 done;\n",
      "DPF1 done;\n",
      "DNMT3A done;\n",
      "DRAP1 done;\n",
      "E2F3 done;\n",
      "DPF2 done;\n",
      "E2F4 done;\n",
      "E2F5 done;\n",
      "DUX4 done;\n",
      "E2F6 done;\n",
      "CREB1 done;\n",
      "E2F7 done;\n",
      "E2F8 done;\n",
      "E2F1 done;\n",
      "EBNA3C done;\n",
      "EBF3 done;\n",
      "EGLN2 done;\n",
      "EBF1 done;\n",
      "EGR3 done;\n",
      "EED done;\n",
      "ELK3 done;\n",
      "EGR2 done;\n",
      "EGR1 done;\n",
      "EMSY done;\n",
      "ELK1 done;\n",
      "ELL2 done;\n",
      "ELF3 done;\n",
      "EMX1 done;\n",
      "EP400 done;\n",
      "ESCO2 done;\n",
      "ELF1 done;\n",
      "EOMES done;\n",
      "ESRRA done;\n",
      "ETS2 done;\n",
      "ETV1 done;\n",
      "ETV5 done;\n",
      "ETV4 done;\n",
      "ETV6 done;\n",
      "EWSR1 done;\n",
      "EZH1 done;\n",
      "ETS1 done;\n",
      "EZH2 done;\n",
      "FAM208A done;\n",
      "FGFR1 done;\n",
      "FEZF1 done;\n",
      "ERG done;\n",
      "FAIRE done;\n",
      "FOSL1 done;\n",
      "FOXH1 done;\n",
      "FLI1 done;\n",
      "FOXJ2 done;\n",
      "FOXK1 done;\n",
      "FOSL2 done;\n",
      "FOXK2 done;\n",
      "FOXO1 done;\n",
      "BRD4 done;\n",
      "FOXO3 done;\n",
      "FOS done;\n",
      "FOXP3 done;\n",
      "FOXP1 done;\n",
      "FUS done;\n",
      "FOXM1 done;\n",
      "FXR2 done;\n",
      "GABP done;\n",
      "GATAD1 done;\n",
      "CEBPB done;\n",
      "GATA6 done;\n",
      "GATAD2B done;\n",
      "GLI2 done;\n",
      "FOXA2 done;\n",
      "GABPA done;\n",
      "GATA4 done;\n",
      "GMEB2 done;\n",
      "GLIS2 done;\n",
      "GLIS1 done;\n",
      "GREB1 done;\n",
      "GRIP1 done;\n",
      "GTF2F1 done;\n",
      "GTF3C2 done;\n",
      "GTF2B done;\n",
      "GATA2 done;\n",
      "GATA1 done;\n",
      "GTF2I done;\n",
      "GTF3C5 done;\n",
      "AR done;\n",
      "HAND2 done;\n",
      "HBP1 done;\n",
      "HCFC1 done;\n",
      "GRHL2 done;\n",
      "HDAC3 done;\n",
      "HES1 done;\n",
      "HHEX done;\n",
      "HES2 done;\n",
      "HDAC1 done;\n",
      "HEY1 done;\n",
      "HEXIM1 done;\n",
      "HINFP done;\n",
      "HDAC2 done;\n",
      "HMBOX1 done;\n",
      "HMGN3 done;\n",
      "HIRA done;\n",
      "HIF1A done;\n",
      "GATA3 done;\n",
      "HNF1B done;\n",
      "HNF1A done;\n",
      "HLF done;\n",
      "HOXA9 done;\n",
      "HOXA6 done;\n",
      "HNF4A done;\n",
      "EP300 done;\n",
      "HOTAIR done;\n",
      "HOXC9 done;\n",
      "ICE1 done;\n",
      "HNF4G done;\n",
      "HSF1 done;\n",
      "INTS12 done;\n",
      "IKZF2 done;\n",
      "ING2 done;\n",
      "IRF3 done;\n",
      "INTS11 done;\n",
      "INTS3 done;\n",
      "JARID2 done;\n",
      "IRF4 done;\n",
      "JMJD6 done;\n",
      "IRF1 done;\n",
      "IKZF1 done;\n",
      "JMJD1C done;\n",
      "JUNB done;\n",
      "KAT7 done;\n",
      "KDM3B done;\n",
      "KDM4B done;\n",
      "HOXB13 done;\n",
      "KDM2B done;\n",
      "KDM4C done;\n",
      "KDM5A done;\n",
      "KDM4A done;\n",
      "KDM6B done;\n",
      "JUN done;\n",
      "KLF12 done;\n",
      "KLF10 done;\n",
      "KDM1A done;\n",
      "KLF1 done;\n",
      "KLF11 done;\n",
      "JUND done;\n",
      "KLF16 done;\n",
      "KLF5 done;\n",
      "KLF8 done;\n",
      "KLF15 done;\n",
      "H2AZ done;\n",
      "KLF4 done;\n",
      "KMT2B done;\n",
      "KLF9 done;\n",
      "LANA done;\n",
      "KMT2D done;\n",
      "KDM5B done;\n",
      "LDB1 done;\n",
      "ESR1 done;\n",
      "L3MBTL2 done;\n",
      "LEF1 done;\n",
      "LHX2 done;\n",
      "LARP7 done;\n",
      "LIN9 done;\n",
      "LEO1 done;\n",
      "KMT2A done;\n",
      "LMO1 done;\n",
      "LYL1 done;\n",
      "LMO2 done;\n",
      "MAF done;\n",
      "MAML3 done;\n",
      "MAPK1 done;\n",
      "MAFG done;\n",
      "MAFF done;\n",
      "MBD1_isoform1 done;\n",
      "MBD1_isoform2 done;\n",
      "MBTD1 done;\n",
      "MBD3 done;\n",
      "MBD2 done;\n",
      "MECP2 done;\n",
      "MED12 done;\n",
      "MEF2D done;\n",
      "MEF2A done;\n",
      "MAZ done;\n",
      "MEIS1 done;\n",
      "MEN1 done;\n",
      "MEF2B done;\n",
      "MAFK done;\n",
      "MIER1 done;\n",
      "MITF done;\n",
      "MNT done;\n",
      "MLLT1 done;\n",
      "MTA2 done;\n",
      "MTA3 done;\n",
      "MYBL2 done;\n",
      "MYCN done;\n",
      "MYH11 done;\n",
      "MYF5 done;\n",
      "MXI1 done;\n",
      "MYNN done;\n",
      "MYOG done;\n",
      "MYOD1 done;\n",
      "NCAPG done;\n",
      "NCAPG2 done;\n",
      "MYB done;\n",
      "NCOA1 done;\n",
      "MED1 done;\n",
      "NCAPH2 done;\n",
      "NCOR1 done;\n",
      "NCOR2 done;\n",
      "NANOG done;\n",
      "NELFA done;\n",
      "NFE2L1 done;\n",
      "NELFE done;\n",
      "NFATC1 done;\n",
      "NFIA done;\n",
      "NFE2L2 done;\n",
      "NFIL3 done;\n",
      "NFRKB done;\n",
      "NFE2 done;\n",
      "NFYA done;\n",
      "NFKB1 done;\n",
      "NFYC done;\n",
      "NFYB done;\n",
      "NFIC done;\n",
      "NEUROG2 done;\n",
      "NEUROD1 done;\n",
      "NKRF done;\n",
      "NKX3-1 done;\n",
      "MAX done;\n",
      "NOTCH1 done;\n",
      "NR1H2 done;\n",
      "NR2C2 done;\n",
      "NKX2-1 done;\n",
      "NIPBL done;\n",
      "NR1H3 done;\n",
      "NR2F6 done;\n",
      "NR5A2 done;\n",
      "NR2F1 done;\n",
      "NR4A1 done;\n",
      "OGT done;\n",
      "ORC2 done;\n",
      "OSR2 done;\n",
      "PAX6 done;\n",
      "PATZ1 done;\n",
      "NR2F2 done;\n",
      "NRF1 done;\n",
      "PAX5 done;\n",
      "PBX1 done;\n",
      "PAF1 done;\n",
      "PBX2 done;\n",
      "PGBD3 done;\n",
      "PCGF1 done;\n",
      "PDX1 done;\n",
      "PBX3 done;\n",
      "PHOX2B done;\n",
      "PITX3 done;\n",
      "PHF8 done;\n",
      "PKNOX1 done;\n",
      "PMEL done;\n",
      "POLR2B done;\n",
      "POLR3A done;\n",
      "PML done;\n",
      "POLR2AphosphoS5 done;\n",
      "POLR3D done;\n",
      "PIAS1 done;\n",
      "POU2F2 done;\n",
      "PRAME done;\n",
      "PRDM11 done;\n",
      "PRDM10 done;\n",
      "PPARG done;\n",
      "POU5F1 done;\n",
      "MYC done;\n",
      "PRDM14 done;\n",
      "PRDM1 done;\n",
      "PRDM6 done;\n",
      "OTX2 done;\n",
      "PRKDC done;\n",
      "PTTG1 done;\n",
      "PROX1 done;\n",
      "PRMT1 done;\n",
      "RAG2 done;\n",
      "RAD51 done;\n",
      "RARA done;\n",
      "RARG done;\n",
      "NR3C1 done;\n",
      "RBP2 done;\n",
      "RBBP5 done;\n",
      "REL done;\n",
      "RELB done;\n",
      "RBPJ done;\n",
      "RFX2 done;\n",
      "RFX1 done;\n",
      "REPIN1 done;\n",
      "RNF2 done;\n",
      "RCOR1 done;\n",
      "RPE done;\n",
      "RFX5 done;\n",
      "RUNX1T1 done;\n",
      "RUNX2 done;\n",
      "RXRG done;\n",
      "RYBP done;\n",
      "RXRA done;\n",
      "RUNX3 done;\n",
      "PR done;\n",
      "SCRT1 done;\n",
      "REST done;\n",
      "SETD1A done;\n",
      "SIX5 done;\n",
      "SKI done;\n",
      "SCRT2 done;\n",
      "SMAD2 done;\n",
      "SMAD1 done;\n",
      "RELA done;\n",
      "SIX2 done;\n",
      "SMAD23 done;\n",
      "SMAD5 done;\n",
      "SMAD4 done;\n",
      "SIN3A done;\n"
     ]
    }
   ],
   "source": [
    "# Compute overlapping weights\n",
    "from joblib import Parallel, delayed\n",
    "import subprocess\n",
    "import pdb\n",
    "import shutil\n",
    "\n",
    "# Create tissue subfolder for saving TFs.\n",
    "for tissue in search_tree.keys():\n",
    "    \n",
    "    # remove subfolder if it already exists.\n",
    "    shutil.rmtree(\"data/processed/chip+atac/{}\".format(tissue), ignore_errors=True)\n",
    "    os.mkdir(\"data/processed/chip+atac/{}\".format(tissue))\n",
    "\n",
    "def search_overlap(tf,df):\n",
    "    \n",
    "    # Read all peak files for a TF\n",
    "    peaks = []\n",
    "    for idx,row in df.iterrows():\n",
    "        peaks.append(\n",
    "                        pd.read_csv(\"data/processed/cistromedb/\" + str(row.DCid) + \"_sort_peaks.narrowPeak.bed\",\n",
    "                        sep = \"\\t\",\n",
    "                        header = None)\n",
    "                    )\n",
    "        peaks[-1].columns = [\"chrom\",\n",
    "                         \"chromStart\",\n",
    "                         \"chromEnd\",\n",
    "                         \"name\",\n",
    "                         \"score\",\n",
    "                         \"strand\",\n",
    "                         \"signalValue\",\n",
    "                         \"pValue\",\n",
    "                         \"qValue\",\n",
    "                         \"peak\"]\n",
    "        peaks[-1][\"tf\"] =  np.repeat(row.Factor,peaks[-1].shape[0])\n",
    "        peaks[-1][\"DCid\"] = np.repeat(row.DCid,peaks[-1].shape[0])\n",
    "        \n",
    "    peaks = pd.concat(peaks)\n",
    "\n",
    "    # Search the overlapped between scATAC-seq peaks and ChIP-seq peaks for each TF in each tissue\n",
    "    # each row of 'peaks' represents a peak in ChIP-seq data.\n",
    "    # each 'peaks' table represents all peaks of a TF from ChIP-seq data.\n",
    "    # 1. iterate over all tissues\n",
    "    for tissue,tree in search_tree.items():\n",
    "    \n",
    "        # 2. iterate over all peaks of a TF\n",
    "        res = []\n",
    "        for idx,row in peaks.iterrows():\n",
    "            chrom = row['chrom']\n",
    "            start = row['chromStart']\n",
    "            end = row['chromEnd']\n",
    "            sigVal = row['signalValue']\n",
    "\n",
    "            if chrom in tree:\n",
    "                intervals = tree[chrom][start:end]\n",
    "                intervals = sorted(list(intervals), key = lambda x: x[0])\n",
    "                over_len = 0\n",
    "                for interval in intervals:\n",
    "                    over_len += min(end,interval[1]) - max(start,interval[0])\n",
    "                res.append(over_len/(int(end) - int(start)))\n",
    "            else:\n",
    "                res.append(None)\n",
    "        \n",
    "        # After all peaks of a TF is done. All peaks of the TF is saved as one file, specific to each tissue.\n",
    "        peaks[\"chip_atac_weight\"] = res\n",
    "        outname = \"data/processed/chip+atac/{}/{}.csv\".format(tissue,tf)\n",
    "        peaks.to_csv(outname)\n",
    "\n",
    "        # map TF peaks to nearest genes\n",
    "        commands = [\n",
    "            \"module load singularity\",\n",
    "            \"Rscript annotate_peaks.R {} {}\".format(outname,outname),\n",
    "        ]\n",
    "        commands = \";\".join(commands)\n",
    "        subprocess.run(commands, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        \n",
    "    print(\"{} done;\".format(tf))\n",
    "    return(None)\n",
    "\n",
    "res = Parallel(n_jobs=14,backend='multiprocessing')(delayed(search_overlap)(tf,df) \n",
    "                              for i,(tf,df) in enumerate(qc.groupby(\"Factor\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4. For each tissue, read the results and generate the TF-gene activity matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get non-zero and non-na TF-gene pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Kidney_Left================\n",
      "================Heart================heded\n",
      "================Lung_Right================\n",
      "================Kidney_Right================\n",
      "================Large_Intestine================\n",
      "================Spleen================eded\n",
      "================Liver================heded\n",
      "ZNF24.csv done, 623/623 finisheddinisheded\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "folder = \"data/processed/chip+atac/\"\n",
    "os.chdir(folder)\n",
    "tissues = os.listdir()\n",
    "tf_gene = defaultdict(list)\n",
    "\n",
    "for tissue in tissues:\n",
    "    os.chdir(folder + tissue)\n",
    "    print(\"================{}================\".format(tissue))\n",
    "    tf_files = os.listdir() \n",
    "    \n",
    "    for idx,tf_file in enumerate(tf_files):\n",
    "        df = pd.read_csv(tf_file)\n",
    "        tf_gene[tissue].append(df.loc[~df[\"gene\"].isna() & (df[\"chip_atac_weight\"] != 0),[\"tf\",\"gene\",\"chip_atac_weight\"]])\n",
    "        print(\"{} done, {}/{} finished\".format(tf_file, idx+1, len(tf_files)),end = '\\r')\n",
    "    tf_gene[tissue] = pd.concat(tf_gene[tissue])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get mean of weights for each TF-gene pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Kidney_Left================\n",
      "================Heart================\n",
      "================Lung_Right================\n",
      "================Kidney_Right================\n",
      "================Large_Intestine================\n",
      "================Spleen================\n",
      "================Liver================\n",
      "1125664/4632677 done 24.3% finishedd\r"
     ]
    }
   ],
   "source": [
    "tf_gene_mean = defaultdict(list)\n",
    "for tissue,tab in tf_gene.items():\n",
    "    print(\"================{}================\".format(tissue))\n",
    "    total_num = tab.loc[:,[\"tf\",\"gene\"]].drop_duplicates().shape[0]\n",
    "    for idx,((tf,gene),df) in enumerate(tab.groupby([\"tf\",\"gene\"])):\n",
    "        tf_gene_mean[tissue].append({\"tf\":tf,\n",
    "         \"gene\":gene,\n",
    "         \"chip_atac_weight\":df[\"chip_atac_weight\"].mean()})\n",
    "        print(\"{}/{} done {}% finished\".format(idx+1, total_num, np.round((idx+1)/total_num * 100,2)),end = '\\r')\n",
    "    tf_gene_mean[tissue] = pd.DataFrame(tf_gene_mean[tissue])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sum of weights for each TF-gene pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_gene_sum = defaultdict(list)\n",
    "for tissue,tab in tf_gene.items():\n",
    "    tf_gene_sum[tissue] = tab.groupby([\"tf\",\"gene\"], as_index = False)['chip_atac_weight'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data frames to tf-gene activities matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_gene_mat_mean = dict()\n",
    "for tissue,mat in tf_gene_mean.items():\n",
    "    tf_gene_mat_mean[tissue] = mat.pivot(index = \"tf\", columns = \"gene\", values = \"chip_atac_weight\")\n",
    "\n",
    "tf_gene_mat_sum = dict()\n",
    "for tissue,mat in tf_gene_sum.items():\n",
    "    tf_gene_mat_sum[tissue] = mat.pivot(index = \"tf\", columns = \"gene\", values = \"chip_atac_weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save tf-gene activities matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tissue in tf_gene_mat_mean.keys():\n",
    "    tf_gene_mat_mean[tissue].to_csv(\"data/processed/tf_activity/mean_tf/{}_tfGeneMat.csv\".format(tissue))\n",
    "    \n",
    "for tissue in tf_gene_mat_sum.keys():\n",
    "    tf_gene_mat_sum[tissue].to_csv(\"data/processed/tf_activity/sum_tf/{}_tfGeneMat.csv\".format(tissue))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
