{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read TF list and ensembl to symbol mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tf_list = pd.read_csv(\"data/raw/tf/tf_list.csv\", index_col = 0)    \n",
    "ensembl_to_symbol = pd.read_csv(\"data/raw/id_mapping/ensembl_to_symbol.csv\",index_col = 0)\n",
    "ensembl_to_symbol = ensembl_to_symbol.loc[~ensembl_to_symbol[\"ensembl_id\"].duplicated(),:]\n",
    "ensembl_to_symbol.index = ensembl_to_symbol[\"ensembl_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load expression data, and TF activitiy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keep only one tissue and TF columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tissue = 'Lung_Right'\n",
    "\n",
    "# First we get indices of TFs\n",
    "with h5py.File('data/processed/rpkm/rpkm.hdf5', 'r') as f:\n",
    "    col_names = np.array(f[tissue]['ensembl']).astype(str)\n",
    "tf_idx = np.where(np.isin(col_names, tf_list[\"Ensembl ID\"].values))[0]\n",
    "\n",
    "# Get expressions only for TF columns \n",
    "with h5py.File('data/processed/rpkm/rpkm.hdf5', 'r') as f:\n",
    "    rpkm = pd.DataFrame(np.log10(np.array(f[tissue]['exp'][:,tf_idx])+1),\n",
    "                                index = np.array(f[tissue]['barcode']).astype(str),\n",
    "                                columns = np.array(f[tissue]['ensembl'][tf_idx]).astype(str))\n",
    "\n",
    "with h5py.File('data/processed/velo/velo.hdf5', 'r') as f:\n",
    "    velo = pd.DataFrame(np.array(f[tissue]['velo']),\n",
    "                                index = np.array(f[tissue]['barcode']).astype(str),\n",
    "                                columns = np.array(f[tissue]['ensembl']).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read TF activity score matrices. Missing values are treated as zeros.  \n",
    "keep only one tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder = \"data/tf_activity/\"\n",
    "\n",
    "tf_gene_mat_mean = pd.read_csv(folder + \"mean_tf/\" + tissue + \"_tfGeneMat.csv\", index_col = 0).transpose()\n",
    "tf_gene_mat_sum = pd.read_csv(folder + \"sum_tf/\" + tissue + \"_tfGeneMat.csv\", index_col = 0).transpose()\n",
    "tf_gene_mat_mean.fillna(0,inplace = True)\n",
    "tf_gene_mat_sum.fillna(0,inplace = True)\n",
    "\n",
    "# scale the value by log2\n",
    "tf_gene_mat_mean = np.log2(tf_gene_mat_mean+1)\n",
    "tf_gene_mat_sum = np.log2(tf_gene_mat_sum+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat the data matrices to keep the consistent TFs and genes.\n",
    "Make rpkm matrix and tf activity matrix have the same tfs  \n",
    "Make velo matrix and tf activity matrix have the same genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_mat_sum = dict()\n",
    "act_mat_mean = dict()\n",
    "    \n",
    "# Find common TF \n",
    "tfmat_cols = pd.DataFrame(tf_gene_mat_mean.columns.values,columns = ['tfmat_cols'])\n",
    "comm_tfs = ensembl_to_symbol.merge(how = 'left',\n",
    "                                    left_on = 'gene_symbol',\n",
    "                                    right_on = \"tfmat_cols\",\n",
    "                                    right = tfmat_cols)\n",
    "comm_tfs = comm_tfs.loc[~comm_tfs['tfmat_cols'].isna(),]\n",
    "comm_tfs = comm_tfs.loc[comm_tfs[\"ensembl_id\"].isin(rpkm.columns),]\n",
    "\n",
    "# Find common (velocity) genes\n",
    "tfmat_rows = pd.DataFrame(tf_gene_mat_mean.index.values,columns = ['tfmat_rows'])\n",
    "comm_genes = ensembl_to_symbol.merge(how = 'left',\n",
    "                                        left_on = 'gene_symbol',\n",
    "                                        right_on = \"tfmat_rows\",\n",
    "                                        right = tfmat_rows)\n",
    "comm_genes = comm_genes.loc[~comm_genes['tfmat_rows'].isna(),]\n",
    "comm_genes = comm_genes.loc[comm_genes[\"ensembl_id\"].isin(velo.columns),]\n",
    "\n",
    "'''\n",
    "Reorder rpkm mat, velo mat, and cluster label vectors. The TF-Gene matrix follow the same tf_order and gene_order. In this order, the columns in upper left\n",
    "corner are the tfs commonly found in rpkm matrix and tf activity matrix and the rows represent the genes commonly found in velo matrix\n",
    "and tf activity matrix.\n",
    "          TF\n",
    "       _______ __\n",
    "      | common|  |\n",
    "Genes |_______|  |\n",
    "      |__________|\n",
    "'''\n",
    "tf_order = pd.concat([comm_tfs['ensembl_id'], pd.Series(np.setdiff1d(rpkm.columns, comm_tfs['ensembl_id']))])\n",
    "gene_order = pd.concat([comm_genes['ensembl_id'], pd.Series(np.setdiff1d(velo.columns, comm_genes['ensembl_id']))])\n",
    "\n",
    "rpkm = rpkm.loc[:,tf_order]\n",
    "velo = velo.loc[:,gene_order]\n",
    "\n",
    "act_mat_sum = np.zeros((velo.shape[1], rpkm.shape[1]))\n",
    "act_mat_mean = np.zeros((velo.shape[1], rpkm.shape[1]))\n",
    "\n",
    "act_mat_sum[:comm_genes.shape[0],:][:,:comm_tfs.shape[0]] = tf_gene_mat_sum.loc[comm_genes['tfmat_rows'],comm_tfs['tfmat_cols']]\n",
    "act_mat_mean[:comm_genes.shape[0],:][:,:comm_tfs.shape[0]] = tf_gene_mat_mean.loc[comm_genes['tfmat_rows'],comm_tfs['tfmat_cols']]\n",
    "\n",
    "act_mat_sum = pd.DataFrame(act_mat_sum, index = gene_order, columns = tf_order)\n",
    "act_mat_mean = pd.DataFrame(act_mat_mean, index = gene_order, columns = tf_order)\n",
    "\n",
    "del tf_gene_mat_mean\n",
    "del tf_gene_mat_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select genes\n",
    "- For liver, we get genes with more than 1000 cells for which the velocity values are available.\n",
    "- For other tissues, we get genes with more than 5000 cells for which the velocity values are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lung_Right has 2380 selected genes.\n"
     ]
    }
   ],
   "source": [
    "# Get cell counts for which the velocity values are available\n",
    "cell_counts = (~velo.isna()).sum(axis = 0)\n",
    "if tissue == \"Liver\":\n",
    "    selected_genes = cell_counts.index[cell_counts > 1000].values\n",
    "else:\n",
    "    selected_genes = cell_counts.index[cell_counts > 5000].values\n",
    "print(\"{} has {} selected genes.\".format(tissue, str(selected_genes.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize rpkm train\n",
    "rpkm = (rpkm - rpkm.mean())/rpkm.std()\n",
    "\n",
    "# Fill na as zeros in rpkm matrices\n",
    "rpkm.fillna(value = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute shap values from trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_model(num_tf, num_feature_type):\n",
    "    inputs = [Input(shape = (num_feature_type,)) for i in range(num_tf)]\n",
    "    concat_layer = [Dense(1, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.l1(0.01))(inp) for inp in inputs]\n",
    "    concat_layer = concatenate(concat_layer)\n",
    "    out = Dense(64, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.l1(0.01))(concat_layer)\n",
    "    out = Dense(32, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.l1(0.01))(out)\n",
    "    out = Dense(16, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.l1(0.01))(out)\n",
    "    out = Dense(1, activation = \"linear\")(out)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = out)\n",
    "    model.compile()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load trained model weights and compute SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import shap\n",
    "from joblib import Parallel,delayed\n",
    "tissue = 'Lung_Right'\n",
    "num_feature_type = 3\n",
    "\n",
    "def run_shap(tissue, gene, rep):\n",
    "\n",
    "    begin = time()\n",
    "\n",
    "    # Build, compile the model, and load up weights from trained model.\n",
    "    model = build_model(num_tf = rpkm.shape[1], num_feature_type = num_feature_type)\n",
    "    model.load_weights(\"results/full_model/{}-{}-rep{}\".format(gene,tissue,rep))\n",
    "\n",
    "    # Prepare inputs\n",
    "    velo_train = velo[gene]\n",
    "\n",
    "    # Remove NAs.\n",
    "    select = ~pd.isna(velo_train)\n",
    "    rpkm_train = rpkm.loc[select,:]\n",
    "\n",
    "    X_train = []\n",
    "\n",
    "    # Generate inputs for current gene\n",
    "    for i,TF in enumerate(rpkm_train.columns):\n",
    "\n",
    "        X_train.append(np.empty((rpkm_train.shape[0], num_feature_type)))\n",
    "\n",
    "        # For current tf, get expression rpkms\n",
    "        X_train[-1][:,0] = rpkm_train[TF].values\n",
    "\n",
    "        # Get TF mean signals and TF sum signals\n",
    "        X_train[-1][:,1] = act_mat_mean.loc[gene,TF]\n",
    "        X_train[-1][:,2] = act_mat_sum.loc[gene,TF]\n",
    "\n",
    "    # Zeros as reference samples\n",
    "    background = [np.zeros((1,3)) for TF in rpkm.columns]\n",
    "\n",
    "    # Compute shap values for all samples\n",
    "    e = shap.DeepExplainer(model, background)\n",
    "    shap_values = e.shap_values(X_train)\n",
    "\n",
    "    # Aggregate shap values (absolute) for each feature (TF)\n",
    "    tf_shap_values = np.array([np.abs(np.abs(TF.sum(axis = 0))).sum() for TF in shap_values[0]])\n",
    "    idx = tf_shap_values.argsort()[::-1] # Descending order\n",
    "    tf_shap_values = tf_shap_values[idx]\n",
    "    tf_ensembl = rpkm.columns[idx]\n",
    "    ranking = pd.DataFrame({\"gene_ensembl\":gene,\"tf_ensembl\":tf_ensembl,\"sum_shap_value\":tf_shap_values,\"rep\":rep})\n",
    "    \n",
    "    # Save TF ranking results\n",
    "    ranking.to_csv(\"results/ranking/shap-val-{}.csv\".format(tissue),mode = \"a\", header = False)\n",
    "    \n",
    "    end = time()\n",
    "    print(\"Completed {}s used\".format(end-begin))\n",
    "    return(None)\n",
    "\n",
    "# Run shap computation in parallel\n",
    "res = Parallel(n_jobs = 16)(delayed(run_shap)(tissue, gene, rep)\n",
    "                              for gene,rep in zip(left_genes, left_reps))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGC TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
