{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Load expression, TF activitiy scores, and ensmebl to symbol mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read RPKM values and velocity values and then scale them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rpkm = dict()\n",
    "with h5py.File('data/raw/rpkm/rpkm.hdf5', 'r') as f:\n",
    "    for tissue in f.keys():\n",
    "        \n",
    "        # scale the rpkm by log10\n",
    "        rpkm[tissue] = pd.DataFrame(np.log10(np.array(f[tissue]['exp'])+1),\n",
    "                                        index = np.array(f[tissue]['barcode']).astype(str),\n",
    "                                        columns = np.array(f[tissue]['ensembl']).astype(str))\n",
    "\n",
    "velo = dict()\n",
    "with h5py.File('data/raw/velo/velo.hdf5', 'r') as f:\n",
    "    for tissue in f.keys():\n",
    "        velo[tissue] = pd.DataFrame(np.array(f[tissue]['velo']),\n",
    "                                        index = np.array(f[tissue]['barcode']).astype(str),\n",
    "                                        columns = np.array(f[tissue]['ensembl']).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read ensmebl to hgnc symbol mapping table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_to_symbol = pd.read_csv(\"data/raw/id_mapping/ensembl_to_symbol.csv\",index_col = 0)\n",
    "ensembl_to_symbol = ensembl_to_symbol.loc[~ensembl_to_symbol[\"ensembl_id\"].duplicated(),:]\n",
    "ensembl_to_symbol.index = ensembl_to_symbol[\"ensembl_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Select genes for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select 500 genes in each tissue for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31281/4239762614.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  l1_res[\"tissue\"] = l1_res['tissue'].str.replace('\\s+',\"_\")\n",
      "/tmp/ipykernel_31281/4239762614.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  l1_res[\"tissue\"] = l1_res['tissue'].str.replace('\\(',\"\")\n",
      "/tmp/ipykernel_31281/4239762614.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  l1_res[\"tissue\"] = l1_res['tissue'].str.replace('\\)',\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart has 500 selected genes.\n",
      "Kidney_Left has 500 selected genes.\n",
      "Large_Intestine has 500 selected genes.\n",
      "Liver has 500 selected genes.\n",
      "Lung_Right has 500 selected genes.\n",
      "Spleen has 500 selected genes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "l1_res = pd.read_csv(\"results/r2/lasso_r2.csv\", index_col=0)\n",
    "\n",
    "num_genes = 500\n",
    "num_samples = 4000\n",
    "\n",
    "# Remove parenthesis and spaces in the tissue name\n",
    "l1_res[\"tissue\"] = l1_res['tissue'].str.replace('\\s+',\"_\")\n",
    "l1_res[\"tissue\"] = l1_res['tissue'].str.replace('\\(',\"\")\n",
    "l1_res[\"tissue\"] = l1_res['tissue'].str.replace('\\)',\"\")\n",
    "\n",
    "selected_genes = dict()\n",
    "\n",
    "for tissue,df in l1_res.groupby(\"tissue\"):\n",
    "    \n",
    "    if tissue in comm_tissues:\n",
    "        \n",
    "        # Select genes that have > 4000 samples\n",
    "        # For Liver, because there fewer samples, threshold is 1000 samples\n",
    "        sample_counts = (~velo[tissue].isna()).sum(axis = 0)\n",
    "        if tissue == \"Liver\":\n",
    "            genes = sample_counts.index[sample_counts > 1000].values\n",
    "        else:\n",
    "            genes = sample_counts.index[sample_counts > 4000].values\n",
    "        genes = np.intersect1d(rpkm[tissue].columns, genes)\n",
    "        df = df.loc[df[\"gene_ensembl\"].isin(genes),]\n",
    "\n",
    "        # Randomly select 500 genes in each tissue\n",
    "        np.random.seed(1000)\n",
    "        if num_genes < df.shape[0]:\n",
    "            idx = np.random.choice(np.arange(df.shape[0]), size=num_genes, replace=False)\n",
    "        else:\n",
    "            idx = np.arange(df.shape[0])\n",
    "        selected_genes[tissue] = df.iloc[idx,][\"gene_ensembl\"].values\n",
    "        print(\"{} has {} selected genes.\".format(tissue, str(selected_genes[tissue].shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the TFs as columns for rpkm_tf mat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_list = pd.read_csv(\"data/raw/tf/tf_list.csv\", index_col = 0)\n",
    "rpkm_tf = dict()\n",
    "for tissue in velo.keys():\n",
    "    \n",
    "    use_tfs = rpkm[tissue].columns.intersection(tf_list[\"Ensembl ID\"])\n",
    "    rpkm_tf[tissue] = rpkm[tissue].loc[:,use_tfs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Train and test models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use expressions to predict expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from arboreto.core import SGBM_KWARGS, RF_KWARGS, EARLY_STOP_WINDOW_LENGTH, fit_model\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "import os, psutil\n",
    "import datetime\n",
    "import scipy\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pdb\n",
    "\n",
    "n_rep = 3\n",
    "test_ratio = 0.1\n",
    "\n",
    "def train_test(tissue, gene, rep):\n",
    "    # Exclude the gene from columns of tf matrix if it appears there\n",
    "    if gene in rpkm_tf[tissue].columns:\n",
    "        train_X = rpkm_tf[tissue].drop(columns = gene).iloc[train_idx[rep],:].values\n",
    "        train_y = rpkm[tissue][gene].iloc[train_idx[rep]].values\n",
    "        test_X = rpkm_tf[tissue].drop(columns = gene).iloc[test_idx[rep],:].values\n",
    "        test_y = rpkm[tissue][gene].iloc[test_idx[rep]].values\n",
    "    else:\n",
    "        train_X = rpkm_tf[tissue].iloc[train_idx[rep],:].values\n",
    "        train_y = rpkm[tissue][gene].iloc[train_idx[rep]].values\n",
    "        test_X = rpkm_tf[tissue].iloc[test_idx[rep],:].values\n",
    "        test_y = rpkm[tissue][gene].iloc[test_idx[rep]].values\n",
    "    \n",
    "    # Convert inputs to sparse matrix\n",
    "    train_X = csr_matrix(train_X)\n",
    "    test_X = csr_matrix(test_X)\n",
    "\n",
    "    #Train regressor model\n",
    "    model = fit_model(regressor_type = \"GBM\",\n",
    "                      regressor_kwargs = SGBM_KWARGS,\n",
    "                      tf_matrix = train_X,\n",
    "                      target_gene_expression = train_y,\n",
    "                      early_stop_window_length = EARLY_STOP_WINDOW_LENGTH,\n",
    "                      seed = None)\n",
    "    \n",
    "    # Test regressor model\n",
    "    pred_y = model.predict(test_X)\n",
    "    r2 = r2_score(test_y, pred_y)\n",
    "    \n",
    "    # Save results\n",
    "    print(\"{},{},{},{}\".format(tissue, gene, str(rep), str(r2)))\n",
    "    with open(\"results/r2/grnboost2_expTFAPredExp_r2.csv\",\"a\") as f:\n",
    "        f.writelines(\"{},{},{},{}\\n\".format(tissue, gene, str(rep), str(r2)))\n",
    "    \n",
    "    return(None)\n",
    "\n",
    "for tissue in velo.keys():\n",
    "    \n",
    "    # Generate train and test sample indices for different replicates\n",
    "    idx = np.arange(rpkm[tissue].shape[0])\n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "    \n",
    "    # Generate train and test cell indices for different replicates\n",
    "    for rep in range(n_rep):\n",
    "        idx1, idx2 = train_test_split(idx, test_size = test_ratio, shuffle = True)\n",
    "        train_idx.append(idx1)\n",
    "        test_idx.append(idx2)\n",
    "    \n",
    "    # Run this number of replicates\n",
    "    for rep in range(n_rep):\n",
    "        res = Parallel(n_jobs = 50)(delayed(train_test)(tissue, gene, rep)\n",
    "                                    for gene in selected_genes[tissue])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGC TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
