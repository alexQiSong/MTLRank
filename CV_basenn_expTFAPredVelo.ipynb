{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Define and compile baseline NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 22:05:41.477873: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_model(num_tf,num_feature_type):\n",
    "    inputs = [Input(shape = (num_feature_type,)) for i in range(num_tf)]\n",
    "    concat_layer = [Dense(1, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.l1(0.01))(inp) for inp in inputs]\n",
    "    concat_layer = concatenate(concat_layer)\n",
    "    out = Dense(64, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.l1(0.01))(concat_layer)\n",
    "    out = Dense(32, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.l1(0.01))(out)\n",
    "    out = Dense(16, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.l1(0.01))(out)\n",
    "    out = Dense(1, activation = \"linear\")(out)\n",
    "    model = Model(inputs = inputs, outputs = out)\n",
    "    model.compile(loss = 'mean_squared_error',\n",
    "                  metrics = 'mean_absolute_error',\n",
    "                  optimizer = \"SGD\")\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Load expression, TF activitiy scores, and ensmebl to symbol mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read RPKM values and velocity values and then scale them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rpkm = dict()\n",
    "with h5py.File('data/processed/rpkm/rpkm.hdf5', 'r') as f:\n",
    "    for tissue in f.keys():\n",
    "        \n",
    "        # scale the rpkm by log10\n",
    "        rpkm[tissue] = pd.DataFrame(np.log10(np.array(f[tissue]['exp'])+1),\n",
    "                                        index = np.array(f[tissue]['barcode']).astype(str),\n",
    "                                        columns = np.array(f[tissue]['ensembl']).astype(str))\n",
    "\n",
    "velo = dict()\n",
    "with h5py.File('data/processed/velo/velo.hdf5', 'r') as f:\n",
    "    for tissue in f.keys():\n",
    "        velo[tissue] = pd.DataFrame(np.array(f[tissue]['velo']),\n",
    "                                        index = np.array(f[tissue]['barcode']).astype(str),\n",
    "                                        columns = np.array(f[tissue]['ensembl']).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read TF activity score matrices. Missing values are treated as zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder = \"data/processed/tf_activity/\"\n",
    "\n",
    "tf_gene_mat_mean = dict()\n",
    "for filename in os.listdir(folder + \"mean_tf/\"):\n",
    "    tissue = \"_\".join(filename.split(\"_\")[:-1])\n",
    "    tf_gene_mat_mean[tissue] = pd.read_csv(\"{}/mean_tf/{}\".format(folder,filename),index_col = 0).transpose()\n",
    "    tf_gene_mat_mean[tissue].fillna(0,inplace = True)\n",
    "\n",
    "tf_gene_mat_sum = dict()\n",
    "for filename in os.listdir(folder + \"sum_tf/\"):\n",
    "    tissue = \"_\".join(filename.split(\"_\")[:-1])\n",
    "    tf_gene_mat_sum[tissue] = pd.read_csv(\"{}/sum_tf/{}\".format(folder,filename),index_col = 0).transpose()\n",
    "    tf_gene_mat_sum[tissue].fillna(0,inplace = True)\n",
    "    \n",
    "    # scale the value by log2\n",
    "    tf_gene_mat_sum[tissue] = np.log2(tf_gene_mat_sum[tissue]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep TFs as columns for rpkm mat.\n",
    "# Keep common genes between tf_gene mat and velocity mat.\n",
    "\n",
    "tf_list = pd.read_csv(\"data/raw/tf/tf_list.csv\", index_col = 0)\n",
    "for tissue in velo.keys():\n",
    "    \n",
    "    use_tfs = rpkm[tissue].columns.intersection(tf_list[\"Ensembl ID\"])\n",
    "    rpkm[tissue] = rpkm[tissue].loc[:,use_tfs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ensembl to hgnc mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_to_symbol = pd.read_csv(\"data/raw/id_maping/ensembl_to_symbol.csv\",index_col = 0)\n",
    "ensembl_to_symbol = ensembl_to_symbol.loc[~ensembl_to_symbol[\"ensembl_id\"].duplicated(),:]\n",
    "ensembl_to_symbol.index = ensembl_to_symbol[\"ensembl_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Select genes for testing\n",
    "For each tissue, train and test the model with reps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select 500 genes in each tissue for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "l1_res = pd.read_csv(\"results/r2/lasso_r2.csv\", index_col=0)\n",
    "\n",
    "num_genes = 500\n",
    "num_samples = 4000\n",
    "\n",
    "# Remove parenthesis and spaces in the tissue name\n",
    "l1_res[\"tissue\"] = l1_res['tissue'].str.replace('\\s+',\"_\")\n",
    "l1_res[\"tissue\"] = l1_res['tissue'].str.replace('\\(',\"\")\n",
    "l1_res[\"tissue\"] = l1_res['tissue'].str.replace('\\)',\"\")\n",
    "\n",
    "selected_genes = dict()\n",
    "\n",
    "for tissue,df in l1_res.groupby(\"tissue\"):\n",
    "        \n",
    "    # Select genes that have > 4000 cells for velocity values\n",
    "    sample_counts = (~velo[tissue].isna()).sum(axis = 0)\n",
    "    genes = sample_counts.index[sample_counts > num_samples].values\n",
    "    df = df.loc[df[\"gene_ensembl\"].isin(genes),]\n",
    "\n",
    "    # Randomly select 500 genes in each tissue\n",
    "    np.random.seed(1000)\n",
    "    if num_genes < df.shape[0]:\n",
    "        idx = np.random.choice(np.arange(df.shape[0]), size=num_genes, replace=False)\n",
    "    else:\n",
    "        idx = np.arange(df.shape[0])\n",
    "    selected_genes[tissue] = df.iloc[idx,][\"gene_ensembl\"].values\n",
    "    print(\"{} has {} selected genes.\".format(tissue, str(selected_genes[tissue].shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Train and test baseline NN models  \n",
    "This step may take a long time to complte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    "from tensorflow import keras\n",
    "from joblib import Parallel,delayed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pdb\n",
    "\n",
    "n_rep = 3\n",
    "n_epoch = 15\n",
    "n_job = 4\n",
    "batch_size = 256\n",
    "test_ratio = 0.1\n",
    "r2 = dict()\n",
    "\n",
    "def train_parallel(tissue):\n",
    "    \n",
    "    # Generate train and test sample indices\n",
    "    idx = np.arange(rpkm[tissue].shape[0])\n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "    for rep in range(n_rep):\n",
    "        idx1, idx2 = train_test_split(idx, test_size = test_ratio, shuffle = True)\n",
    "        train_idx.append(idx1)\n",
    "        test_idx.append(idx2)\n",
    "\n",
    "    # Compile model and keep the initial weights\n",
    "    model = build_model(num_tf = rpkm[tissue].shape[1], num_feature_type = 5)\n",
    "    ini_weights = model.get_weights()\n",
    "        \n",
    "    # Train and test each gene.\n",
    "    r2_mat = np.full((n_rep,selected_genes[tissue].shape[0]),np.nan)\n",
    "    for i,gene in enumerate(selected_genes[tissue]):\n",
    "        for rep in range(n_rep):\n",
    "\n",
    "            # Reformat data to multiple inputs\n",
    "            y_train = velo[tissue][gene].values[train_idx[rep]]\n",
    "            y_test = velo[tissue][gene].values[test_idx[rep]]\n",
    "            \n",
    "            # Remove NA entries\n",
    "            select_train = ~np.isnan(y_train)\n",
    "            select_test = ~np.isnan(y_test)\n",
    "\n",
    "            y_train = y_train[select_train]\n",
    "            y_test = y_test[select_test]\n",
    "            \n",
    "            # Standardize y\n",
    "            y_train = (y_train - np.mean(y_train))/np.std(y_train)\n",
    "            y_test = (y_test - np.mean(y_test))/np.std(y_test)\n",
    "\n",
    "            X_all_train = []\n",
    "            X_all_test = []\n",
    "\n",
    "            for TF in rpkm[tissue].columns:\n",
    "\n",
    "                X_all_train.append(np.empty((train_idx[rep].shape[0], 5)))\n",
    "                X_all_test.append(np.empty((test_idx[rep].shape[0], 5)))\n",
    "\n",
    "                # Expression rpkms\n",
    "                X_all_train[-1][:,0] = rpkm[tissue][TF].values[train_idx[rep],]\n",
    "                X_all_test[-1][:,0] = rpkm[tissue][TF].values[test_idx[rep],]\n",
    "\n",
    "                # For current tf & gene, get corresponding gene symbol name\n",
    "                tf_symbol = ensembl_to_symbol.loc[ensembl_to_symbol[\"ensembl_id\"] == TF,\"gene_symbol\"].iloc[0]\n",
    "                gene_symbol = ensembl_to_symbol.loc[ensembl_to_symbol[\"ensembl_id\"] == gene,\"gene_symbol\"].iloc[0]\n",
    "                \n",
    "                # Remove the NA entries\n",
    "                X_all_train[-1] = X_all_train[-1][select_train,:]\n",
    "                X_all_test[-1] = X_all_test[-1][select_test,:]\n",
    "\n",
    "                # Use TF activities if they exist (tf from rpkm matrix), otherwise specify them as zero.\n",
    "                if tf_symbol in tf_gene_mat_mean[tissue].columns and gene_symbol in tf_gene_mat_mean[tissue].index:\n",
    "\n",
    "                    # TF mean signals\n",
    "                    X_all_train[-1][:,1] = tf_gene_mat_mean[tissue].loc[gene_symbol, tf_symbol]\n",
    "                    X_all_test[-1][:,1] = tf_gene_mat_mean[tissue].loc[gene_symbol, tf_symbol]\n",
    "\n",
    "                    # TF sum signals\n",
    "                    X_all_train[-1][:,2] = tf_gene_mat_sum[tissue].loc[gene_symbol, tf_symbol]\n",
    "                    X_all_test[-1][:,2] = tf_gene_mat_sum[tissue].loc[gene_symbol, tf_symbol]\n",
    "                else:\n",
    "                    # TF mean signals\n",
    "                    X_all_train[-1][:,1] = 0\n",
    "                    X_all_test[-1][:,1] = 0\n",
    "\n",
    "                    # TF sum signals\n",
    "                    X_all_train[-1][:,2] = 0\n",
    "                    X_all_test[-1][:,2] = 0\n",
    "\n",
    "                # The product of expressions and TF mean signals\n",
    "                X_all_train[-1][:,3] =  X_all_train[-1][:,0] * X_all_train[-1][:,1]\n",
    "                X_all_test[-1][:,3] = X_all_test[-1][:,0] * X_all_test[-1][:,1]\n",
    "\n",
    "                # The product of expressions and TF sum signals\n",
    "                X_all_train[-1][:,4] = X_all_train[-1][:,0] * X_all_train[-1][:,2]\n",
    "                X_all_test[-1][:,4] = X_all_test[-1][:,0] * X_all_test[-1][:,2]\n",
    "\n",
    "                # Standardize the rpkms and the prod features\n",
    "                if np.sum(X_all_train[-1][:,0]) != 0:\n",
    "                    X_all_train[-1][:,0] = (X_all_train[-1][:,0] - np.mean(X_all_train[-1][:,0]))/np.std(X_all_train[-1][:,0])\n",
    "\n",
    "                if np.sum(X_all_train[-1][:,3]) != 0:\n",
    "                    X_all_train[-1][:,3] = (X_all_train[-1][:,3] - np.mean(X_all_train[-1][:,3]))/np.std(X_all_train[-1][:,3])\n",
    "\n",
    "                if np.sum(X_all_train[-1][:,4]) != 0:\n",
    "                    X_all_train[-1][:,4] = (X_all_train[-1][:,4] - np.mean(X_all_train[-1][:,4]))/np.std(X_all_train[-1][:,4])\n",
    "\n",
    "                if np.sum(X_all_test[-1][:,0]) != 0:\n",
    "                    X_all_test[-1][:,0] = (X_all_test[-1][:,0] - np.mean(X_all_test[-1][:,0]))/np.std(X_all_test[-1][:,0])\n",
    "\n",
    "                if np.sum(X_all_test[-1][:,3]) != 0:\n",
    "                    X_all_test[-1][:,3] = (X_all_test[-1][:,3] - np.mean(X_all_test[-1][:,3]))/np.std(X_all_test[-1][:,3])\n",
    "\n",
    "                if np.sum(X_all_test[-1][:,4]) != 0:\n",
    "                    X_all_test[-1][:,4] = (X_all_test[-1][:,4] - np.mean(X_all_test[-1][:,4]))/np.std(X_all_test[-1][:,4])\n",
    "            \n",
    "            # Reset model weights.\n",
    "            model.set_weights(ini_weights)\n",
    "                \n",
    "            # Train model\n",
    "            model.fit(\n",
    "                x = X_all_train,\n",
    "                y = y_train,\n",
    "                batch_size = batch_size,\n",
    "                epochs = n_epoch,\n",
    "                verbose = 0\n",
    "            )\n",
    "\n",
    "            # Test model\n",
    "            y_pred = model.predict(x = X_all_test)\n",
    "            r2_mat[rep,i] = r2_score(y_test, y_pred)\n",
    "            \n",
    "        # Save r2 results to file\n",
    "        with open(\"results/r2/basenn_expTFAPredVelo_r2.csv\",\"a\") as f:\n",
    "            f.writelines(\"Tissue:{}, Gene:{} finished; r2:{}\\n\".format(tissue,gene,str(np.mean(r2_mat[:,i]))))\n",
    "    \n",
    "    return(r2_mat,tissue)\n",
    "\n",
    "res = Parallel(n_jobs=6)(delayed(train_parallel)(tissue) \n",
    "                              for tissue in comm_tissues) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGC TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
